<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chaotic Neutral's: Voiceforge Pro</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/static/styles.css">
</head>
<body>
    <!-- Animated shooting stars -->
    <div class="shooting-stars">
        <div class="shooting-star"></div>
        <div class="shooting-star"></div>
        <div class="shooting-star"></div>
        <div class="shooting-star"></div>
        <div class="shooting-star"></div>
    </div>
    
    <div class="container">
        <div class="header">
            <h1 class="title">Chaotic Neutral's: Voiceforge Pro</h1>
            <button class="btn btn-secondary help-btn" onclick="showHelp()" aria-label="Show help">
                <span>?</span> Help
            </button>
        </div>

        <div class="tabs" role="tablist">
            <button class="tab active" onclick="switchTab(0)" role="tab" aria-selected="true" aria-controls="tab-0">TTS</button>
            <button class="tab" onclick="switchTab(1)" role="tab" aria-selected="false" aria-controls="tab-1">RVC</button>
            <button class="tab" onclick="switchTab(2)" role="tab" aria-selected="false" aria-controls="tab-2">Preprocess</button>
            <button class="tab" onclick="switchTab(3)" role="tab" aria-selected="false" aria-controls="tab-3">Post-Processing</button>
            <button class="tab" onclick="switchTab(4)" role="tab" aria-selected="false" aria-controls="tab-4">Background Audio</button>
            <button class="tab" onclick="switchTab(5)" role="tab" aria-selected="false" aria-controls="tab-5">Transcribe</button>
            <button class="tab" onclick="switchTab(6)" role="tab" aria-selected="false" aria-controls="tab-6">ComfyUI</button>
            <button class="tab" onclick="switchTab(7)" role="tab" aria-selected="false" aria-controls="tab-7">Training</button>
        </div>

        <!-- TTS Tab -->
        <div id="tab-0" class="tab-content active" role="tabpanel" aria-labelledby="tab-0">
            <div class="card-section">
                <!-- Voice Cloning (Chatterbox only) -->
                <div class="form-group" id="chatterbox-voice-cloning-section">
                    <label class="label-with-help">
                        Voice Cloning Audio (Required for Chatterbox)
                        <span class="help-icon" title="Reference audio file for voice cloning. 5+ seconds required, 10+ seconds recommended for best results. Only needed for Chatterbox backend.">?</span>
                    </label>
                    <div class="form-row" style="gap: 8px; align-items: center;">
                        <select id="audio-prompt-select" style="flex: 1;" onchange="selectAudioPrompt(this)" aria-label="Select audio prompt">
                            <option value="">-- Select saved prompt --</option>
                        </select>
                        <span style="color: var(--text-secondary);">or</span>
                        <input type="file" id="chatterbox-prompt-audio" accept="audio/*" style="flex: 1;" aria-label="Upload audio file" onchange="trackChatterboxPromptFile(this)">
                    </div>
                    <div class="input-hint"><strong>5+ sec required</strong> (10+ recommended) ‚Äî TTS will mimic this voice</div>
                    <div id="chatterbox-prompt-hint" class="input-hint" style="display: none; color: var(--accent);"></div>
                </div>

                <div class="form-group">
                    <div style="display: flex; flex-direction: row; align-items: center; gap: 8px; margin-bottom: 8px;">
                        <label for="text-input" class="label-with-help" style="margin: 0;">
                            Text Input
                            <span class="help-icon" title="Enter the text you want to convert to speech">?</span>
                        </label>
                        <select id="script-select" style="padding: 4px 8px; font-size: 0.85em; width: auto;" onchange="loadScriptFromSelect()" aria-label="Load script">
                            <option value="">üìÇ Scripts...</option>
                        </select>
                        <button class="btn btn-secondary" onclick="addScript()" style="padding: 4px 8px; font-size: 0.85em;" aria-label="Add new script" title="Add new script">
                            <span>‚ûï</span>
                        </button>
                    </div>
                    <textarea id="text-input" placeholder="Enter text to synthesize‚Ä¶" aria-label="Text input for speech synthesis"></textarea>
                    <div class="input-hint">Press Ctrl+G to generate speech, or Ctrl+O to load a script</div>
                </div>

                <div class="checkbox-group">
                    <label class="checkbox-label">
                        <input type="checkbox" id="enable-rvc" checked aria-label="Enable RVC voice conversion">
                        <span>Enable RVC</span>
                    </label>
                    <label class="checkbox-label">
                        <input type="checkbox" id="enable-post" checked aria-label="Enable post-processing">
                        <span>Enable Post-Processing</span>
                    </label>
                    <label class="checkbox-label">
                        <input type="checkbox" id="enable-background" checked aria-label="Enable background audio mixing">
                        <span>Enable Background Audio</span>
                    </label>
                </div>

                <div class="form-row" style="gap: 8px; margin-top: 8px;">
                    <button class="btn btn-primary" id="generate-btn" onclick="generateSpeech()" style="flex: 1;" aria-label="Generate speech">
                    <span>üéµ</span> Generate Speech (Ctrl+G)
                </button>
                    <button class="btn btn-danger" id="stop-btn" onclick="stopGeneration()" style="display: none; min-width: 100px;" aria-label="Stop generation">
                        <span>‚èπ</span> Stop
                    </button>
                </div>

                <div class="status" id="status" role="status" aria-live="polite">Ready.</div>
                <div class="progress-bar" id="progress-bar" role="progressbar" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100">
                    <div class="progress-fill" id="progress-fill">0%</div>
                </div>

                <audio id="audio-player" class="audio-player" controls style="display: none;" aria-label="Generated audio playback"></audio>
            </div>

            <!-- TTS Settings -->
            <div class="card-section" style="margin-top: 4px;">
                <div class="section-header">TTS Settings</div>
                
                <div class="form-grid">
                    <div class="form-group">
                        <label for="tts-mode" class="label-with-help">
                            Generation Mode
                            <span class="help-icon" title="Chunked: Generates all chunks, then returns combined audio. Streaming: Streams each chunk as it's generated for faster initial playback.">?</span>
                        </label>
                        <select id="tts-mode" aria-label="TTS generation mode">
                            <option value="chunked">Chunked (wait for complete audio)</option>
                            <option value="streaming">Streaming (progressive playback)</option>
                        </select>
                        <div class="input-hint">Streaming starts playback faster for long text</div>
                    </div>

                    <div class="form-group">
                        <label for="tts-backend" class="label-with-help">
                            TTS Backend
                            <span class="help-icon" title="Select which TTS engine to use. Chatterbox supports voice cloning; Soprano is lightweight and fast.">?</span>
                        </label>
                        <select id="tts-backend" aria-label="TTS backend" onchange="updateTTSBackendUI()">
                            <option value="chatterbox">Chatterbox</option>
                            <option value="soprano">Soprano</option>
                        </select>
                        <div class="input-hint">Chatterbox = voice cloning | Soprano = fast TTS</div>
                    </div>

                    <div class="form-group" id="chatterbox-model-section">
                        <label for="chatterbox-model" class="label-with-help">
                            Chatterbox Model
                            <span class="help-icon" title="Select which Chatterbox model to use. 'Default' uses the base pretrained model. Custom models are trained via the Training tab.">?</span>
                        </label>
                        <div class="form-row" style="gap: 8px; align-items: center;">
                            <select id="chatterbox-model" aria-label="Chatterbox model" style="flex: 1;">
                                <option value="">Default (Base Model)</option>
                            </select>
                            <button type="button" class="btn btn-secondary btn-sm" onclick="refreshChatterboxModels()" title="Refresh model list">‚Üª</button>
                        </div>
                        <div class="input-hint">Custom models trained in the Training tab will appear here</div>
                    </div>

                    <div id="soprano-settings" style="display: none;">
                        <div class="form-group">
                            <label for="soprano-model" class="label-with-help">
                                Soprano Model
                                <span class="help-icon" title="Select which Soprano model to use. 'Default' uses the base pretrained model. Custom models are trained via the Training tab.">?</span>
                            </label>
                            <div class="form-row" style="gap: 8px; align-items: center;">
                                <select id="soprano-model" aria-label="Soprano model" style="flex: 1;">
                                    <option value="">Default (Base Model)</option>
                                </select>
                                <button type="button" class="btn btn-secondary btn-sm" onclick="refreshSopranoModels()" title="Refresh model list">‚Üª</button>
                            </div>
                            <div class="input-hint">Custom models trained in the Training tab will appear here</div>
                        </div>
                        
                        <div class="form-group">
                            <label class="label-with-help">
                                Soprano Sampling
                                <span class="help-icon" title="Soprano sampling settings. Higher temperature = more varied output. Lower = more consistent. Repetition penalty helps avoid loops.">?</span>
                            </label>
                            <div class="form-row" style="align-items: center; gap: 10px;">
                                <label for="soprano-temperature" style="min-width: 90px;">Temperature</label>
                                <input type="number" id="soprano-temperature" value="0.7" min="0.01" max="2" step="0.01" aria-label="Soprano temperature">
                                <label for="soprano-top-p" style="min-width: 60px;">Top P</label>
                                <input type="number" id="soprano-top-p" value="0.95" min="0.01" max="1" step="0.01" aria-label="Soprano top p">
                                <label for="soprano-repetition-penalty" style="min-width: 130px;">Repetition</label>
                                <input type="number" id="soprano-repetition-penalty" value="1.2" min="0.8" max="2" step="0.05" aria-label="Soprano repetition penalty">
                            </div>
                            <div class="input-hint">Soprano uses a fixed voice (no cloning). Lower temp (0.3) = consistent, higher (0.7+) = varied</div>
                        </div>
                    </div>
                    
                    <div class="form-group">
                        <label for="output-volume" class="label-with-help">
                            Output Volume
                            <span class="help-icon" title="Final volume of generated audio. 1.0 = 100% (no change), 0.5 = 50%, 2.0 = 200%. Applied to saved files.">?</span>
                        </label>
                        <input type="number" id="output-volume" value="1.0" min="0" max="3" step="0.05" aria-label="Output volume">
                        <div class="input-hint">1.0 = 100%, 0.5 = 50%, 2.0 = 200%</div>
                    </div>

                    <div class="form-group">
                        <label class="label-with-help">
                            Save Output
                            <span class="help-icon" title="Save the final merged audio to the server output folder. Off by default to reduce disk writes.">?</span>
                        </label>
                        <label class="checkbox_label" style="margin-top: 4px;">
                            <input type="checkbox" id="save-output">
                            <small>Save merged file after generation</small>
                        </label>
                    </div>
                    
                    <div class="form-group">
                        <label for="chatterbox-seed" class="label-with-help">
                            Seed
                            <span class="help-icon" title="Random seed for reproducibility. -1 = new random each time, 0 = no seeding (PyTorch default), >0 = specific seed for reproducible output.">?</span>
                        </label>
                        <input type="number" id="chatterbox-seed" min="-1" step="1" value="-1" aria-label="Random seed">
                        <div class="input-hint">-1 = new random, 0 = no seeding</div>
                    </div>
                    
                    <div class="form-group">
                        <label for="tts-batch-tokens" class="label-with-help">
                            Chunk Size (tokens)
                            <span class="help-icon" title="Text chunk size for TTS generation. Higher = better quality but slower startup, Lower = faster startup but may affect quality. Default: 50">?</span>
                        </label>
                        <div class="form-row" style="align-items: center; gap: 12px;">
                            <input type="range" id="tts-batch-tokens" min="5" max="100" value="50" style="flex: 1;" oninput="document.getElementById('tts-batch-tokens-value').textContent = this.value">
                            <span id="tts-batch-tokens-value" style="min-width: 40px; text-align: right; font-weight: 600;">50</span>
                        </div>
                        <div class="input-hint">5-25 = fast startup | 50 = balanced | 75-100 = best quality</div>
                    </div>
                </div>
                
                <div class="form-group" style="margin-top: 12px;">
                    <label class="label-with-help">
                        Token Counting Method
                        <span class="help-icon" title="Tiktoken is accurate (GPT-4 tokenizer). Word-based is faster.">?</span>
                    </label>
                    <div class="form-row" style="gap: 14px; align-items: center;">
                        <label style="display: flex; align-items: center; gap: 8px; cursor: pointer;">
                            <input type="radio" name="token-method" id="token-method-tiktoken" value="tiktoken" checked>
                            <span>Tiktoken (accurate)</span>
                        </label>
                        <label style="display: flex; align-items: center; gap: 8px; cursor: pointer;">
                            <input type="radio" name="token-method" id="token-method-words" value="words">
                            <span>Word-based (fast)</span>
                        </label>
                    </div>
                </div>

                <div class="card-section" style="margin-top: 4px; background: var(--bg-tertiary); padding: 10px; border-radius: 6px;">
                    <div style="font-weight: 600; margin-bottom: 6px; font-size: 12px;">Supported Paralinguistic Tags:</div>
                    <div style="color: var(--text-muted); font-family: monospace; font-size: 11px;">
                        [laugh] [chuckle] [cough] [sigh] [gasp] [groan] [yawn] [clear throat]
                    </div>
                    <div class="input-hint" style="margin-top: 6px;">Add these tags in your text to insert natural speech sounds</div>
                </div>
            </div>
        </div>

        <!-- RVC Tab -->
        <div id="tab-1" class="tab-content" role="tabpanel" aria-labelledby="tab-1">
            <div class="scrollable">
                <!-- RVC File Processing Section -->
                <div class="card-section">
                    <div class="section-header">Process Audio File</div>
                    <p style="color: var(--text-muted); margin-bottom: 12px;">Upload an audio file to run through RVC with the settings below.</p>
                    
                    <div class="form-group">
                        <label for="rvc-audio-input" class="label-with-help">
                            Audio File
                            <span class="help-icon" title="Select an audio file to process through RVC voice conversion">?</span>
                        </label>
                        <input type="file" id="rvc-audio-input" accept="audio/*" aria-label="Audio file for RVC processing">
                        <div class="input-hint">Supported: WAV, MP3, FLAC, OGG, etc.</div>
                    </div>
                    
                    <button class="btn btn-primary" id="rvc-process-btn" onclick="processRvcFile()" style="width: 100%; margin-top: 8px;" aria-label="Process audio through RVC">
                        <span>üé§</span> Process with RVC
                    </button>
                    
                    <div class="status" id="rvc-status" role="status" aria-live="polite" style="margin-top: 12px;">Select an audio file and click Process.</div>
                    <div class="progress-bar" id="rvc-progress-bar" role="progressbar" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" style="margin-top: 8px; display: none;">
                        <div class="progress-fill" id="rvc-progress-fill">0%</div>
                    </div>
                    
                    <audio id="rvc-audio-player" class="audio-player" controls style="display: none; margin-top: 12px;" aria-label="RVC processed audio playback"></audio>
                </div>

                <div class="card-section">
                    <div class="section-header">RVC Settings</div>
                    <div class="form-group">
                        <label for="model-select" class="label-with-help">
                            RVC Model
                            <span class="help-icon" title="Select the RVC model to use for voice conversion">?</span>
                        </label>
                        <select id="model-select" aria-label="RVC model selection"></select>
                        <div class="input-hint">Required if RVC is enabled</div>
                    </div>
                </div>

                <div class="card-section">
                    <div class="section-header">Basic Parameters</div>
                    <div class="form-grid">
                        <div class="form-group">
                            <label for="pitch-algo" class="label-with-help">
                                Pitch Algorithm
                                <span class="help-icon" title="Algorithm used for pitch detection">?</span>
                            </label>
                            <select id="pitch-algo" aria-label="Pitch algorithm">
                                <option value="pm">pm</option>
                                <option value="harvest">harvest</option>
                                <option value="dio">dio</option>
                                <option value="crepe">crepe</option>
                                <option value="mangio-crepe">mangio-crepe</option>
                                <option value="rmvpe">rmvpe</option>
                                <option value="rmvpe+" selected>rmvpe+</option>
                                <option value="mangio-crepe+">mangio-crepe+</option>
                            </select>
                        </div>
                        <div class="form-group">
                            <label for="pitch-lvl" class="label-with-help">
                                Pitch Level
                                <span class="help-icon" title="Pitch adjustment in semitones (-24 to +24)">?</span>
                            </label>
                            <input type="number" id="pitch-lvl" value="0" min="-24" max="24" aria-label="Pitch level">
                            <div class="input-hint">Range: -24 to +24 semitones</div>
                        </div>
                    </div>
                </div>

                <div class="card-section">
                    <div class="section-header">Advanced Parameters</div>
                    <div class="form-grid">
                        <div class="form-group">
                            <label for="index-influence" class="label-with-help">
                                Index Influence
                                <span class="help-icon" title="How much the index file influences the output (0.0 to 1.0)">?</span>
                            </label>
                            <input type="number" id="index-influence" value="0.75" min="0" max="1" step="0.01" aria-label="Index influence">
                            <div class="input-hint">Range: 0.0 to 1.0</div>
                        </div>
                        <div class="form-group">
                            <label for="respiration-median" class="label-with-help">
                                Respiration Median Filtering
                                <span class="help-icon" title="Median filter size for respiration artifacts">?</span>
                            </label>
                            <input type="number" id="respiration-median" value="3" min="0" max="99" aria-label="Respiration median filtering">
                        </div>
                        <div class="form-group">
                            <label for="envelope-ratio" class="label-with-help">
                                Envelope Ratio
                                <span class="help-icon" title="Envelope ratio for formant preservation">?</span>
                            </label>
                            <input type="number" id="envelope-ratio" value="0.25" min="0" max="1" step="0.01" aria-label="Envelope ratio">
                        </div>
                        <div class="form-group">
                            <label for="consonant-breath" class="label-with-help">
                                Consonant Breath Protection
                                <span class="help-icon" title="Protection level for consonant breath sounds">?</span>
                            </label>
                            <input type="number" id="consonant-breath" value="0.33" min="0" max="1" step="0.01" aria-label="Consonant breath protection">
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Post-Processing Tab -->
        <div id="tab-3" class="tab-content" role="tabpanel" aria-labelledby="tab-3">
            <div class="scrollable">
                <!-- Post-Process Audio File Section -->
                <div class="card-section">
                    <div class="section-header">Process Audio File</div>
                    <p style="color: var(--text-muted); margin-bottom: 12px;">Upload an audio file to apply post-processing effects with the settings below.</p>
                    
                    <div class="form-group">
                        <label for="postprocess-audio-file" class="label-with-help">
                            Audio File
                            <span class="help-icon" title="Select an audio file to post-process">?</span>
                        </label>
                        <input type="file" id="postprocess-audio-file" accept="audio/*" aria-label="Select audio file to post-process">
                        <div class="input-hint">Supported: WAV, MP3, FLAC, OGG, etc.</div>
                    </div>
                    
                    <button class="btn btn-primary" id="postprocess-btn" onclick="postProcessAudio()" style="width: 100%; margin-top: 8px;" aria-label="Post-process audio file">
                        <span>üéöÔ∏è</span> Post-Process Audio
                    </button>
                    
                    <div class="status" id="postprocess-audio-status" role="status" aria-live="polite" style="margin-top: 12px;">Select an audio file and click Post-Process.</div>
                    <div class="progress-bar" id="postprocess-progress-bar" role="progressbar" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" style="margin-top: 8px; display: none;">
                        <div class="progress-fill" id="postprocess-progress-fill">0%</div>
                    </div>
                    
                    <audio id="postprocessed-audio-player" class="audio-player" controls style="display: none; margin-top: 12px;" aria-label="Post-processed audio playback"></audio>
                </div>

                <div class="card-section">
                    <div class="section-header">Audio Mastering</div>
                    
                    <!-- EQ Row -->
                    <div style="margin-bottom: 16px;">
                        <div style="font-size: 11px; color: var(--text-muted); margin-bottom: 8px; text-transform: uppercase; letter-spacing: 0.5px;">Equalization</div>
                        <div class="form-grid" style="gap: 10px;">
                        <div class="form-group">
                                <label for="highpass" title="Remove rumble. Try: 60-100Hz">Highpass (Hz)</label>
                                <input type="number" id="highpass" value="0" min="0" max="20000" placeholder="60-100" aria-label="Highpass frequency">
                        </div>
                        <div class="form-group">
                                <label for="lowpass" title="Remove harshness. Try: 12000-16000Hz">Lowpass (Hz)</label>
                                <input type="number" id="lowpass" value="0" min="0" max="24000" placeholder="12000-16000" aria-label="Lowpass frequency">
                        </div>
                        <div class="form-group">
                                <label for="bass-freq" title="Bass center frequency. Try: 60-150Hz">Bass (Hz)</label>
                                <input type="number" id="bass-freq" value="100" min="20" max="500" placeholder="60-150" aria-label="Bass frequency">
                        </div>
                        <div class="form-group">
                                <label for="bass-gain" title="Bass boost/cut. Try: 2-6dB boost">Bass (dB)</label>
                                <input type="number" id="bass-gain" value="0" min="-24" max="24" step="0.1" placeholder="0" aria-label="Bass gain">
                        </div>
                        <div class="form-group">
                                <label for="treble-freq" title="Treble center frequency. Try: 6000-10000Hz">Treble (Hz)</label>
                                <input type="number" id="treble-freq" value="8000" min="1000" max="20000" placeholder="6000-10000" aria-label="Treble frequency">
                        </div>
                        <div class="form-group">
                                <label for="treble-gain" title="Treble boost/cut. Try: 1-4dB boost">Treble (dB)</label>
                                <input type="number" id="treble-gain" value="0" min="-24" max="24" step="0.1" placeholder="0" aria-label="Treble gain">
                        </div>
                        </div>
                    </div>
                    
                    <!-- Dynamics & Effects Row -->
                    <div style="margin-bottom: 16px;">
                        <div style="font-size: 11px; color: var(--text-muted); margin-bottom: 8px; text-transform: uppercase; letter-spacing: 0.5px;">Dynamics & Enhancement</div>
                        <div class="form-grid" style="gap: 10px;">
                        <div class="form-group">
                                <label for="crystalizer" title="Enhances clarity. Try: 4-8">Crystalizer</label>
                                <input type="number" id="crystalizer" value="0" min="0" max="20" step="0.1" placeholder="4-8" aria-label="Crystalizer intensity">
                            </div>
                            <div class="form-group">
                                <label for="deesser" title="Reduces harsh 's' sounds. Try: 0.3-0.5">De-esser</label>
                                <input type="number" id="deesser" value="0" min="0" max="1" step="0.01" placeholder="0.3-0.5" aria-label="De-esser intensity">
                            </div>
                        </div>
                    </div>
                    
                    <!-- Reverb Row -->
                    <div style="margin-bottom: 16px;">
                        <div style="font-size: 11px; color: var(--text-muted); margin-bottom: 8px; text-transform: uppercase; letter-spacing: 0.5px;">Reverb</div>
                        <div class="form-grid" style="gap: 10px;">
                            <div class="form-group">
                                <label for="reverb-delay" title="Echo delay in milliseconds. Try: 20-60ms for room, 100-200ms for hall">Delay (ms)</label>
                                <input type="number" id="reverb-delay" value="0" min="0" max="500" placeholder="20-60" aria-label="Reverb delay">
                            </div>
                            <div class="form-group">
                                <label for="reverb-decay" title="Echo decay/feedback. Try: 0.1-0.4 for subtle, 0.5+ for long tails">Decay</label>
                                <input type="number" id="reverb-decay" value="0" min="0" max="0.9" step="0.05" placeholder="0.1-0.4" aria-label="Reverb decay">
                            </div>
                        </div>
                    </div>
                    
                    <!-- Pitch Shift Row -->
                    <div>
                        <div style="font-size: 11px; color: var(--text-muted); margin-bottom: 8px; text-transform: uppercase; letter-spacing: 0.5px;">Pitch Shift</div>
                        <div class="form-grid" style="gap: 10px;">
                            <div class="form-group">
                                <label class="checkbox-label">
                                    <input type="checkbox" id="pitch-shift-enabled" aria-label="Enable pitch shift">
                                    <span>Enable Pitch Shift</span>
                                </label>
                            </div>
                            <div class="form-group">
                                <label for="pitch-shift-semitones">Semitones</label>
                                <input type="number" id="pitch-shift-semitones" value="0" min="-12" max="12" step="1" aria-label="Pitch shift semitones">
                                <small style="display: block; font-size: 10px; color: var(--text-muted); margin-top: 2px;">-12 to +12 (negative = lower, positive = higher)</small>
                            </div>
                        </div>
                    </div>
                    
                    <!-- ASMR Enhancement Row -->
                    <div style="margin-top: 16px; padding-top: 16px; border-top: 1px solid var(--border);">
                        <div style="font-size: 11px; color: var(--text-muted); margin-bottom: 8px; text-transform: uppercase; letter-spacing: 0.5px;">
                            üéß ASMR / Whisper Enhancement
                        </div>
                        <div class="form-grid" style="gap: 10px;">
                            <div class="form-group">
                                <label class="checkbox-label">
                                    <input type="checkbox" id="asmr-enabled" aria-label="Enable ASMR enhancement">
                                    <span>Enable ASMR Mode</span>
                            </label>
                        </div>
                            <div class="form-group">
                                <label for="asmr-tingles" class="label-with-help">
                                    Tingles
                                    <span class="help-icon" title="Enhances the 2-8kHz 'tingle zone' frequencies that trigger ASMR sensations. The magic sauce!">?</span>
                                </label>
                                <input type="range" id="asmr-tingles" value="60" min="0" max="100" step="5" style="width: 100%;" aria-label="Tingle intensity">
                                <div style="display: flex; justify-content: space-between; font-size: 9px; color: var(--text-muted); margin-top: 2px;">
                                    <span>Subtle</span><span>‚ö° Intense</span>
                </div>
                            </div>
                        <div class="form-group">
                                <label for="asmr-breathiness" class="label-with-help">
                                    Breathiness
                                    <span class="help-icon" title="High frequency air and breath sounds. Creates that whispered, airy quality.">?</span>
                            </label>
                                <input type="range" id="asmr-breathiness" value="65" min="0" max="100" step="5" style="width: 100%;" aria-label="Breathiness level">
                                <div style="display: flex; justify-content: space-between; font-size: 9px; color: var(--text-muted); margin-top: 2px;">
                                    <span>Soft</span><span>Airy ‚ú®</span>
                                </div>
                        </div>
                        <div class="form-group">
                                <label for="asmr-crispness" class="label-with-help">
                                    Crispness
                                    <span class="help-icon" title="Mouth sounds, consonants, clicks, and crisp details that trigger tingles.">?</span>
                            </label>
                                <input type="range" id="asmr-crispness" value="55" min="0" max="100" step="5" style="width: 100%;" aria-label="Crispness level">
                                <div style="display: flex; justify-content: space-between; font-size: 9px; color: var(--text-muted); margin-top: 2px;">
                                    <span>Smooth</span><span>Crispy</span>
                                </div>
                        </div>
                        </div>
                        <div style="margin-top: 12px; padding: 10px; background: linear-gradient(135deg, rgba(138, 43, 226, 0.15), rgba(30, 144, 255, 0.1)); border-radius: var(--radius-sm); font-size: 10px; color: var(--text-muted); border: 1px solid rgba(138, 43, 226, 0.2);">
                            <div style="margin-bottom: 6px;">üéß <strong style="color: var(--accent);">ASMR Guide:</strong></div>
                            <ul style="margin: 0; padding-left: 16px; line-height: 1.5;">
                                <li><strong>ASMR = tonal shaping</strong> (tingles, breath, compression)</li>
                                <li><strong>Spatial Audio below</strong> = positioning, movement + warmth (via Proximity)</li>
                                <li><strong>Best combo:</strong> ASMR + Spatial with low Distance</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="card-section">
                    <div class="section-header">üéß Spatial Audio</div>
                    
                    <!-- Main Enable Checkbox -->
                    <div class="form-group" style="margin-bottom: 16px;">
                        <label class="checkbox-label">
                            <input type="checkbox" id="audio-8d-enabled">
                            <span>Enable Spatial Audio</span>
                        </label>
                        <div style="font-size: 10px; color: var(--text-muted); margin-top: 4px;">
                            Immersive binaural: ITD, head shadow, proximity, crossfeed, panning
                        </div>
                    </div>
                    
                    <!-- Visualization + Controls Container -->
                    <div id="spatial-audio-controls" style="opacity: 0.5; pointer-events: none; transition: opacity 0.2s;">
                        
                        <!-- Circular Spatial Audio Visualization -->
                        <div style="background: linear-gradient(135deg, rgba(30,144,255,0.08) 0%, rgba(140,80,200,0.08) 100%); border-radius: var(--radius-lg); padding: 20px; margin-bottom: 16px; border: 1px solid var(--border);">
                            <div style="display: flex; justify-content: center;">
                                <svg id="spatial-circle" width="200" height="200" style="display: block;">
                                    <!-- Outer glow ring -->
                                    <circle cx="100" cy="100" r="85" fill="none" stroke="var(--accent)" stroke-width="1" opacity="0.2"/>
                                    
                                    <!-- Main position ring -->
                                    <circle cx="100" cy="100" r="70" fill="none" stroke="var(--border)" stroke-width="3" stroke-linecap="round"/>
                                    
                                    <!-- Quadrant markers -->
                                    <line x1="100" y1="25" x2="100" y2="35" stroke="var(--text-muted)" stroke-width="2" opacity="0.5"/>
                                    <line x1="100" y1="165" x2="100" y2="175" stroke="var(--text-muted)" stroke-width="2" opacity="0.5"/>
                                    <line x1="25" y1="100" x2="35" y2="100" stroke="var(--accent)" stroke-width="3"/>
                                    <line x1="165" y1="100" x2="175" y2="100" stroke="var(--accent)" stroke-width="3"/>
                                    
                                    <!-- Direction labels -->
                                    <text x="100" y="16" text-anchor="middle" fill="var(--text-muted)" font-size="10" opacity="0.6">Front</text>
                                    <text x="100" y="192" text-anchor="middle" fill="var(--text-muted)" font-size="10" opacity="0.6">Back</text>
                                    <text x="12" y="104" text-anchor="middle" fill="var(--accent)" font-size="13" font-weight="bold">L</text>
                                    <text x="188" y="104" text-anchor="middle" fill="var(--accent)" font-size="13" font-weight="bold">R</text>
                                    
                                    <!-- Inner ring (closer) -->
                                    <circle cx="100" cy="100" r="45" fill="none" stroke="var(--border)" stroke-width="1" stroke-dasharray="4,4" opacity="0.3"/>
                                    
                                    <!-- Head in center -->
                                    <circle cx="100" cy="100" r="22" fill="var(--bg-dark)" stroke="var(--text-muted)" stroke-width="2"/>
                                    <!-- Ears -->
                                    <ellipse id="ear-left-svg" cx="78" cy="100" rx="6" ry="10" fill="var(--accent)" opacity="0.8" style="transition: all 0.1s;"/>
                                    <ellipse id="ear-right-svg" cx="122" cy="100" rx="6" ry="10" fill="var(--text-muted)" opacity="0.4" style="transition: all 0.1s;"/>
                                    <!-- Eyes -->
                                    <circle cx="93" cy="95" r="3" fill="var(--text-muted)"/>
                                    <circle cx="107" cy="95" r="3" fill="var(--text-muted)"/>
                                    <!-- Smile -->
                                    <path d="M93 106 Q100 112 107 106" fill="none" stroke="var(--text-muted)" stroke-width="2" stroke-linecap="round"/>
                                    
                                    <!-- Trail effect (shows recent positions) -->
                                    <circle id="pan-trail-3" cx="30" cy="100" r="4" fill="var(--accent)" opacity="0.1" style="transition: all 0.15s;"/>
                                    <circle id="pan-trail-2" cx="30" cy="100" r="5" fill="var(--accent)" opacity="0.2" style="transition: all 0.1s;"/>
                                    <circle id="pan-trail-1" cx="30" cy="100" r="6" fill="var(--accent)" opacity="0.3" style="transition: all 0.05s;"/>
                                    
                                    <!-- Sound position indicator (main dot) -->
                                    <circle id="pan-position-dot" cx="30" cy="100" r="10" fill="var(--accent)" style="filter: drop-shadow(0 0 8px var(--accent)) drop-shadow(0 0 16px rgba(30,144,255,0.6)); transition: all 0.05s linear;"/>
                                    
                                    <!-- Glow effect around position -->
                                    <circle id="pan-glow" cx="30" cy="100" r="18" fill="none" stroke="var(--accent)" stroke-width="2" opacity="0.3" style="transition: all 0.05s;"/>
                                </svg>
                            </div>
                            
                            <!-- Position text and preview button -->
                            <div style="text-align: center; margin-top: 8px;">
                                <div id="pan-position-text" style="font-size: 13px; color: var(--accent); font-weight: 600; margin-bottom: 10px;">‚óè Center</div>
                                <button id="preview-panning-btn" class="btn btn-secondary" style="font-size: 11px; padding: 6px 20px;">
                                    ‚ñ∂ Preview Movement
                                </button>
                            </div>
                        </div>
                        
                        <!-- Controls Grid -->
                        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(140px, 1fr)); gap: 12px;">
                            <!-- Mode -->
                            <div class="form-group">
                                <label for="audio-8d-mode" style="font-size: 11px; color: var(--text-muted); margin-bottom: 4px; display: block;">Position / Movement</label>
                                <select id="audio-8d-mode" style="width: 100%; padding: 8px; font-size: 12px;">
                                    <option value="center">üéØ Center (Binaural)</option>
                                    <option value="extreme" selected>üëÇ Ear Zones (dwell L/R)</option>
                                    <option value="sweep">‚Üî Linear Sweep</option>
                                    <option value="rotate">„Ä∞ Smooth Rotation</option>
                                    <option value="static">‚óÄ Static Left</option>
                                    <option value="static_right">‚ñ∂ Static Right</option>
                                </select>
                            </div>
                            
                            <!-- Speed -->
                            <div class="form-group" id="pan-speed-group">
                                <label for="audio-8d-speed" style="font-size: 11px; color: var(--text-muted); margin-bottom: 4px; display: block;">
                                    Speed: <span id="speed-display">0.08</span> Hz
                                </label>
                                <input type="range" id="audio-8d-speed" value="0.08" min="0.01" max="0.5" step="0.01" style="width: 100%;">
                            </div>
                            
                            <!-- Arc Width (in degrees) -->
                            <div class="form-group">
                                <label for="audio-8d-depth" style="font-size: 11px; color: var(--text-muted); margin-bottom: 4px; display: block;">
                                    Arc: <span id="depth-display">180</span>¬∞ <span style="opacity: 0.6">(180=L‚ÜîR, 360=full)</span>
                                </label>
                                <input type="range" id="audio-8d-depth" value="180" min="0" max="360" step="1" style="width: 100%;">
                            </div>
                            
                        </div>
                        
                        <!-- Enhanced Spatial Settings -->
                        <div style="margin-top: 16px; padding: 14px; background: rgba(100,200,255,0.05); border-radius: var(--radius-md); border: 1px solid rgba(100,200,255,0.15);">
                            <div style="display: flex; align-items: center; gap: 8px; margin-bottom: 12px; cursor: pointer;" onclick="toggleSpatialAdvanced()">
                                <span id="spatial-advanced-arrow" style="transition: transform 0.2s;">‚ñ∂</span>
                                <span style="font-size: 12px; font-weight: 500; color: var(--text);">Enhanced Binaural (8D/16D)</span>
                                <span style="font-size: 10px; padding: 2px 6px; background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); color: #000; border-radius: 4px; font-weight: 600;">NEW</span>
                            </div>
                            
                            <div id="spatial-advanced-panel" style="display: none;">
                                <p style="font-size: 11px; color: var(--text-muted); margin-bottom: 12px; line-height: 1.5;">
                                    Ultra-realistic spatial audio with ITD (ear timing), head shadow, proximity effects, and natural crossfeed.
                                </p>
                                
                                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(130px, 1fr)); gap: 12px;">
                                    <!-- Quality Preset -->
                                    <div class="form-group">
                                        <label for="audio-8d-quality" style="font-size: 11px; color: var(--text-muted); margin-bottom: 4px; display: block;">
                                            Quality Preset
                                        </label>
                                        <select id="audio-8d-quality" style="width: 100%; padding: 8px; font-size: 12px;">
                                            <option value="fast">‚ö° Fast (streaming)</option>
                                            <option value="balanced" selected>‚öñÔ∏è Balanced</option>
                                            <option value="ultra">‚ú® Ultra (ASMR)</option>
                                        </select>
                                    </div>
                                    
                                    <!-- Distance/Proximity - controls the enhanced proximity effect -->
                                    <div class="form-group">
                                        <label for="audio-8d-distance" style="font-size: 11px; color: var(--text-muted); margin-bottom: 4px; display: block;">
                                            Distance: <span id="distance-display">0.3</span> <span style="opacity: 0.6">(0=in ear)</span>
                                        </label>
                                        <input type="range" id="audio-8d-distance" value="0.3" min="0" max="1" step="0.01" style="width: 100%;">
                                        <div style="font-size: 9px; color: var(--text-muted); margin-top: 2px;">
                                            Controls bass+presence boost (proximity effect)
                                        </div>
                                    </div>
                                </div>
                                
                                <!-- Feature Toggles -->
                                <div style="margin-top: 12px; padding: 10px; background: var(--input-bg); border-radius: var(--radius-sm);">
                                    <div style="font-size: 10px; color: var(--text-muted); margin-bottom: 8px; text-transform: uppercase; letter-spacing: 0.5px;">Feature Overrides (auto by preset)</div>
                                    <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 8px;">
                                        <label class="checkbox-label" style="font-size: 11px;">
                                            <input type="checkbox" id="audio-8d-itd" checked>
                                            <span title="Interaural Time Difference - the ~0.7ms delay between ears for realism">üïê ITD (timing)</span>
                                        </label>
                                        <label class="checkbox-label" style="font-size: 11px;">
                                            <input type="checkbox" id="audio-8d-proximity" checked>
                                            <span title="Bass boost and presence when close - the 'in your ear' ASMR feel">üëÇ Proximity</span>
                                        </label>
                                        <label class="checkbox-label" style="font-size: 11px;">
                                            <input type="checkbox" id="audio-8d-crossfeed" checked>
                                            <span title="Natural bleed between ears - sounds more realistic than isolated headphones">üîÄ Crossfeed</span>
                                        </label>
                                        <label class="checkbox-label" style="font-size: 11px;">
                                            <input type="checkbox" id="audio-8d-micro-movements" checked>
                                            <span title="Subtle organic variation - prevents robotic/artificial feel">üåä Micro-moves</span>
                                        </label>
                                        <label class="checkbox-label" style="font-size: 11px; grid-column: span 2;">
                                            <input type="checkbox" id="audio-8d-speech-aware" checked>
                                            <span title="Transitions happen at natural speech pauses - prevents jarring mid-word ear swaps">üó£Ô∏è Speech-Aware Transitions</span>
                                        </label>
                                    </div>
                                </div>
                                
                                <!-- Mode Info -->
                                <div style="margin-top: 10px; padding: 8px; background: rgba(100,200,100,0.1); border-radius: var(--radius-sm); border-left: 3px solid #4CAF50;">
                                    <div style="font-size: 10px; color: #4CAF50; font-weight: 600; margin-bottom: 4px;">üéß Position Modes</div>
                                    <div style="font-size: 10px; color: var(--text-muted); line-height: 1.5;">
                                        <strong>Center:</strong> Stationary front position with full spatial quality<br>
                                        <strong>Ear Zones:</strong> Dwells at left/right ears (best for ASMR)<br>
                                        <strong>Sweep/Rotate:</strong> Continuous movement patterns<br>
                                        <strong>Static L/R:</strong> Fixed position at one ear
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                    </div>
                </div>

            </div>
        </div>

        <!-- Background Audio Tab -->
        <div id="tab-4" class="tab-content" role="tabpanel" aria-labelledby="tab-4">
            <div class="card-section">
                <div class="section-header">Background Audio</div>
                <p style="color: var(--text-muted); margin-bottom: 20px;">Add background audio tracks to mix with your generated speech. Adjust volume levels for each track.</p>
                
                <div class="form-group" style="margin-bottom: 14px; padding: 12px; background: var(--input-bg); border: 1px solid var(--border); border-radius: var(--radius-md);">
                    <label for="main-audio-file" class="label-with-help" style="margin-bottom: 10px;">
                        Main Audio File
                        <span class="help-icon" title="Select an audio file to blend with background tracks">?</span>
                    </label>
                    <div class="form-row" style="margin-bottom: 12px;">
                        <input type="file" id="main-audio-file" accept="audio/*" style="flex: 1; padding: 8px;" aria-label="Select main audio file">
                        <button class="btn btn-primary" onclick="blendBackgroundAudio()" id="blend-btn" aria-label="Blend audio with background tracks">
                            <span>üéµ</span> Blend Audio
                        </button>
                    </div>
                    <div id="main-audio-status" class="status" style="margin-top: 8px; min-height: 20px;"></div>
                </div>
                
                <button class="btn btn-secondary" onclick="addBgTrack()" style="margin-bottom: 16px;" aria-label="Add background track">
                    <span>‚ûï</span> Add BG Track
                </button>
                <div id="bg-tracks"></div>
                
                <audio id="blended-audio-player" class="audio-player" controls style="display: none; margin-top: 16px;" aria-label="Blended audio playback"></audio>
            </div>
        </div>

        <!-- Transcribe Tab -->
        <div id="tab-5" class="tab-content" role="tabpanel" aria-labelledby="tab-5">
            <div class="scrollable">
                <div class="card-section">
                    <div class="section-header">Speech-to-Text Transcription</div>
                    <p style="color: var(--text-muted); margin-bottom: 20px;">Transcribe audio using <strong>Whisper</strong> (OpenAI) or <strong>GLM-ASR</strong> (Z.ai). GLM-ASR excels at quiet/whispered speech and dialects like Cantonese. Supports WAV, MP3, FLAC, and other common formats.</p>
                    
                    <div class="form-group">
                        <label class="label-with-help">
                            Input Source
                            <span class="help-icon" title="Choose between file upload or microphone">?</span>
                        </label>
                        <div style="display: flex; gap: 12px; margin-bottom: 12px;">
                            <button class="btn btn-secondary" id="input-source-file-btn" onclick="setInputSource('file')" style="flex: 1;" aria-label="Use file input">
                                <span>üìÅ</span> File
                            </button>
                            <button class="btn btn-secondary" id="input-source-mic-btn" onclick="setInputSource('mic')" style="flex: 1; opacity: 0.6;" aria-label="Use microphone">
                                <span>üéôÔ∏è</span> Microphone
                            </button>
                        </div>
                    </div>
                    
                    <!-- File Input Section -->
                    <div id="file-input-section">
                        <div class="form-group">
                            <label for="transcribe-audio" class="label-with-help">
                                Audio File
                                <span class="help-icon" title="Select an audio file to transcribe">?</span>
                            </label>
                            <input type="file" id="transcribe-audio" accept="audio/*" class="file-input" aria-label="Select audio file for transcription">
                            <div class="input-hint">Supported: WAV, MP3, FLAC, OGG, M4A</div>
                        </div>
                        
                        <div id="transcribe-audio-preview" style="margin: 16px 0; display: none;">
                            <audio id="transcribe-audio-player" controls style="width: 100%;"></audio>
                        </div>
                    </div>
                    
                    <!-- Microphone Input Section -->
                    <div id="mic-input-section" style="display: none;">
                        <!-- Mode Selection -->
                        <div class="form-group" style="margin-bottom: 16px;">
                            <label class="label-with-help">
                                Microphone Mode
                                <span class="help-icon" title="Record & Transcribe: Record first, then transcribe. Live: Real-time transcription as you speak.">?</span>
                            </label>
                            <div class="button-group" style="display: flex; gap: 8px;">
                                <button class="btn btn-primary" id="mic-mode-record-btn" onclick="setMicMode('record')" style="flex: 1;">
                                    üéôÔ∏è Record & Transcribe
                                </button>
                                <button class="btn btn-outline" id="mic-mode-live-btn" onclick="setMicMode('live')" style="flex: 1;">
                                    ‚ö° Live Transcription
                                </button>
                            </div>
                        </div>
                        
                        <!-- Record Mode UI -->
                        <div id="mic-record-mode" class="form-group">
                            <label class="label-with-help">
                                Microphone Recording
                                <span class="help-icon" title="Record audio from your microphone for transcription">?</span>
                            </label>
                            
                            <div style="display: flex; gap: 12px; align-items: center; margin-bottom: 12px;">
                                <button class="btn btn-primary" id="mic-record-btn" onclick="toggleMicRecording()" style="min-width: 140px;" aria-label="Start/stop recording">
                                    <span id="mic-record-icon">üî¥</span> <span id="mic-record-text">Start Recording</span>
                                </button>
                                <div id="mic-recording-time" style="font-family: monospace; font-size: 18px; color: var(--text-muted);">00:00</div>
                            </div>
                            
                            <!-- Audio level visualization -->
                            <div id="mic-level-container" style="background: var(--bg-card); border: 1px solid var(--border); border-radius: 8px; padding: 12px; margin-bottom: 12px;">
                                <div style="display: flex; align-items: center; gap: 12px;">
                                    <span style="font-size: 12px; color: var(--text-muted);">Level:</span>
                                    <div style="flex: 1; background: var(--border); border-radius: 4px; height: 8px; overflow: hidden;">
                                        <div id="mic-level-bar" style="background: var(--accent); height: 100%; width: 0%; transition: width 0.05s;"></div>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="input-hint">Click "Start Recording" to begin. Recording will be transcribed when you stop.</div>
                        </div>
                        
                        <!-- Live Mode UI -->
                        <div id="mic-live-mode" class="form-group" style="display: none;">
                            <label class="label-with-help">
                                Live Transcription
                                <span class="help-icon" title="Real-time transcription - text appears as you speak!">?</span>
                            </label>
                            
                            <div style="display: flex; gap: 12px; align-items: center; margin-bottom: 12px;">
                                <button class="btn btn-primary" id="live-start-btn" onclick="toggleLiveTranscription()" style="min-width: 160px;" aria-label="Start/stop live transcription">
                                    <span id="live-btn-icon">‚ö°</span> <span id="live-btn-text">Start Live</span>
                                </button>
                                <div id="live-status" style="font-size: 12px; color: var(--text-muted);">
                                    <span id="live-status-text">Ready</span>
                                    <span id="live-status-dot" style="display: none; color: #28a745;">‚óè</span>
                                </div>
                            </div>
                            
                            <!-- Live audio level -->
                            <div style="background: var(--bg-card); border: 1px solid var(--border); border-radius: 8px; padding: 12px; margin-bottom: 12px;">
                                <div style="display: flex; align-items: center; gap: 12px;">
                                    <span style="font-size: 12px; color: var(--text-muted);">Level:</span>
                                    <div style="flex: 1; background: var(--border); border-radius: 4px; height: 8px; overflow: hidden;">
                                        <div id="live-level-bar" style="background: #28a745; height: 100%; width: 0%; transition: width 0.05s;"></div>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="input-hint">
                                üé§ Speak into your microphone - text appears in real-time!<br>
                                <small>Uses selected ASR model. Processes audio in ~3 second chunks.</small>
                            </div>
                        </div>
                        
                        <div id="mic-audio-preview" style="margin: 16px 0; display: none;">
                            <label style="font-size: 12px; color: var(--text-muted); margin-bottom: 8px; display: block;">Recorded Audio:</label>
                            <audio id="mic-audio-player" controls style="width: 100%;"></audio>
                        </div>
                    </div>
                    
                    <div class="form-group" style="margin-top: 16px;">
                        <label for="transcribe-device" class="label-with-help">
                            Device
                            <span class="help-icon" title="GPU requires CUDA, CPU works anywhere">?</span>
                        </label>
                        <select id="transcribe-device" aria-label="Device">
                            <option value="gpu">GPU</option>
                            <option value="cpu">CPU</option>
                        </select>
                    </div>
                    
                    <div class="form-group" style="margin-top: 8px;">
                        <label for="transcribe-model" class="label-with-help">
                            ASR Model
                            <span class="help-icon" title="Choose between Whisper (OpenAI) or GLM-ASR (Z.ai). GLM-ASR excels at low-volume/whisper speech and dialects.">?</span>
                        </label>
                        <select id="transcribe-model" aria-label="Model" onchange="updateModelHints()">
                            <optgroup label="üß† GLM-ASR (Z.ai)">
                                <option value="glm-asr-nano">GLM-ASR Nano (~3GB, best for quiet speech & dialects)</option>
                            </optgroup>
                            <optgroup label="üéôÔ∏è Whisper (OpenAI)">
                                <option value="whisper-large-v3-turbo" selected>Whisper Large V3 Turbo (~1.5GB, best speed/quality)</option>
                                <option value="whisper-large-v3">Whisper Large V3 (~3GB, highest quality)</option>
                                <option value="whisper-medium">Whisper Medium (~1.5GB)</option>
                                <option value="whisper-small">Whisper Small (~0.5GB, fast)</option>
                            </optgroup>
                        </select>
                        <div class="input-hint" id="model-hint">Whisper: Best general-purpose ASR. GLM-ASR: Excels at whispered/quiet speech and Cantonese dialect.</div>
                    </div>
                    
                    <div class="form-group" style="margin-top: 8px;" id="transcribe-language-group">
                        <label for="transcribe-language" class="label-with-help">
                            Language
                            <span class="help-icon" title="Audio language. Auto-detect works with Whisper. GLM-ASR excels at Chinese (including Cantonese) and English.">?</span>
                        </label>
                        <select id="transcribe-language" aria-label="Language">
                            <option value="auto">Auto-detect (Whisper only)</option>
                            <option value="en" selected>English</option>
                            <option value="es">Spanish</option>
                            <option value="fr">French</option>
                            <option value="de">German</option>
                            <option value="it">Italian</option>
                            <option value="pt">Portuguese</option>
                            <option value="nl">Dutch</option>
                            <option value="pl">Polish</option>
                            <option value="ru">Russian</option>
                            <option value="zh">Chinese (Mandarin)</option>
                            <option value="yue">Cantonese (Á≤§ËØ≠) - GLM-ASR recommended</option>
                            <option value="ja">Japanese</option>
                            <option value="ko">Korean</option>
                            <option value="ar">Arabic</option>
                            <option value="hi">Hindi</option>
                            <option value="tr">Turkish</option>
                            <option value="vi">Vietnamese</option>
                            <option value="th">Thai</option>
                            <option value="id">Indonesian</option>
                            <option value="uk">Ukrainian</option>
                            <option value="cs">Czech</option>
                            <option value="sv">Swedish</option>
                            <option value="da">Danish</option>
                            <option value="fi">Finnish</option>
                            <option value="no">Norwegian</option>
                            <option value="el">Greek</option>
                            <option value="he">Hebrew</option>
                            <option value="hu">Hungarian</option>
                            <option value="ro">Romanian</option>
                        </select>
                        <div class="input-hint" id="language-hint">Whisper: 90+ languages with auto-detect. GLM-ASR: Optimized for English, Mandarin, and Cantonese.</div>
                    </div>
                    
                    <div class="form-group" style="margin-top: 8px;">
                        <label for="transcribe-endpoint" class="label-with-help">
                            Endpoint
                            <span class="help-icon" title="Batch waits for result, Streaming shows progress">?</span>
                        </label>
                        <select id="transcribe-endpoint" aria-label="Endpoint">
                            <option value="batch">Batch</option>
                            <option value="streaming">Streaming</option>
                        </select>
                    </div>
                    
                    <div class="checkbox-group" style="margin-top: 16px;">
                        <label class="checkbox-label">
                            <input type="checkbox" id="clean-vocals" aria-label="Clean vocals before transcription">
                            <span>Clean Vocals (remove background music/noise)</span>
                        </label>
                        <div class="input-hint" style="margin-left: 24px;">Uses HP5_only_main_vocal model to extract speech before transcription. Improves accuracy for audio with music or noise.</div>
                    </div>
                    
                    <div class="checkbox-group" style="margin-top: 8px;">
                        <label class="checkbox-label">
                            <input type="checkbox" id="postprocess-audio" aria-label="Enhance audio before transcription">
                            <span>Enhance Audio (post-process before transcription)</span>
                        </label>
                        <div class="input-hint" style="margin-left: 24px;">Applies highpass filter, de-essing, and cleanup to improve speech clarity. Requires Audio Services server.</div>
                    </div>
                    
                    <div class="checkbox-group" style="margin-top: 8px;">
                        <label class="checkbox-label">
                            <input type="checkbox" id="skip-existing-vocals" checked aria-label="Skip if vocals already extracted">
                            <span>Skip Vocal Separation if Already Done</span>
                        </label>
                        <div class="input-hint" style="margin-left: 24px;">Reuse previously extracted vocals from output folder instead of reprocessing.</div>
                    </div>
                    
                    <button class="btn btn-primary" onclick="transcribeAudio()" style="margin-top: 16px;" id="transcribe-btn" aria-label="Transcribe audio">
                        <span>üé§</span> Transcribe Audio
                    </button>
                    
                    <div id="transcribe-status" style="margin-top: 16px; color: var(--text-muted); display: none;">
                        <span class="loading-spinner"></span> <span id="transcribe-status-text">Transcribing...</span>
                        <div id="transcribe-progress" style="margin-top: 8px; display: none;">
                            <div style="background: var(--border); border-radius: 4px; height: 8px; overflow: hidden;">
                                <div id="transcribe-progress-bar" style="background: var(--accent); height: 100%; width: 0%; transition: width 0.3s;"></div>
                            </div>
                            <div id="transcribe-segment-info" style="font-size: 12px; margin-top: 4px;"></div>
                        </div>
                    </div>
                    
                    <div class="form-group" style="margin-top: 24px;">
                        <label for="transcription-output" class="label-with-help">
                            Transcription Result
                            <span class="help-icon" title="The transcribed text will appear here">?</span>
                        </label>
                        <textarea id="transcription-output" rows="10" style="width: 100%; padding: 12px; border-radius: 8px; background: var(--bg-card); border: 1px solid var(--border); color: var(--text-primary); font-family: inherit; resize: vertical;" readonly placeholder="Transcription will appear here..."></textarea>
                    </div>
                    
                    <div style="display: flex; gap: 12px; margin-top: 16px;">
                        <button class="btn btn-secondary" onclick="copyTranscription()" id="copy-transcription-btn" disabled aria-label="Copy transcription">
                            <span>üìã</span> Copy to Clipboard
                        </button>
                        <button class="btn btn-secondary" onclick="useTranscriptionAsTTS()" id="use-for-tts-btn" disabled aria-label="Use transcription for TTS">
                            <span>üîä</span> Use for TTS
                        </button>
                    </div>
                    
                    <div id="transcription-saved" style="margin-top: 16px; color: var(--accent); display: none;">
                        ‚úì Saved to: <span id="transcription-filename"></span>
                    </div>
                </div>
            </div>
        </div>

        <!-- ComfyUI Tab -->
        <div id="tab-6" class="tab-content" role="tabpanel" aria-labelledby="tab-6">
            <div class="scrollable">
                <!-- Connection Status -->
                <div class="card-section">
                    <div class="section-header">ComfyUI Connection</div>
                    <div class="form-group">
                        <label for="comfyui-url" class="label-with-help">
                            Server URL
                            <span class="help-icon" title="ComfyUI server address (default: http://127.0.0.1:8188)">?</span>
                        </label>
                        <div class="form-row">
                            <input type="text" id="comfyui-url" value="http://127.0.0.1:8188" placeholder="http://127.0.0.1:8188" style="flex: 1;" aria-label="ComfyUI server URL">
                            <button class="btn btn-primary" onclick="testComfyUIConnection()" id="comfyui-connect-btn" aria-label="Test connection">
                                <span>üîå</span> Connect
                            </button>
                        </div>
                        <div style="margin-top: 8px;">
                            <label for="comfyui-path" style="font-size: 11px; color: var(--text-muted);">
                                ComfyUI Path (optional - for browsing file system workflows)
                            </label>
                            <div class="form-row" style="margin-top: 4px;">
                                <input type="text" id="comfyui-path" placeholder="C:\ComfyUI or /path/to/ComfyUI" style="font-size: 12px; flex: 1;" aria-label="ComfyUI installation path">
                                <button class="btn btn-secondary" onclick="launchComfyUI()" id="launch-comfyui-btn" title="Launch ComfyUI server">
                                    <span>üöÄ</span> Launch
                                </button>
                            </div>
                        </div>
                    </div>
                    
                    
                    <div id="comfyui-status" class="status" style="margin-top: 12px;">
                        Not connected. Click Connect to test the connection.
                    </div>
                    
                    <div id="comfyui-info" style="display: none; margin-top: 16px; padding: 12px; background: var(--input-bg); border-radius: var(--radius-md); border: 1px solid var(--border);">
                        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 12px;">
                            <div>
                                <div style="color: var(--text-muted); font-size: 12px;">Status</div>
                                <div id="comfyui-connection-status" style="font-weight: 600;">-</div>
                            </div>
                            <div>
                                <div style="color: var(--text-muted); font-size: 12px;">Available Nodes</div>
                                <div id="comfyui-node-count">-</div>
                            </div>
                            <div>
                                <div style="color: var(--text-muted); font-size: 12px;">Queue</div>
                                <div id="comfyui-queue-status">-</div>
                            </div>
                            <div>
                                <div style="color: var(--text-muted); font-size: 12px;">VRAM Usage</div>
                                <div id="comfyui-vram">-</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Workflows -->
                <div class="card-section" style="margin-top: 12px;">
                    <div class="section-header">Workflows</div>
                    <p style="color: var(--text-muted); margin-bottom: 10px; font-size: 12px;">Load and execute ComfyUI workflows. Upload workflow JSON files or use the ones in the workflows folder.</p>
                    
                    <div class="form-row" style="margin-bottom: 12px;">
                        <button class="btn btn-secondary" onclick="refreshComfyUIWorkflows()" id="refresh-workflows-btn" aria-label="Refresh workflow list">
                            <span>üîÑ</span> Refresh
                        </button>
                        <label class="btn btn-secondary" style="cursor: pointer;">
                            <span>üì§</span> Upload Workflow
                            <input type="file" id="comfyui-workflow-upload" accept=".json" style="display: none;" onchange="uploadComfyUIWorkflow(this)">
                        </label>
                    </div>
                    
                    <div id="comfyui-workflows-list" style="display: flex; flex-direction: column; gap: 8px;">
                        <div style="color: var(--text-muted); padding: 20px; text-align: center;">
                            Click Refresh to load workflows
                        </div>
                    </div>
                </div>

                <!-- Workflow Execution -->
                <div class="card-section" id="comfyui-execution-section" style="margin-top: 12px; display: none;">
                    <div class="section-header">Execute Workflow</div>
                    <div id="comfyui-workflow-name" style="color: var(--accent); font-weight: 600; margin-bottom: 10px; font-size: 12px;"></div>
                    
                    <div id="comfyui-workflow-inputs" style="margin-bottom: 12px;">
                        <!-- Dynamic inputs will be added here -->
                    </div>
                    
                    <button class="btn btn-primary" onclick="executeComfyUIWorkflow()" id="execute-workflow-btn" style="width: 100%;" aria-label="Execute workflow">
                        <span>‚ñ∂Ô∏è</span> Execute Workflow
                    </button>
                    
                    <div id="comfyui-execution-status" class="status" style="margin-top: 12px; display: none;"></div>
                    
                    <div id="comfyui-result" style="margin-top: 16px; display: none;">
                        <div style="color: var(--text-muted); font-size: 12px; margin-bottom: 8px;">Result:</div>
                        <div id="comfyui-result-images" style="display: flex; flex-wrap: wrap; gap: 8px;"></div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Preprocess Tab (UVR5) -->
        <div id="tab-2" class="tab-content" role="tabpanel" aria-labelledby="tab-2">
            <div class="scrollable">
                <div class="card-section">
                    <div class="section-header">Audio Preprocessing with UVR5</div>
                    <p style="color: var(--text-muted); margin-bottom: 20px;">Clean up audio files using neural network models - remove background music, echo, reverb, or isolate vocals.</p>
                    
                    <div class="form-group">
                        <label for="uvr5-audio-input" class="label-with-help">
                            Input Audio File
                            <span class="help-icon" title="Select an audio file to process. Supports WAV, MP3, FLAC, etc.">?</span>
                        </label>
                        <input type="file" id="uvr5-audio-input" accept="audio/*" style="padding: 8px;" aria-label="Select audio file for preprocessing">
                    </div>
                    
                    <div class="form-group" style="margin-top: 16px;">
                        <label for="uvr5-model" class="label-with-help">
                            Processing Model
                            <span class="help-icon" title="Choose the model based on what you want to remove from the audio">?</span>
                        </label>
                        <select id="uvr5-model" style="width: 100%; padding: 10px;">
                            <option value="hp5_vocals">üé§ HP5 Vocals - Isolate vocals from music/background</option>
                            <option value="deecho_normal">üîä DeEcho Normal - Standard echo removal (preserves quality)</option>
                            <option value="deecho_aggressive">üîä DeEcho Aggressive - Stronger echo/delay removal</option>
                            <option value="deecho_dereverb">üîä DeEcho + DeReverb - Remove echo AND reverb together</option>
                        </select>
                        <div class="input-hint" style="margin-top: 8px;">
                            HP5: Best for removing music/instrumentals. DeEcho: Best for cleaning recorded speech/podcasts.
                        </div>
                    </div>
                    
                    <div class="form-group" style="margin-top: 16px;">
                        <label for="uvr5-aggression" class="label-with-help">
                            Processing Aggressiveness
                            <span class="help-icon" title="How aggressively to process. Higher = more aggressive removal, but may affect audio quality. Default: 10">?</span>
                        </label>
                        <div class="form-row" style="align-items: center; gap: 12px;">
                            <input type="range" id="uvr5-aggression" min="0" max="20" value="10" style="flex: 1;" oninput="document.getElementById('uvr5-aggression-value').textContent = this.value">
                            <span id="uvr5-aggression-value" style="min-width: 30px; text-align: right; font-weight: 600;">10</span>
                        </div>
                        <div class="input-hint" style="margin-top: 8px;">0 = gentle (preserves more) | 10 = balanced | 20 = aggressive (cleaner output)</div>
                    </div>
                    
                    <div class="form-group" style="margin-top: 16px;">
                        <label class="label-with-help">
                            Options
                            <span class="help-icon" title="Additional processing options">?</span>
                        </label>
                        <div class="form-row" style="gap: 16px; align-items: center; flex-wrap: wrap;">
                            <label style="display: flex; align-items: center; gap: 8px; cursor: pointer;">
                                <input type="checkbox" id="uvr5-skip-cache">
                                <span>Force reprocess (skip cache)</span>
                            </label>
                        </div>
                    </div>
                    
                    <button class="btn btn-primary" onclick="processUVR5()" id="uvr5-process-btn" style="width: 100%; margin-top: 20px;" aria-label="Process audio with UVR5">
                        <span>üéµ</span> Process Audio
                    </button>
                    
                    <div id="uvr5-progress-bar" class="progress-bar" style="display: none; margin-top: 16px;">
                        <div id="uvr5-progress-fill" class="progress-fill">0%</div>
                    </div>
                    
                    <div id="uvr5-status" class="status" style="margin-top: 12px; min-height: 20px;"></div>
                </div>
                
                <!-- Results Section -->
                <div class="card-section" style="margin-top: 20px;">
                    <div class="section-header">Processed Audio</div>
                    
                    <div id="uvr5-vocals-result" style="display: none; margin-bottom: 16px;">
                        <label style="font-weight: 600; color: var(--text); margin-bottom: 8px; display: block;">Processed Output:</label>
                        <audio id="uvr5-vocals-player" class="audio-player" controls style="width: 100%;"></audio>
                        <button class="btn btn-secondary" onclick="downloadUVR5Audio()" style="margin-top: 8px;">
                            <span>üíæ</span> Download
                        </button>
                    </div>
                    
                    <div id="uvr5-no-results" style="color: var(--text-muted); font-style: italic;">
                        No processed audio yet. Select a file and click "Process Audio" to start.
                    </div>
                </div>
                
                <!-- Memory Management -->
                <div class="card-section" style="margin-top: 20px;">
                    <div class="section-header">Memory Management</div>
                    <p style="color: var(--text-muted); margin-bottom: 12px;">The UVR5 model uses ~2GB VRAM. Unload it when not in use to free GPU memory for other tasks.</p>
                    <button class="btn btn-secondary" onclick="unloadUVR5()" aria-label="Unload UVR5 model from GPU">
                        <span>üóëÔ∏è</span> Unload UVR5 Model
                    </button>
                </div>
            </div>
        </div>

        <!-- Training Tab -->
        <div id="tab-7" class="tab-content" role="tabpanel" aria-labelledby="tab-7">
            <div class="scrollable">
                <!-- Training Backend Selection -->
                <div class="card-section">
                    <div class="section-header">TTS Model Training</div>
                    <p style="color: var(--text-muted); margin-bottom: 16px;">
                        Fine-tune TTS models with your own voice data. Create custom voices for Soprano or Chatterbox.
                    </p>
                    
                    <div class="form-group">
                        <label>Training Backend</label>
                        <select id="training-backend" class="form-control" onchange="updateTrainingUI()">
                            <option value="soprano">Soprano (Fast, lightweight)</option>
                            <option value="chatterbox">Chatterbox (Voice cloning)</option>
                        </select>
                        <div class="input-hint" id="training-backend-hint">Soprano: 80M params, very fast. Chatterbox: Full voice cloning with audio prompts.</div>
                    </div>
                </div>
                
                <!-- Dataset Section -->
                <div class="card-section" style="margin-top: 20px;">
                    <div class="section-header">Dataset</div>
                    
                    <!-- Dataset Mode Toggle -->
                    <div class="form-group">
                        <label>Dataset Mode</label>
                        <div class="form-row" style="gap: 10px;">
                            <button class="btn btn-secondary dataset-mode-btn active" onclick="setDatasetMode('simple')" id="dataset-mode-simple">Simple (Folder)</button>
                            <button class="btn btn-secondary dataset-mode-btn" onclick="setDatasetMode('advanced')" id="dataset-mode-advanced">Advanced (Prepare)</button>
                        </div>
                    </div>
                    
                    <!-- Simple Mode: Folder Selection -->
                    <div id="dataset-simple-mode">
                        <div class="form-group">
                            <label>Dataset Path</label>
                            <div class="form-row" style="gap: 10px;">
                                <input type="text" id="training-dataset-path" class="form-control" placeholder="Path to LJSpeech format dataset folder" style="flex: 1;">
                                <button class="btn btn-secondary" onclick="browseDatasetFolder()">Browse</button>
                                <button class="btn btn-secondary" onclick="validateDataset()">Validate</button>
                            </div>
                            <div class="input-hint">Expected format: folder with metadata.csv and wavs/ directory</div>
                        </div>
                        
                        <!-- Dataset Validation Status -->
                        <div id="dataset-validation-status" style="display: none; padding: 12px; border-radius: 8px; margin-top: 12px;">
                            <div id="dataset-validation-message"></div>
                        </div>
                    </div>
                    
                    <!-- Advanced Mode: Dataset Preparation -->
                    <div id="dataset-advanced-mode" style="display: none;">
                        <div class="form-group">
                            <label>Create New Dataset</label>
                            <div class="form-row" style="gap: 10px;">
                                <input type="text" id="new-dataset-name" class="form-control" placeholder="Dataset name" style="flex: 1;">
                                <button class="btn btn-primary" onclick="createNewDataset()">Create</button>
                            </div>
                        </div>
                        
                        <div class="form-group">
                            <label>Existing Datasets</label>
                            <div class="form-row" style="gap: 10px;">
                                <select id="training-dataset-select" class="form-control" onchange="selectDataset()" style="flex: 1;">
                                    <option value="">-- Select dataset --</option>
                                </select>
                                <button class="btn btn-danger" onclick="deleteSelectedDataset()" title="Delete selected dataset">Delete</button>
                            </div>
                        </div>
                        
                        <!-- Upload Audio -->
                        <div class="form-group" id="dataset-upload-section" style="display: none;">
                            <label>Upload Audio Files</label>
                            <div class="upload-area" id="training-upload-area" ondrop="handleTrainingDrop(event)" ondragover="event.preventDefault()">
                                <input type="file" id="training-audio-files" multiple accept="audio/*,video/*" onchange="handleTrainingUpload(event)" style="display: none;">
                                <p>Drag & drop audio/video files or <a href="#" onclick="document.getElementById('training-audio-files').click(); return false;">browse</a></p>
                                <p style="color: var(--text-muted); font-size: 12px;">Supported: WAV, MP3, FLAC, MP4, etc.</p>
                            </div>
                        </div>
                        
                        <!-- Uploaded Files List -->
                        <div id="training-files-list" style="display: none; margin-top: 12px;">
                            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 8px;">
                                <label style="margin: 0;">Uploaded Files <span id="training-files-count" style="color: var(--text-muted);"></span></label>
                                <button class="btn btn-secondary" onclick="refreshDatasetFiles()" style="padding: 4px 12px; font-size: 12px;">Refresh</button>
                            </div>
                            <div id="training-files-container" style="max-height: 200px; overflow-y: auto; border: 1px solid var(--border); border-radius: 8px; padding: 8px;"></div>
                            
                            <div class="input-hint" style="margin: 12px 0 8px 0;">
                                <strong>Workflow:</strong> Long audio? Click <em>Segment</em> first to split into 3-10s clips, then <em>Transcribe</em>. Already short clips? Just <em>Transcribe</em>.
                            </div>
                            <div class="form-row" style="gap: 10px;">
                                <button class="btn btn-secondary" onclick="segmentDataset()">1. Segment Long Audio (VAD)</button>
                                <button class="btn btn-secondary" onclick="transcribeDataset()">2. Transcribe All (ASR)</button>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Soprano Training Config -->
                <div class="card-section" style="margin-top: 20px;" id="soprano-training-config">
                    <div class="section-header">Soprano Training Configuration</div>
                    
                    <div class="form-group">
                        <label>Model Name</label>
                        <input type="text" id="soprano-model-name" class="form-control" placeholder="my_custom_voice" value="my_soprano_voice">
                        <div class="input-hint">Name for the output model (used in TTS backend selection)</div>
                    </div>
                    
                    <div class="form-row" style="gap: 20px;">
                        <div class="form-group" style="flex: 1;">
                            <label>Epochs</label>
                            <input type="number" id="soprano-epochs" class="form-control" value="20" min="1" max="1000">
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>Learning Rate</label>
                            <input type="text" id="soprano-lr" class="form-control" value="5e-5" placeholder="e.g. 1e-4, 5e-5">
                            <div class="input-hint">Scientific notation (e.g. 5e-5 = 0.00005)</div>
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>Batch Size</label>
                            <input type="number" id="soprano-batch-size" class="form-control" value="4" min="1" max="32">
                        </div>
                    </div>
                    
                    <div class="form-row" style="gap: 20px;">
                        <div class="form-group" style="flex: 1;">
                            <label>Save Every N Epochs</label>
                            <input type="number" id="soprano-save-every" class="form-control" value="10" min="1" max="100">
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>Warmup Steps</label>
                            <input type="number" id="soprano-warmup" class="form-control" value="100" min="0" max="1000">
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>Gradient Accumulation</label>
                            <input type="number" id="soprano-grad-accum" class="form-control" value="1" min="1" max="64">
                        </div>
                    </div>
                    
                    <!-- LoRA Settings -->
                    <div class="form-group" style="margin-top: 15px;">
                        <label class="toggle-label">
                            <input type="checkbox" id="soprano-use-lora" checked>
                            <span>Use LoRA (Recommended)</span>
                            <span class="help-icon" title="LoRA preserves voice quality by only training ~2% of parameters. Highly recommended for fine-tuning.">?</span>
                        </label>
                    </div>
                    
                    <div class="form-row" style="gap: 20px;" id="soprano-lora-settings">
                        <div class="form-group" style="flex: 1;">
                            <label>LoRA Rank</label>
                            <input type="number" id="soprano-lora-rank" class="form-control" value="32" min="4" max="256" step="4">
                            <div class="input-hint">Higher = more capacity (16-64 typical)</div>
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>LoRA Alpha</label>
                            <input type="number" id="soprano-lora-alpha" class="form-control" value="64" min="4" max="512" step="4">
                            <div class="input-hint">Usually 2x rank</div>
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>LoRA Dropout</label>
                            <input type="number" id="soprano-lora-dropout" class="form-control" value="0.05" min="0" max="0.5" step="0.01">
                        </div>
                    </div>
                </div>
                
                <!-- Chatterbox Training Config -->
                <div class="card-section" style="margin-top: 20px; display: none;" id="chatterbox-training-config">
                    <div class="section-header">Chatterbox Training Configuration</div>
                    
                    <div class="form-group">
                        <label>Model Name</label>
                        <input type="text" id="chatterbox-model-name" class="form-control" placeholder="my_custom_voice" value="my_chatterbox_voice">
                        <div class="input-hint">Name for the output model</div>
                    </div>
                    
                    <div class="form-group">
                        <label>Mode</label>
                        <div class="form-row" style="gap: 10px;">
                            <label class="toggle-label">
                                <input type="checkbox" id="chatterbox-turbo-mode" checked>
                                <span>Turbo Mode (GPT-2, faster)</span>
                            </label>
                        </div>
                        <div class="input-hint">Turbo: GPT-2 based, faster. Standard: Llama based, more expressive.</div>
                    </div>
                    
                    <div class="form-row" style="gap: 20px;">
                        <div class="form-group" style="flex: 1;">
                            <label>Epochs</label>
                            <input type="number" id="chatterbox-epochs" class="form-control" value="150" min="1" max="1000">
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>Learning Rate</label>
                            <input type="text" id="chatterbox-lr" class="form-control" value="5e-5" placeholder="e.g. 5e-5">
                            <div class="input-hint">Scientific notation (e.g. 5e-5)</div>
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>Batch Size</label>
                            <input type="number" id="chatterbox-batch-size" class="form-control" value="4" min="1" max="32">
                        </div>
                    </div>
                    
                    <div class="form-row" style="gap: 20px;">
                        <div class="form-group" style="flex: 1;">
                            <label>Gradient Accumulation</label>
                            <input type="number" id="chatterbox-grad-accum" class="form-control" value="8" min="1" max="64">
                        </div>
                        <div class="form-group" style="flex: 1;">
                            <label>
                                <input type="checkbox" id="chatterbox-preprocess" checked>
                                Run Preprocessing
                            </label>
                            <div class="input-hint">Extract embeddings before training (required first time)</div>
                        </div>
                    </div>
                    
                    <div class="form-group">
                        <label>Speaker Reference Audio (Optional)</label>
                        <div class="form-row" style="gap: 10px;">
                            <input type="text" id="chatterbox-speaker-ref" class="form-control" placeholder="Path to reference audio for voice cloning" style="flex: 1;">
                            <button class="btn btn-secondary" onclick="browseSpeakerRef()">Browse</button>
                        </div>
                        <div class="input-hint">3-10 second clean audio sample of the target voice</div>
                    </div>
                </div>
                
                <!-- Training Controls -->
                <div class="card-section" style="margin-top: 20px;">
                    <div class="section-header">Training Control</div>
                    
                    <div class="form-row" style="gap: 10px;">
                        <button class="btn btn-primary" onclick="startTraining()" id="start-training-btn">Start Training</button>
                        <button class="btn btn-secondary" onclick="cancelTraining()" id="cancel-training-btn" disabled>Cancel</button>
                    </div>
                    
                    <!-- Progress Section -->
                    <div id="training-progress-section" style="display: none; margin-top: 20px;">
                        <div class="form-group">
                            <label>Training Progress</label>
                            <div class="progress-bar-container" style="background: var(--bg-tertiary); border-radius: 8px; height: 24px; overflow: hidden;">
                                <div id="training-progress-bar" style="background: var(--primary); height: 100%; width: 0%; transition: width 0.3s;"></div>
                            </div>
                            <div id="training-progress-text" style="text-align: center; margin-top: 8px; color: var(--text-muted);">
                                Ready to start
                            </div>
                        </div>
                        
                        <div class="form-row" style="gap: 20px; margin-top: 12px;">
                            <div style="flex: 1; text-align: center;">
                                <div id="training-step-label" style="color: var(--text-muted); font-size: 12px;">Step</div>
                                <div id="training-epoch" style="font-size: 24px; font-weight: bold;">-</div>
                            </div>
                            <div style="flex: 1; text-align: center;">
                                <div style="color: var(--text-muted); font-size: 12px;">Loss</div>
                                <div id="training-loss" style="font-size: 24px; font-weight: bold;">-</div>
                            </div>
                            <div style="flex: 1; text-align: center;">
                                <div style="color: var(--text-muted); font-size: 12px;">ETA</div>
                                <div id="training-eta" style="font-size: 24px; font-weight: bold;">-</div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Training Log -->
                    <div class="form-group" style="margin-top: 20px;">
                        <label>Training Log</label>
                        <div id="training-log" style="background: var(--bg-tertiary); border-radius: 8px; padding: 12px; max-height: 300px; overflow-y: auto; font-family: monospace; font-size: 12px; color: var(--text-muted);">
                            Waiting for training to start...
                        </div>
                    </div>
                </div>
                
                <!-- Trained Models -->
                <div class="card-section" style="margin-top: 20px;">
                    <div class="section-header">Trained Models</div>
                    
                    <div class="form-group">
                        <label>Custom Soprano Models</label>
                        <div id="soprano-models-list" style="color: var(--text-muted);">
                            No custom Soprano models found.
                        </div>
                    </div>
                    
                    <div class="form-group">
                        <label>Custom Chatterbox Models</label>
                        <div id="chatterbox-models-list" style="color: var(--text-muted);">
                            No custom Chatterbox models found.
                        </div>
                    </div>
                    
                    <button class="btn btn-secondary" onclick="refreshTrainedModels()" style="margin-top: 12px;">Refresh Models</button>
                </div>
            </div>
        </div>
    </div>

    <div class="toast" id="toast" role="alert" aria-live="assertive"></div>

    <div class="help-modal" id="help-modal" onclick="closeHelp(event)" role="dialog" aria-labelledby="help-title" aria-modal="true">
        <div class="help-content" onclick="event.stopPropagation()">
            <h2 id="help-title" style="margin-bottom: 12px; font-size: 18px;">Quick Tips & Keyboard Shortcuts</h2>
            <ul style="line-height: 2;">
                <li><b>Ctrl+O</b> to load a .txt script</li>
                <li><b>Ctrl+G</b> to generate speech</li>
                <li>Set an <b>RVC Model</b> first (tab: RVC)</li>
                <li>Add <b>Background Tracks</b> and volumes in the Background Audio tab</li>
                <li>All settings are auto-saved to your config file</li>
                <li>ASMR/Hypnosis enhancements: Air uses proper highshelf with width control</li>
                <li>Hover over <b>?</b> icons for parameter descriptions</li>
                <li>Use custom voice combinations by adding them with the "Add Combo" button</li>
            </ul>
            <button class="btn btn-primary" onclick="closeHelp()" style="margin-top: 24px; width: 100%;" aria-label="Close help dialog">Close</button>
        </div>
    </div>

    <input type="file" id="script-file" accept=".txt" style="display: none;" onchange="handleScriptUpload(event)" aria-label="Upload script file">

    <script>
        // =================================================================
        // CONFIG - Simple load/save from config.json
        // =================================================================
        let config = {};
        let configLoading = false;
        
        // Generation abort handling
        let currentAbortController = null;
        let currentAudioContext = null;
        let currentRequestId = null;  // Server-side request ID for cancellation
        let isGenerating = false;
        
        function getElementValue(id) {
            const el = document.getElementById(id);
            return el ? el.value : '';
        }
        
        function getFloatValue(id, defaultVal) {
            const el = document.getElementById(id);
            if (!el || el.value === '') return defaultVal;
            const val = parseFloat(el.value);
            return isNaN(val) ? defaultVal : val;
        }
        
        function getIntValue(id, defaultVal) {
            const el = document.getElementById(id);
            if (!el || el.value === '') return defaultVal;
            const val = parseInt(el.value, 10);
            return isNaN(val) ? defaultVal : val;
        }
        
        function getElementChecked(id) {
            const el = document.getElementById(id);
            return el ? el.checked : false;
        }
        
        async function loadSettings() {
            configLoading = true;
            try {
                const res = await fetch('/api/config');
                if (res.ok) {
                    config = await res.json();
                    applySettings(config);
                    setTimeout(() => applySettings(config), 300);
                }
            } catch(e) { console.error('Load config failed:', e); }
            finally { configLoading = false; }
        }
        
        function applySettings(cfg) {
            if (!cfg) return;
            document.querySelectorAll('input, select').forEach(el => {
                if (!el.id) return;
                const key = el.id.replace(/-/g, '_');
                if (!(key in cfg)) return;
                if (el.type === 'checkbox') el.checked = Boolean(cfg[key]);
                else if (el.tagName === 'SELECT') {
                    if ([...el.options].some(o => o.value === String(cfg[key]))) el.value = cfg[key];
                } else el.value = cfg[key];
                
                // For range inputs, also update the associated value display span
                if (el.type === 'range') {
                    let valueSpan = document.getElementById(el.id + '-value');
                    // Handle special spatial audio display spans
                    if (!valueSpan) {
                        const specialMappings = {
                            'audio-8d-speed': 'speed-display',
                            'audio-8d-depth': 'depth-display',
                            'audio-8d-distance': 'distance-display'
                        };
                        if (specialMappings[el.id]) {
                            valueSpan = document.getElementById(specialMappings[el.id]);
                        }
                    }
                    if (valueSpan) valueSpan.textContent = el.value;
                }
            });
            if (cfg.chatterbox_prompt_path) window.lastChatterboxPromptPath = cfg.chatterbox_prompt_path;
            if (cfg.chatterbox_prompt_filename) {
                window.lastChatterboxPromptFilename = cfg.chatterbox_prompt_filename;
                // Show the saved prompt audio in the hint
                const hint = document.getElementById('chatterbox-prompt-hint');
                if (hint) {
                    hint.textContent = `Using saved: ${cfg.chatterbox_prompt_filename}`;
                    hint.style.display = 'block';
                    hint.style.color = 'var(--success, #28a745)';
                }
            }
            
            // Restore background tracks
            if (cfg.bg_tracks && Array.isArray(cfg.bg_tracks) && cfg.bg_tracks.length > 0) {
                // Clear existing tracks
                const tracksDiv = document.getElementById('bg-tracks');
                if (tracksDiv) {
                    tracksDiv.innerHTML = '';
                    window.bgTrackCount = 0;
                }
                
                // Add saved tracks
                cfg.bg_tracks.forEach(track => {
                    if (track && (track.file || track.volume)) {
                        addBgTrack(track.file || '', track.volume || 0, track.delay || 0, track.fade_in || 0, track.fade_out || 0);
                    }
                });
            }
            
            // Trigger change events for checkboxes that control visibility
            const spatialCheckbox = document.getElementById('audio-8d-enabled');
            if (spatialCheckbox) spatialCheckbox.dispatchEvent(new Event('change'));
            
            // Trigger ASMR mode checkbox too
            const asmrCheckbox = document.getElementById('asmr-enabled');
            if (asmrCheckbox) asmrCheckbox.dispatchEvent(new Event('change'));
            
            // Update spatial mode dropdown (may hide/show speed slider)
            const spatialMode = document.getElementById('audio-8d-mode');
            if (spatialMode) spatialMode.dispatchEvent(new Event('change'));
        }
        
        async function saveSettings() {
            if (configLoading) return;
            const data = {};
            document.querySelectorAll('input, select').forEach(el => {
                if (!el.id || el.type === 'file') return;
                if (['text-input', 'script-select'].includes(el.id)) return;
                const key = el.id.replace(/-/g, '_');
                if (el.type === 'checkbox') data[key] = el.checked;
                else if (el.type === 'number' || el.type === 'range') {
                    const v = parseFloat(el.value); if (!isNaN(v)) data[key] = v;
                } else if (el.value) data[key] = el.value;
            });
            if (typeof getBgTracks === 'function') data.bg_tracks = getBgTracks();
            if (window.lastChatterboxPromptPath) data.chatterbox_prompt_path = window.lastChatterboxPromptPath;
            if (window.lastChatterboxPromptFilename) data.chatterbox_prompt_filename = window.lastChatterboxPromptFilename;
            config = data;
            try { await fetch('/api/config', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify(data)}); }
            catch(e) { console.error('Save failed:', e); }
        }
        
        function collectTTSRequest() {
            const text = document.getElementById('text-input')?.value.trim() || '';
            const ttsBackend = getElementValue('tts-backend') || 'chatterbox';
            const chatterboxModel = ttsBackend === 'chatterbox' ? (getElementValue('chatterbox-model') || null) : null;
            const sopranoModel = ttsBackend === 'soprano' ? (getElementValue('soprano-model') || null) : null;
            return {
                input: text,
                rvc_model: getElementChecked('enable-rvc') ? getElementValue('model-select') : null,
                enable_rvc: getElementChecked('enable-rvc'),
                enable_post: getElementChecked('enable-post'),
                enable_background: getElementChecked('enable-background'),
                tts_mode: getElementValue('tts-mode') || 'chunked',
                tts_backend: ttsBackend,
                chatterbox_model: chatterboxModel,
                soprano_model: sopranoModel,
                tts_batch_tokens: parseInt(getElementValue('tts-batch-tokens')) || 50,
                tts_token_method: document.querySelector('input[name="token-method"]:checked')?.value || 'tiktoken',
                pitch_algo: getElementValue('pitch-algo') || 'rmvpe+',
                pitch_level: getIntValue('pitch-lvl', 0),
                index_influence: getFloatValue('index-influence', 0.75),
                respiration_median_filtering: getIntValue('respiration-median', 3),
                envelope_ratio: getFloatValue('envelope-ratio', 0.25),
                consonant_breath_protection: getFloatValue('consonant-breath', 0.33),
                highpass: getFloatValue('highpass', 80),
                lowpass: getFloatValue('lowpass', 12000),
                bass_freq: getFloatValue('bass-freq', 60),
                bass_gain: getFloatValue('bass-gain', 4),
                treble_freq: getFloatValue('treble-freq', 8000),
                treble_gain: getFloatValue('treble-gain', 2),
                reverb_delay: getFloatValue('reverb-delay', 0),
                reverb_decay: getFloatValue('reverb-decay', 0),
                crystalizer: getFloatValue('crystalizer', 0),
                deesser: getFloatValue('deesser', 0),
                audio_8d_enabled: getElementChecked('audio-8d-enabled'),
                audio_8d_mode: getElementValue('audio-8d-mode') || 'rotate',
                audio_8d_speed: getFloatValue('audio-8d-speed', 0.1),
                audio_8d_depth: getFloatValue('audio-8d-depth', 180),
                audio_8d_distance: getFloatValue('audio-8d-distance', 0.3),
                audio_8d_quality: getElementValue('audio-8d-quality') || 'balanced',
                audio_8d_itd: getElementChecked('audio-8d-itd'),
                audio_8d_proximity: getElementChecked('audio-8d-proximity'),
                audio_8d_crossfeed: getElementChecked('audio-8d-crossfeed'),
                audio_8d_micro_movements: getElementChecked('audio-8d-micro-movements'),
                audio_8d_speech_aware: getElementChecked('audio-8d-speech-aware'),
                pitch_shift_enabled: getElementChecked('pitch-shift-enabled'),
                pitch_shift_semitones: getIntValue('pitch-shift-semitones', 0),
                asmr_enabled: getElementChecked('asmr-enabled'),
                asmr_tingles: getIntValue('asmr-tingles', 60),
                asmr_breathiness: getIntValue('asmr-breathiness', 65),
                asmr_crispness: getIntValue('asmr-crispness', 55),
                bg_files: getElementChecked('enable-background') && typeof getBgTracks === 'function' ? getBgTracks().map(t=>t.file).filter(f=>f) : [],
                bg_volumes: getElementChecked('enable-background') && typeof getBgTracks === 'function' ? getBgTracks().map(t=>parseFloat(t.volume)||0) : [],
                bg_delays: getElementChecked('enable-background') && typeof getBgTracks === 'function' ? getBgTracks().map(t=>parseFloat(t.delay)||0) : [],
                bg_fade_ins: getElementChecked('enable-background') && typeof getBgTracks === 'function' ? getBgTracks().map(t=>parseFloat(t.fade_in)||0) : [],
                bg_fade_outs: getElementChecked('enable-background') && typeof getBgTracks === 'function' ? getBgTracks().map(t=>parseFloat(t.fade_out)||0) : [],
                server_mix_background: true,  // Mix background on server for streaming
                output_volume: parseFloat(getElementValue('output-volume')) || 1.0,
                chatterbox_seed: parseInt(getElementValue('chatterbox-seed')) || 0,
                save_output: getElementChecked('save-output'),
                soprano_temperature: ttsBackend === 'soprano' ? getFloatValue('soprano-temperature', 0.7) : null,
                soprano_top_p: ttsBackend === 'soprano' ? getFloatValue('soprano-top-p', 0.95) : null,
                soprano_repetition_penalty: ttsBackend === 'soprano' ? getFloatValue('soprano-repetition-penalty', 1.2) : null
            };
        }
        
        function collectRVCParams() {
            return {
                pitch_algo: getElementValue('pitch-algo') || 'rmvpe+',
                pitch_lvl: parseInt(getElementValue('pitch-lvl')) || 0,
                index_influence: parseFloat(getElementValue('index-influence')) || 0.75,
                respiration_median_filtering: parseInt(getElementValue('respiration-median')) || 3,
                envelope_ratio: parseFloat(getElementValue('envelope-ratio')) || 0.25,
                consonant_breath_protection: parseFloat(getElementValue('consonant-breath')) || 0.33
            };
        }
        
        function collectPostProcessParams() {
            return {
                highpass: getFloatValue('highpass', 80),
                lowpass: getFloatValue('lowpass', 12000),
                bass_freq: getFloatValue('bass-freq', 60),
                bass_gain: getFloatValue('bass-gain', 4),
                treble_freq: getFloatValue('treble-freq', 8000),
                treble_gain: getFloatValue('treble-gain', 2),
                reverb_delay: getFloatValue('reverb-delay', 0),
                reverb_decay: getFloatValue('reverb-decay', 0),
                crystalizer: getFloatValue('crystalizer', 0),
                deesser: getFloatValue('deesser', 0),
                audio_8d_enabled: getElementChecked('audio-8d-enabled'),
                audio_8d_mode: getElementValue('audio-8d-mode') || 'rotate',
                audio_8d_speed: getFloatValue('audio-8d-speed', 0.1),
                audio_8d_depth: getFloatValue('audio-8d-depth', 180),
                audio_8d_distance: getFloatValue('audio-8d-distance', 0.3),
                audio_8d_quality: getElementValue('audio-8d-quality') || 'balanced',
                audio_8d_itd: getElementChecked('audio-8d-itd'),
                audio_8d_proximity: getElementChecked('audio-8d-proximity'),
                audio_8d_crossfeed: getElementChecked('audio-8d-crossfeed'),
                audio_8d_micro_movements: getElementChecked('audio-8d-micro-movements'),
                audio_8d_speech_aware: getElementChecked('audio-8d-speech-aware'),
                pitch_shift_enabled: getElementChecked('pitch-shift-enabled'),
                pitch_shift_semitones: getIntValue('pitch-shift-semitones', 0),
                asmr_enabled: getElementChecked('asmr-enabled'),
                asmr_tingles: getIntValue('asmr-tingles', 60),
                asmr_breathiness: getIntValue('asmr-breathiness', 65),
                asmr_crispness: getIntValue('asmr-crispness', 55)
            };
        }
        
        // Spatial Audio Controls - Simplified UI
        (function initSpatialAudio() {
            const enabledCheckbox = document.getElementById('audio-8d-enabled');
            const controlsContainer = document.getElementById('spatial-audio-controls');
            const modeSelect = document.getElementById('audio-8d-mode');
            const speedSlider = document.getElementById('audio-8d-speed');
            const depthSlider = document.getElementById('audio-8d-depth');
            const speedDisplay = document.getElementById('speed-display');
            const depthDisplay = document.getElementById('depth-display');
            const speedGroup = document.getElementById('pan-speed-group');
            const previewBtn = document.getElementById('preview-panning-btn');
            const panDot = document.getElementById('pan-position-dot');
            const panGlow = document.getElementById('pan-glow');
            const panTrail1 = document.getElementById('pan-trail-1');
            const panTrail2 = document.getElementById('pan-trail-2');
            const panTrail3 = document.getElementById('pan-trail-3');
            const panText = document.getElementById('pan-position-text');
            const earLeftSvg = document.getElementById('ear-left-svg');
            const earRightSvg = document.getElementById('ear-right-svg');
            
            let previewAnimationId = null;
            let isPreviewRunning = false;
            let trailHistory = [{x: 30, y: 100}, {x: 30, y: 100}, {x: 30, y: 100}];
            
            // Circle parameters
            const cx = 100, cy = 100, radius = 70;
            
            // Enable/disable controls
            function updateEnabledState() {
                const enabled = enabledCheckbox?.checked;
                if (controlsContainer) {
                    controlsContainer.style.opacity = enabled ? '1' : '0.5';
                    controlsContainer.style.pointerEvents = enabled ? 'auto' : 'none';
                }
            }
            enabledCheckbox?.addEventListener('change', updateEnabledState);
            
            // Update slider displays
            function updateDisplays() {
                if (speedDisplay && speedSlider) {
                    speedDisplay.textContent = parseFloat(speedSlider.value).toFixed(2);
                }
                if (depthDisplay && depthSlider) {
                    // Direct degree value (20-360)
                    depthDisplay.textContent = Math.round(parseFloat(depthSlider.value));
                }
                // Show/hide speed for static/center modes (no movement = no speed needed)
                if (speedGroup && modeSelect) {
                    const isStaticMode = ['static', 'static_right', 'center'].includes(modeSelect.value);
                    speedGroup.style.display = isStaticMode ? 'none' : 'block';
                }
            }
            speedSlider?.addEventListener('input', updateDisplays);
            depthSlider?.addEventListener('input', updateDisplays);
            modeSelect?.addEventListener('change', updateDisplays);
            
            // Distance slider - controls proximity effect (bass + presence boost)
            const distanceSlider = document.getElementById('audio-8d-distance');
            const distanceDisplay = document.getElementById('distance-display');
            const startDistanceInput = document.getElementById('audio-8d-start-distance');
            const endDistanceInput = document.getElementById('audio-8d-end-distance');
            
            function updateDistanceDisplay() {
                if (distanceSlider && distanceDisplay) {
                    const val = parseFloat(distanceSlider.value).toFixed(2);
                    distanceDisplay.textContent = val;
                    // Sync to hidden inputs
                    if (startDistanceInput) startDistanceInput.value = val;
                    if (endDistanceInput) endDistanceInput.value = val;
                }
            }
            distanceSlider?.addEventListener('input', updateDistanceDisplay);
            
            // Quality preset changes feature defaults
            const qualitySelect = document.getElementById('audio-8d-quality');
            const itdCheckbox = document.getElementById('audio-8d-itd');
            const proximityCheckbox = document.getElementById('audio-8d-proximity');
            const crossfeedCheckbox = document.getElementById('audio-8d-crossfeed');
            const microMovesCheckbox = document.getElementById('audio-8d-micro-movements');
            
            function updateQualityPreset() {
                const preset = qualitySelect?.value || 'balanced';
                // Preset defaults (user can still override)
                const presets = {
                    'fast': { itd: true, proximity: false, crossfeed: false, micro: false },
                    'balanced': { itd: true, proximity: true, crossfeed: true, micro: true },
                    'ultra': { itd: true, proximity: true, crossfeed: true, micro: true }
                };
                const p = presets[preset] || presets['balanced'];
                if (itdCheckbox) itdCheckbox.checked = p.itd;
                if (proximityCheckbox) proximityCheckbox.checked = p.proximity;
                if (crossfeedCheckbox) crossfeedCheckbox.checked = p.crossfeed;
                if (microMovesCheckbox) microMovesCheckbox.checked = p.micro;
            }
            qualitySelect?.addEventListener('change', updateQualityPreset);
            
            // Convert spatial angle (degrees around head) to position on circle
            // Spatial angle: -90¬∞ = left, 0¬∞ = front, +90¬∞ = right, ¬±180¬∞ = back
            // Circle angle (SVG): 0¬∞ = right, 90¬∞ = top, 180¬∞ = left, 270¬∞ = bottom
            function spatialAngleToCirclePos(spatialAngle) {
                // Map spatial angle to circle position
                // spatialAngle -90¬∞ (left) ‚Üí circleDeg 180¬∞
                // spatialAngle 0¬∞ (front) ‚Üí circleDeg 90¬∞
                // spatialAngle 90¬∞ (right) ‚Üí circleDeg 0¬∞
                // spatialAngle ¬±180¬∞ (back) ‚Üí circleDeg 270¬∞
                let circleDeg = 90 - spatialAngle;
                // Normalize to 0-360
                circleDeg = ((circleDeg % 360) + 360) % 360;
                const circleRad = circleDeg * Math.PI / 180;
                const x = cx + radius * Math.cos(circleRad);
                const y = cy - radius * Math.sin(circleRad);
                return {x, y, angleDeg: circleDeg, spatialAngle: spatialAngle};
            }
            
            // Update circular visualization using spatial angle (degrees around head)
            function updatePanVisualization(spatialAngle) {
                const pos = spatialAngleToCirclePos(spatialAngle);
                // Calculate pan from spatial angle for ear glow (sin gives L-R intensity)
                const pan = Math.sin(spatialAngle * Math.PI / 180);
                
                // Update trail history
                trailHistory.unshift({x: pos.x, y: pos.y});
                trailHistory = trailHistory.slice(0, 3);
                
                // Update main dot position
                if (panDot) {
                    panDot.setAttribute('cx', pos.x);
                    panDot.setAttribute('cy', pos.y);
                }
                if (panGlow) {
                    panGlow.setAttribute('cx', pos.x);
                    panGlow.setAttribute('cy', pos.y);
                }
                
                // Update trail dots
                if (panTrail1 && trailHistory[0]) {
                    panTrail1.setAttribute('cx', trailHistory[0].x);
                    panTrail1.setAttribute('cy', trailHistory[0].y);
                }
                if (panTrail2 && trailHistory[1]) {
                    panTrail2.setAttribute('cx', trailHistory[1].x);
                    panTrail2.setAttribute('cy', trailHistory[1].y);
                }
                if (panTrail3 && trailHistory[2]) {
                    panTrail3.setAttribute('cx', trailHistory[2].x);
                    panTrail3.setAttribute('cy', trailHistory[2].y);
                }
                
                // Update ear brightness in SVG
                const leftIntensity = Math.max(0, -pan);
                const rightIntensity = Math.max(0, pan);
                
                if (earLeftSvg) {
                    earLeftSvg.setAttribute('fill', 'var(--accent)');
                    earLeftSvg.setAttribute('opacity', 0.4 + leftIntensity * 0.6);
                    earLeftSvg.style.filter = leftIntensity > 0.3 ? `drop-shadow(0 0 ${8 + leftIntensity * 12}px var(--accent))` : 'none';
                }
                
                if (earRightSvg) {
                    earRightSvg.setAttribute('fill', 'var(--accent)');
                    earRightSvg.setAttribute('opacity', 0.4 + rightIntensity * 0.6);
                    earRightSvg.style.filter = rightIntensity > 0.3 ? `drop-shadow(0 0 ${8 + rightIntensity * 12}px var(--accent))` : 'none';
                }
                
                // Update position text based on spatial angle (degrees around head)
                // spatialAngle: -90¬∞ = left, 0¬∞ = front, +90¬∞ = right, ¬±180¬∞ = back
                if (panText) {
                    const deg = Math.round(pos.spatialAngle);
                    let label;
                    // Handle full 360¬∞ positions
                    const absDeg = Math.abs(deg);
                    if (absDeg >= 160) label = `‚¨á BACK`;
                    else if (deg >= 70 && deg < 110) label = `RIGHT EAR üëÇ`;
                    else if (deg >= 110 && deg < 160) label = `‚Üò Back-Right`;
                    else if (deg <= -70 && deg > -110) label = `üëÇ LEFT EAR`;
                    else if (deg <= -110 && deg > -160) label = `‚Üô Back-Left`;
                    else if (deg >= 20 && deg < 70) label = `‚Üó Front-Right`;
                    else if (deg <= -20 && deg > -70) label = `‚Üñ Front-Left`;
                    else label = `‚¨Ü FRONT`;
                    panText.textContent = `${label} (${deg}¬∞)`;
                }
            }
            
            // Preview animation
            function startPreview() {
                if (isPreviewRunning) {
                    stopPreview();
                    return;
                }
                
                isPreviewRunning = true;
                previewBtn.textContent = '‚èπ Stop Preview';
                
                const mode = modeSelect?.value || 'sweep';
                const speed = parseFloat(speedSlider?.value || 0.1);
                // Arc in degrees (20-360), this is the full sweep range
                const arcDegrees = parseFloat(depthSlider?.value || 180);
                const halfArc = arcDegrees / 2;  // Half the arc for ¬± range
                const startTime = performance.now();
                
                function animate() {
                    if (!isPreviewRunning) return;
                    
                    const elapsed = (performance.now() - startTime) / 1000;
                    let spatialAngle;  // -180¬∞ to +180¬∞ around head
                    
                    if (mode === 'static') {
                        spatialAngle = -90; // Left ear
                    } else if (mode === 'static_right') {
                        spatialAngle = 90; // Right ear
                    } else if (mode === 'extreme') {
                        // EXTREME: Dwell at arc extremes, quick transition through center
                        const wave = Math.sin(2 * Math.PI * speed * elapsed);
                        // tanh(x*15) = ~95% time at peaks, ~5% in transition
                        let extreme = Math.tanh(wave * 15) * 1.01;
                        extreme = Math.max(-1, Math.min(1, extreme));
                        spatialAngle = extreme * halfArc;
                    } else if (mode === 'sweep') {
                        // Triangle wave (linear back and forth)
                        const wave = Math.sin(2 * Math.PI * speed * elapsed);
                        const triangle = (2 / Math.PI) * Math.asin(wave);
                        spatialAngle = triangle * halfArc;
                    } else {
                        // Sine wave (rotate) - smooth acceleration/deceleration  
                        spatialAngle = Math.sin(2 * Math.PI * speed * elapsed) * halfArc;
                    }
                    
                    updatePanVisualization(spatialAngle);
                    previewAnimationId = requestAnimationFrame(animate);
                }
                
                animate();
            }
            
            function stopPreview() {
                isPreviewRunning = false;
                if (previewAnimationId) {
                    cancelAnimationFrame(previewAnimationId);
                    previewAnimationId = null;
                }
                if (previewBtn) previewBtn.textContent = '‚ñ∂ Preview Movement';
                // Reset trail history
                trailHistory = [{x: 30, y: 100}, {x: 30, y: 100}, {x: 30, y: 100}];
                // Reset to left position (-90¬∞ spatial angle)
                updatePanVisualization(-90);
            }
            
            previewBtn?.addEventListener('click', startPreview);
            
            // Initialize
            updateEnabledState();
            updateDisplays();
            // Start with dot at left position (-90¬∞ spatial angle = left ear)
            updatePanVisualization(-90);
        })();

        function updateTTSBackendVisibility() {
            const backend = getElementValue('tts-backend') || 'chatterbox';
            const isSoprano = backend === 'soprano';
            const isChatterbox = backend === 'chatterbox';
            
            // Show Soprano settings only for Soprano backend
            const sopranoSection = document.getElementById('soprano-settings');
            if (sopranoSection) {
                sopranoSection.style.display = isSoprano ? 'block' : 'none';
            }
            
            // Show voice cloning section only for Chatterbox backend
            const voiceCloningSection = document.getElementById('chatterbox-voice-cloning-section');
            if (voiceCloningSection) {
                voiceCloningSection.style.display = isChatterbox ? 'block' : 'none';
            }
            
            // Show Chatterbox model section only for Chatterbox backend
            const chatterboxModelSection = document.getElementById('chatterbox-model-section');
            if (chatterboxModelSection) {
                chatterboxModelSection.style.display = isChatterbox ? 'block' : 'none';
            }
        }
        
        function updateTTSBackendUI() {
            updateTTSBackendVisibility();
        }
        
        async function refreshChatterboxModels() {
            const select = document.getElementById('chatterbox-model');
            if (!select) return;
            
            // Keep current selection
            const currentValue = select.value;
            
            // Clear existing options except default
            select.innerHTML = '<option value="">Default (Base Model)</option>';
            
            let chatterboxModels = [];
            
            // Try training server first
            try {
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/models`);
                if (res.ok) {
                    const data = await res.json();
                    chatterboxModels = data.chatterbox || [];
                }
            } catch (e) {
                console.log('Training server not available, trying Chatterbox server...');
            }
            
            // Fallback to Chatterbox server if no models found
            if (chatterboxModels.length === 0) {
                try {
                    const res = await fetch(`${CHATTERBOX_URL}/v1/models`);
                    if (res.ok) {
                        const data = await res.json();
                        // Chatterbox server returns models in a different format
                        const customModels = (data.models || []).filter(m => m.type === 'custom' && m.valid);
                        chatterboxModels = customModels.map(m => ({
                            name: m.name,
                            path: m.path,
                            files: m.checkpoint_files
                        }));
                    }
                } catch (e) {
                    console.log('Could not fetch models from Chatterbox server:', e);
                }
            }
            
            // Add models to dropdown
            if (chatterboxModels.length > 0) {
                const optgroup = document.createElement('optgroup');
                optgroup.label = 'Custom Trained Models';
                
                chatterboxModels.forEach(model => {
                    const option = document.createElement('option');
                    option.value = model.name; // Use name instead of path for cleaner switching
                    const fileCount = Array.isArray(model.files) ? model.files.length : (model.files || 0);
                    option.textContent = model.name + (fileCount ? ` (${fileCount} checkpoint${fileCount > 1 ? 's' : ''})` : '');
                    optgroup.appendChild(option);
                });
                
                select.appendChild(optgroup);
            }
            
            // Restore selection if still valid
            if (currentValue) {
                const options = Array.from(select.options);
                if (options.some(o => o.value === currentValue)) {
                    select.value = currentValue;
                }
            }
        }
        
        async function refreshSopranoModels() {
            const select = document.getElementById('soprano-model');
            if (!select) return;
            
            // Keep current selection
            const currentValue = select.value;
            
            // Clear existing options except default
            select.innerHTML = '<option value="">Default (Base Model)</option>';
            
            let sopranoModels = [];
            
            // Try training server first
            try {
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/models`);
                if (res.ok) {
                    const data = await res.json();
                    sopranoModels = data.soprano || [];
                }
            } catch (e) {
                console.log('Training server not available, trying Soprano server...');
            }
            
            // Fallback to Soprano server if no models found
            if (sopranoModels.length === 0) {
                try {
                    const res = await fetch(`${SOPRANO_URL}/v1/models`);
                    if (res.ok) {
                        const data = await res.json();
                        // Soprano server returns models in a different format
                        const customModels = (data.models || []).filter(m => m.type === 'custom' && m.valid);
                        sopranoModels = customModels.map(m => ({
                            name: m.name,
                            path: m.path
                        }));
                    }
                } catch (e) {
                    console.log('Could not fetch models from Soprano server:', e);
                }
            }
            
            // Add models to dropdown
            if (sopranoModels.length > 0) {
                const optgroup = document.createElement('optgroup');
                optgroup.label = 'Custom Trained Models';
                
                sopranoModels.forEach(model => {
                    const option = document.createElement('option');
                    option.value = model.name;
                    option.textContent = model.name;
                    optgroup.appendChild(option);
                });
                
                select.appendChild(optgroup);
            }
            
            // Restore selection if still valid
            if (currentValue) {
                const options = Array.from(select.options);
                if (options.some(o => o.value === currentValue)) {
                    select.value = currentValue;
                }
            }
        }

        const ttsBackendSelect = document.getElementById('tts-backend');
        if (ttsBackendSelect) {
            ttsBackendSelect.addEventListener('change', updateTTSBackendVisibility);
        }
        updateTTSBackendVisibility();
        // Note: Custom model lists are loaded in DOMContentLoaded after server connections are established
        
        // Auto-save on changes
        document.addEventListener('change', (e) => {
            if (e.target?.type === 'file' || e.target?.id === 'script-select') return;
            saveSettings();
        });
        document.addEventListener('input', (e) => {
            if (e.target?.type === 'file') return;
            clearTimeout(window._saveTimer);
            window._saveTimer = setTimeout(saveSettings, 1000);
        });
        
        // =================================================================
        // APP STATE
        // =================================================================
        let ws = null;
        window.bgTrackCount = 0;

        // Initialize
        document.addEventListener('DOMContentLoaded', async () => {
            await loadData();
            await loadScripts();
            await loadAudioPrompts();
            setupWebSocket();
            setupKeyboardShortcuts();
            await loadSettings();
            
            // Re-select audio prompt after settings load (if it was from the dropdown)
            if (window.lastChatterboxPromptPath) {
                const select = document.getElementById('audio-prompt-select');
                if (select) {
                    for (let opt of select.options) {
                        if (opt.value === window.lastChatterboxPromptPath) {
                            select.value = window.lastChatterboxPromptPath;
                            break;
                        }
                    }
                }
            }
            
            // Update TTS backend visibility after settings are loaded
            updateTTSBackendVisibility();
            
            // Load custom model lists after initialization (servers should be ready by now)
            await refreshChatterboxModels();
            await refreshSopranoModels();
        });

        // Keyboard shortcuts
        function setupKeyboardShortcuts() {
            document.addEventListener('keydown', (e) => {
                if (e.ctrlKey && e.key === 'g') {
                    e.preventDefault();
                    generateSpeech();
                } else if (e.ctrlKey && e.key === 'o') {
                    e.preventDefault();
                    const select = document.getElementById('script-select');
                    select.focus();
                    select.click();
                } else if (e.key === 'Escape') {
                    closeHelp();
                }
            });
        }

        // Tab switching
        function switchTab(index) {
            // Remove active class from all tabs
            document.querySelectorAll('.tab').forEach((tab, i) => {
                if (i === index) {
                    tab.classList.add('active');
                    tab.setAttribute('aria-selected', 'true');
                } else {
                    tab.classList.remove('active');
                    tab.setAttribute('aria-selected', 'false');
                }
            });
            // Update tab content visibility using IDs for reliability
            const tabContentIds = ['tab-0', 'tab-1', 'tab-2', 'tab-3', 'tab-4', 'tab-5', 'tab-6', 'tab-7'];
            tabContentIds.forEach((tabId, i) => {
                const content = document.getElementById(tabId);
                if (content) {
                    if (i === index) {
                        content.classList.add('active');
                    } else {
                        content.classList.remove('active');
                    }
                }
            });
        }

        // WebSocket for real-time updates
        function setupWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws/progress`;
            ws = new WebSocket(wsUrl);

            ws.onopen = () => {
                console.log('WebSocket connected');
            };

            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                if (data.type === 'status') {
                    const statusEl = document.getElementById('status');
                    statusEl.textContent = data.message;
                    statusEl.className = 'status';
                } else if (data.type === 'progress') {
                    const progress = data.progress;
                    const progressBar = document.getElementById('progress-bar');
                    const progressFill = document.getElementById('progress-fill');
                    progressBar.classList.add('active');
                    progressBar.setAttribute('aria-valuenow', progress);
                    progressFill.style.width = `${progress}%`;
                    progressFill.textContent = `${progress}%`;
                } else if (data.type === 'complete') {
                    document.getElementById('progress-bar').classList.remove('active');
                    document.getElementById('generate-btn').disabled = false;
                    document.getElementById('generate-btn').classList.remove('btn-loading');
                    if (data.audioUrl) {
                        const audioPlayer = document.getElementById('audio-player');
                        audioPlayer.src = data.audioUrl;
                        audioPlayer.style.display = 'block';
                        audioPlayer.play();
                    }
                } else if (data.type === 'error') {
                    document.getElementById('progress-bar').classList.remove('active');
                    document.getElementById('generate-btn').disabled = false;
                    document.getElementById('generate-btn').classList.remove('btn-loading');
                    const statusEl = document.getElementById('status');
                    statusEl.textContent = `Error: ${data.message}`;
                    statusEl.className = 'status error';
                    showToast(data.message, 'error');
                }
            };

            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
            };

            ws.onclose = () => {
                console.log('WebSocket disconnected, reconnecting...');
                setTimeout(setupWebSocket, 3000);
            };
        }

        // Load data from API
        async function loadData() {
            try {
                // Load models
                const modelsRes = await fetch('/api/models');
                const modelsData = await modelsRes.json();
                const modelSelect = document.getElementById('model-select');
                modelSelect.innerHTML = '<option value="">Select a model...</option>';
                modelsData.models.forEach(model => {
                    const option = document.createElement('option');
                    option.value = model;
                    option.textContent = model;
                    modelSelect.appendChild(option);
                });

                // Load background audio files
                const bgRes = await fetch('/api/background-audio');
                const bgData = await bgRes.json();
                window.bgAudioFiles = bgData.files || [];
            } catch (error) {
                console.error('Error loading data:', error);
                showToast('Failed to load data', 'error');
            }
        }

        // Load available audio prompts from server
        async function loadAudioPrompts() {
            try {
                const response = await fetch('/api/audio-prompts');
                if (response.ok) {
                    const data = await response.json();
                    const select = document.getElementById('audio-prompt-select');
                    if (select && data.prompts) {
                        // Keep the first default option
                        select.innerHTML = '<option value="">-- Select saved prompt --</option>';
                        
                        data.prompts.forEach(prompt => {
                            const option = document.createElement('option');
                            option.value = prompt.path;
                            option.textContent = prompt.name;
                            option.dataset.filename = prompt.filename;
                            select.appendChild(option);
                        });
                        
                        // If we have a saved prompt path, try to select it
                        if (window.lastChatterboxPromptPath) {
                            for (let opt of select.options) {
                                if (opt.value === window.lastChatterboxPromptPath) {
                                    select.value = window.lastChatterboxPromptPath;
                                    break;
                                }
                            }
                        }
                    }
                }
            } catch (e) {
                console.warn('Failed to load audio prompts:', e);
            }
        }
        
        // Handle audio prompt selection from dropdown
        function selectAudioPrompt(select) {
            const hint = document.getElementById('chatterbox-prompt-hint');
            const fileInput = document.getElementById('chatterbox-prompt-audio');
            
            if (select.value) {
                // Clear file input when selecting from dropdown
                if (fileInput) fileInput.value = '';
                
                // Update saved path
                window.lastChatterboxPromptPath = select.value;
                window.lastChatterboxPromptFilename = select.options[select.selectedIndex].dataset.filename;
                
                // Update hint
                if (hint) {
                    hint.textContent = `Using: ${select.options[select.selectedIndex].textContent}`;
                    hint.style.display = 'block';
                    hint.style.color = 'var(--success, #28a745)';
                }
                
                saveSettings();
            } else {
                if (hint && !window.lastChatterboxPromptPath) {
                    hint.style.display = 'none';
                }
            }
        }
        
        // Track Chatterbox prompt audio file selection (upload)
        function trackChatterboxPromptFile(input) {
            if (input.files && input.files.length > 0) {
                // Clear dropdown selection when uploading new file
                const select = document.getElementById('audio-prompt-select');
                if (select) select.value = '';
                
                // Just update the UI hint - don't clear saved path or save settings yet
                // The path will be updated after successful upload during generation
                const hint = document.getElementById('chatterbox-prompt-hint');
                if (hint) {
                    hint.textContent = `Selected: ${input.files[0].name} (will upload on generate)`;
                    hint.style.display = 'block';
                    hint.style.color = 'var(--accent)';
                }
            }
        }



        // Stop generation
        async function stopGeneration() {
            if (!isGenerating) return;
            
            console.log('[Stop] Stopping generation...');
            
            const stopBtn = document.getElementById('stop-btn');
            const statusEl = document.getElementById('status');
            
            // Show stopping state
            stopBtn.disabled = true;
            stopBtn.innerHTML = '<span>‚è≥</span> Stopping...';
            statusEl.textContent = 'Stopping... (waiting for current chunk to finish)';
            statusEl.className = 'status';
            
            // Cancel on server side first (this stops workers after current chunk)
            try {
                const cancelUrl = currentRequestId 
                    ? `/api/generate/cancel?request_id=${currentRequestId}`
                    : '/api/generate/cancel';
                
                // Show pending status while waiting for current chunk
                if (statusEl) {
                    statusEl.textContent = 'Stopping... (waiting for current chunk to finish)';
                    statusEl.className = 'status warning';
                }
                
                const cancelResp = await fetch(cancelUrl, { method: 'POST' });
                const cancelResult = await cancelResp.json();
                console.log('[Stop] Server cancel result:', cancelResult);
                
                // Show the server's response
                if (cancelResult.status === 'pending' && statusEl) {
                    statusEl.textContent = 'Cancellation pending - finishing current chunk...';
                }
            } catch (e) {
                console.warn('[Stop] Server cancel failed:', e);
            }
            
            // Abort the fetch request (this closes the connection)
            if (currentAbortController) {
                currentAbortController.abort();
                currentAbortController = null;
            }
            
            // Stop any playing audio immediately
            if (currentAudioContext && currentAudioContext.state !== 'closed') {
                try { currentAudioContext.close(); } catch (e) {}
                currentAudioContext = null;
            }
            
            // Stop background audio stream
            if (window.bgStreamInfo) {
                stopBackgroundStream(window.bgStreamInfo.session_id, 0.3);
                window.bgStreamInfo = null;
            }
            
            // Reset state
            currentRequestId = null;
            
            // Reset UI
            const generateBtn = document.getElementById('generate-btn');
            
            generateBtn.disabled = false;
            generateBtn.classList.remove('btn-loading');
            stopBtn.style.display = 'none';
            stopBtn.disabled = false;
            stopBtn.innerHTML = '<span>‚èπ</span> Stop';
            document.getElementById('progress-bar').classList.remove('active');
            
            statusEl.textContent = 'Generation stopped.';
            statusEl.className = 'status';
            
            isGenerating = false;
            showToast('Generation stopped (server may finish current chunk)', 'info');
        }

        // Generate speech
        async function generateSpeech() {
            const text = document.getElementById('text-input').value.trim();
            if (!text) {
                showToast('Please enter text to synthesize', 'warn');
                document.getElementById('text-input').focus();
                return;
            }

            const model = document.getElementById('model-select').value;
            const enableRvc = document.getElementById('enable-rvc').checked;

            if (enableRvc && !model) {
                showToast('Select a valid RVC model or disable RVC', 'warn');
                switchTab(1);
                document.getElementById('model-select').focus();
                return;
            }

            // Check prompt audio requirement for Chatterbox (voice cloning)
            const ttsBackend = getElementValue('tts-backend') || 'chatterbox';
            const promptAudioInput = document.getElementById('chatterbox-prompt-audio');
            const hasNewFile = promptAudioInput && promptAudioInput.files && promptAudioInput.files.length > 0;
            const hasSavedPath = window.lastChatterboxPromptPath;
            
            // Soprano doesn't need prompt audio - it uses a fixed voice
            if (ttsBackend === 'chatterbox' && !hasNewFile && !hasSavedPath) {
                showToast('Voice cloning requires a prompt audio file (5+ seconds minimum, 10+ recommended)', 'warn');
                return;
            }

            const generateBtn = document.getElementById('generate-btn');
            const stopBtn = document.getElementById('stop-btn');
            generateBtn.disabled = true;
            generateBtn.classList.add('btn-loading');
            stopBtn.style.display = 'inline-flex';
            isGenerating = true;
            
            // Create abort controller for this generation
            currentAbortController = new AbortController();
            
            const statusEl = document.getElementById('status');
            statusEl.textContent = 'Starting generation‚Ä¶';
            statusEl.className = 'status';
            
            document.getElementById('progress-bar').classList.add('active');
            document.getElementById('progress-fill').style.width = '3%';

            // Collect all parameters using unified collection function
            const params = collectTTSRequest();
            
            // Switch Chatterbox model if needed
            if (ttsBackend === 'chatterbox' && params.chatterbox_model) {
                statusEl.textContent = 'Switching to custom model...';
                try {
                    await fetch(`${CHATTERBOX_URL}/v1/models/switch?model_name=${encodeURIComponent(params.chatterbox_model)}`, {
                        method: 'POST'
                    });
                } catch (e) {
                    console.warn('Model switch failed, using current model:', e);
                }
            } else if (ttsBackend === 'chatterbox' && !params.chatterbox_model) {
                // Ensure default model is loaded
                try {
                    await fetch(`${CHATTERBOX_URL}/v1/models/switch?model_name=default`, {
                        method: 'POST'
                    });
                } catch (e) {
                    // Ignore - default is probably already loaded
                }
            }
            
            // Switch Soprano model if needed
            if (ttsBackend === 'soprano' && params.soprano_model) {
                statusEl.textContent = 'Switching to custom model...';
                try {
                    await fetch(`${SOPRANO_URL}/v1/models/switch?model_name=${encodeURIComponent(params.soprano_model)}`, {
                        method: 'POST'
                    });
                } catch (e) {
                    console.warn('Model switch failed, using current model:', e);
                }
            } else if (ttsBackend === 'soprano' && !params.soprano_model) {
                // Ensure default model is loaded
                try {
                    await fetch(`${SOPRANO_URL}/v1/models/switch?model_name=default`, {
                        method: 'POST'
                    });
                } catch (e) {
                    // Ignore - default is probably already loaded
                }
            }
            
            // Handle prompt audio upload for voice cloning (Chatterbox only)
            if (ttsBackend === 'chatterbox') {
                if (hasNewFile) {
                    // Upload new prompt audio file
                    const formData = new FormData();
                    formData.append('file', promptAudioInput.files[0]);
                    
                    statusEl.textContent = 'Uploading prompt audio for voice cloning...';
                    
                    const uploadResponse = await fetch('/api/upload', {
                        method: 'POST',
                        body: formData
                    });
                    
                    if (!uploadResponse.ok) {
                        throw new Error('Failed to upload prompt audio file');
                    }
                    
                    const uploadResult = await uploadResponse.json();
                    const uploadedPath = uploadResult.path;
                    
                    params.chatterbox_prompt_audio = uploadedPath;
                    
                    // Save the path for future use
                    window.lastChatterboxPromptPath = uploadedPath;
                    window.lastChatterboxPromptFilename = promptAudioInput.files[0].name;
                    saveSettings();
                } else if (hasSavedPath) {
                    // Use previously uploaded file path
                    params.chatterbox_prompt_audio = hasSavedPath;
                }
            }
            // Soprano doesn't need prompt audio - it uses a fixed voice

            try {
                console.log('[Generate] Sending params:', JSON.stringify(params, null, 2));
                
                // Check if streaming mode is selected
                const isStreaming = params.tts_mode === 'streaming';
                
                if (isStreaming) {
                    // Use streaming endpoint with progressive playback
                    await generateWithStreaming(params, statusEl, generateBtn);
                } else {
                    // Use regular endpoint (chunked mode)
                    await generateWithChunked(params, statusEl, generateBtn);
                }
                
                saveSettings();
            } catch (error) {
                document.getElementById('progress-bar').classList.remove('active');
                generateBtn.disabled = false;
                generateBtn.classList.remove('btn-loading');
                stopBtn.style.display = 'none';
                isGenerating = false;
                currentAbortController = null;
                
                // Don't show error if it was aborted
                if (error.name === 'AbortError') {
                    statusEl.textContent = 'Generation stopped.';
                    statusEl.className = 'status';
                } else {
                statusEl.textContent = `Error: ${error.message}`;
                statusEl.className = 'status error';
                showToast(error.message, 'error');
                }
            }
        }
        
        async function generateWithChunked(params, statusEl, generateBtn) {
            const stopBtn = document.getElementById('stop-btn');
            
            // Generate a request_id for cancellation support
            const requestId = Math.random().toString(36).substring(2, 10);
            currentRequestId = requestId;
            params.request_id = requestId;
            console.log(`[Chunked] Request ID: ${requestId}`);
            
            const response = await fetch('/api/generate', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(params),
                signal: currentAbortController?.signal
            });

            if (!response.ok) {
                const error = await response.json();
                let errorMsg = 'Generation failed';
                if (error.detail) {
                    if (Array.isArray(error.detail)) {
                        errorMsg = error.detail.map(e => `${e.loc?.join('.') || 'field'}: ${e.msg}`).join('; ');
                    } else {
                        errorMsg = error.detail;
                    }
                }
                throw new Error(errorMsg);
            }

            const blob = await response.blob();
            const url = URL.createObjectURL(blob);
            const audioPlayer = document.getElementById('audio-player');
            audioPlayer.src = url;
            audioPlayer.style.display = 'block';
            audioPlayer.play();

            document.getElementById('progress-bar').classList.remove('active');
            generateBtn.disabled = false;
            generateBtn.classList.remove('btn-loading');
            stopBtn.style.display = 'none';
            isGenerating = false;
            currentAbortController = null;
            currentRequestId = null;
            statusEl.textContent = 'Generation complete!';
            statusEl.className = 'status';
            showToast('Generation complete!', 'success');
        }
        
        async function generateWithStreaming(params, statusEl, generateBtn) {
            const progressFill = document.getElementById('progress-fill');
            const audioPlayer = document.getElementById('audio-player');
            const stopBtn = document.getElementById('stop-btn');
            
            // Create audio context for streaming playback
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            currentAudioContext = audioContext;  // Store globally for stop function
            const audioChunks = [];
            let totalChunks = 1;
            let chunksReceived = 0;
            let isFirstChunk = true;
            let scheduledTime = audioContext.currentTime;
            
            statusEl.textContent = 'Starting streaming generation...';
            
            // Initialize progress bar
            progressFill.style.width = '0%';
            progressFill.textContent = '0%';
            
            // Clear previous streaming files
            window.streamingChunkFiles = [];
            window.lastStreamingFiles = [];
            
            const response = await fetch('/api/generate/stream', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(params),
                signal: currentAbortController?.signal
            });
            
            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.detail || 'Streaming failed');
            }
            
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';
            
            // Hide the HTML audio player, we'll use Web Audio API
            audioPlayer.style.display = 'none';
            
            try {
                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;
                    
                    buffer += decoder.decode(value, { stream: true });
                    
                    // Process SSE events
                    while (buffer.includes('\n\n')) {
                        const eventEnd = buffer.indexOf('\n\n');
                        const eventData = buffer.slice(0, eventEnd);
                        buffer = buffer.slice(eventEnd + 2);
                        
                        if (eventData.startsWith('data: ')) {
                            try {
                                const event = JSON.parse(eventData.slice(6));
                                
                                if (event.type === 'start') {
                                    totalChunks = event.chunks || event.total || totalChunks;
                                    // Store request ID for cancellation
                                    if (event.request_id) {
                                        currentRequestId = event.request_id;
                                        console.log(`[Stream] Request ID: ${currentRequestId}`);
                                    }
                                    
                                    // Store background stream info for later
                                    window.bgStreamInfo = null;
                                    window.bgAudioElement = null;
                                    if (event.background_enabled && event.background_tracks && event.background_tracks.length > 0) {
                                        window.bgStreamInfo = {
                                            session_id: event.background_session_id || currentRequestId,
                                            tracks: event.background_tracks,
                                            sample_rate: event.sample_rate || 44100
                                        };
                                        console.log(`[Stream] Background audio enabled: ${event.background_tracks.length} tracks`);
                                    }
                                    
                                    const bgStatus = event.background_enabled ? ', BG: stream' : '';
                                    statusEl.textContent = `Streaming: 0/${totalChunks} chunks (RVC: ${event.rvc_enabled ? 'on' : 'off'}, Post: ${event.post_enabled ? 'on' : 'off'}${bgStatus})`;
                                    
                                } else if (event.type === 'cancelled') {
                                    // Server-side cancellation confirmed
                                    console.log('[Stream] Generation cancelled by server');
                                    statusEl.textContent = `Cancelled after ${event.chunks_sent || 0} chunks`;
                                    
                                    // Stop background stream on cancel
                                    if (window.bgStreamInfo) {
                                        stopBackgroundStream(window.bgStreamInfo.session_id, 0.5);
                                    }
                                    break;
                                    
                                } else if (event.type === 'chunk') {
                                    if (!totalChunks && event.total) {
                                        totalChunks = event.total;
                                    }
                                    chunksReceived++;
                                    const progress = Math.round((chunksReceived / Math.max(1, totalChunks)) * 100);
                                    progressFill.style.width = `${progress}%`;
                                    progressFill.textContent = `${progress}%`;
                                    
                                    statusEl.textContent = `Streaming: ${chunksReceived}/${totalChunks} chunks (${event.duration}s)`;
                                    
                                    // Decode base64 audio and play it
                                    const audioBytes = Uint8Array.from(atob(event.audio), c => c.charCodeAt(0));
                                    audioChunks.push(audioBytes);
                                    
                                    // Decode and schedule playback
                                    try {
                                        const audioBuffer = await audioContext.decodeAudioData(audioBytes.buffer.slice(0));
                                        console.log(`[Audio Debug] Chunk ${chunksReceived}: ctx.sampleRate=${audioContext.sampleRate}, buffer.sampleRate=${audioBuffer.sampleRate}, duration=${audioBuffer.duration.toFixed(2)}s, length=${audioBuffer.length}`);
                                        const source = audioContext.createBufferSource();
                                        source.buffer = audioBuffer;
                                        source.connect(audioContext.destination);  // Volume applied server-side
                                        
                                        // Resume context if suspended (autoplay policy)
                                        if (audioContext.state === 'suspended') {
                                            await audioContext.resume();
                                        }
                                        
                                        // Schedule this chunk after previous ones
                                        if (isFirstChunk) {
                                            scheduledTime = audioContext.currentTime;
                                            isFirstChunk = false;
                                            
                                            // Start background audio stream when first voice chunk plays
                                            if (window.bgStreamInfo) {
                                                startBackgroundStream(window.bgStreamInfo);
                                            }
                                        }
                                        
                                        // If scheduled time fell behind (slow chunk delivery), catch up to current time
                                        // This prevents chunks from playing immediately/overlapping
                                        if (scheduledTime < audioContext.currentTime) {
                                            console.log(`[Audio] Schedule time behind by ${(audioContext.currentTime - scheduledTime).toFixed(2)}s, catching up`);
                                            scheduledTime = audioContext.currentTime;
                                        }
                                        
                                        source.start(scheduledTime);
                                        scheduledTime += audioBuffer.duration;
                                        
                                    } catch (decodeErr) {
                                        console.error('Failed to decode audio chunk:', decodeErr);
                                    }
                                    
                                } else if (event.type === 'complete') {
                                    // Schedule background stream stop when voice finishes
                                    // Wait for voice to finish playing (scheduledTime - currentTime)
                                    const voiceEndTime = scheduledTime - audioContext.currentTime;
                                    if (window.bgStreamInfo && voiceEndTime > 0) {
                                        setTimeout(() => {
                                            stopBackgroundStream(window.bgStreamInfo.session_id);
                                        }, voiceEndTime * 1000);
                                    }
                                    
                                    statusEl.textContent = `Streaming complete! ${event.chunks_sent} chunks`;
                                    
                                } else if (event.type === 'error') {
                                    // Stop background stream on error
                                    if (window.bgStreamInfo) {
                                        stopBackgroundStream(window.bgStreamInfo.session_id, 0.3);
                                    }
                                    throw new Error(event.message);
                                }
                            } catch (parseErr) {
                                console.error('Failed to parse SSE event:', parseErr);
                            }
                        }
                    }
                }
                
                // Combine all chunks into a single blob for the audio player (for replay)
                if (audioChunks.length > 0) {
                    const combinedBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const url = URL.createObjectURL(combinedBlob);
                    audioPlayer.src = url;
                    audioPlayer.style.display = 'block';
                }
                
                document.getElementById('progress-bar').classList.remove('active');
                generateBtn.disabled = false;
                generateBtn.classList.remove('btn-loading');
                stopBtn.style.display = 'none';
                isGenerating = false;
                currentAbortController = null;
                showToast('Streaming complete!', 'success');
                
            } catch (streamErr) {
                throw streamErr;
            } finally {
                // Close audio context after playback finishes
                const remainingTime = Math.max(0, scheduledTime - audioContext.currentTime) + 1;
                setTimeout(() => {
                    if (audioContext.state !== 'closed') {
                        audioContext.close();
                    }
                }, remainingTime * 1000);
            }
        }

        // Background tracks
        function addBgTrack(file = '', volume = 0, delay = 0, fadeIn = 0, fadeOut = 0) {
            const tracksDiv = document.getElementById('bg-tracks');
            const trackDiv = document.createElement('div');
            trackDiv.className = 'bg-track';
            
            const normalizePath = (path) => {
                if (!path) return '';
                return path.replace(/\\/g, '/').toLowerCase();
            };
            
            const normalizedFile = normalizePath(file);
            const fileOptions = window.bgAudioFiles?.map(f => {
                const normalized = normalizePath(f);
                const isSelected = normalized === normalizedFile || 
                                 f === file || 
                                 f.endsWith(file) || 
                                 file.endsWith(f);
                return `<option value="${f}" ${isSelected ? 'selected' : ''}>${f}</option>`;
            }).join('') || '';
            
            const delayValue = parseFloat(delay) || 0;
            const fadeInValue = parseFloat(fadeIn) || 0;
            const fadeOutValue = parseFloat(fadeOut) || 0;
            const trackNum = (window.bgTrackCount || 0) + 1;
            
            trackDiv.innerHTML = `
                <div style="display: flex; align-items: center; gap: 8px; width: 100%;">
                    <label style="margin: 0; white-space: nowrap; font-weight: 600;">BG ${trackNum}:</label>
                    <select class="bg-file-select" style="flex: 1; min-width: 150px;" aria-label="Background track ${trackNum} file">
                        <option value="">(none)</option>
                        ${fileOptions}
                    </select>
                    <div style="display: flex; align-items: center; gap: 8px; flex-shrink: 0;">
                        <label style="margin: 0;" title="Volume (0-1)">Vol:</label>
                        <input type="number" class="bg-volume" value="${volume || 0}" min="0" max="1" step="0.01" style="width: 72px;" aria-label="Volume">
                        <label style="margin: 0;" title="Delay (seconds)">Dly:</label>
                        <input type="number" class="bg-delay" value="${delayValue}" min="0" max="300" step="0.1" style="width: 72px;" aria-label="Delay">
                        <label style="margin: 0;" title="Fade in (seconds)">In:</label>
                        <input type="number" class="bg-fade-in" value="${fadeInValue}" min="0" max="60" step="0.5" style="width: 72px;" aria-label="Fade in">
                        <label style="margin: 0;" title="Fade out (seconds)">Out:</label>
                        <input type="number" class="bg-fade-out" value="${fadeOutValue}" min="0" max="60" step="0.5" style="width: 72px;" aria-label="Fade out">
                        <button class="btn btn-danger" onclick="removeBgTrack(this)" style="padding: 4px 8px;" aria-label="Remove background track ${trackNum}">üóëÔ∏è</button>
                    </div>
                </div>
            `;
            tracksDiv.appendChild(trackDiv);
            window.bgTrackCount = (window.bgTrackCount || 0) + 1;
            updateBgTrackLabels();
            
            // Attach event listeners to the new elements for auto-save
            const select = trackDiv.querySelector('.bg-file-select');
            const volumeInput = trackDiv.querySelector('.bg-volume');
            const delayInput = trackDiv.querySelector('.bg-delay');
            const fadeInInput = trackDiv.querySelector('.bg-fade-in');
            const fadeOutInput = trackDiv.querySelector('.bg-fade-out');
            
            if (select) {
                select.addEventListener('change', () => {
                    saveSettings();
                });
            }
            
            [volumeInput, delayInput, fadeInInput, fadeOutInput].forEach(input => {
                if (input) {
                    input.addEventListener('input', () => {
                        clearTimeout(window.saveTimeout);
                        window.saveTimeout = setTimeout(saveSettings, 1000);
                    });
                    input.addEventListener('change', saveSettings);
                }
            });
            
            // Save settings after adding track (with small delay to ensure DOM is updated)
            setTimeout(() => {
                saveSettings();
            }, 100);
        }

        function removeBgTrack(btn) {
            const trackElement = btn.closest('.bg-track');
            if (trackElement) {
                trackElement.remove();
                updateBgTrackLabels();
                // Recalculate bgTrackCount based on remaining tracks
                window.bgTrackCount = document.querySelectorAll('.bg-track').length;
                // Save settings immediately when removing a track
                saveSettings();
            }
        }

        function updateBgTrackLabels() {
            document.querySelectorAll('.bg-track').forEach((track, i) => {
                track.querySelector('label').textContent = `BG ${i + 1}:`;
            });
        }

        // Background stream functions for streaming mode
        async function startBackgroundStream(bgInfo) {
            try {
                console.log('[BGStream] Starting background audio...');
                console.log('[BGStream] Tracks:', bgInfo.tracks);
                
                // Build GET URL for audio element src
                const audioServicesUrl = 'http://127.0.0.1:8892';
                const params = new URLSearchParams({
                    session_id: bgInfo.session_id,
                    tracks_json: JSON.stringify(bgInfo.tracks),
                    sample_rate: String(bgInfo.sample_rate),
                    duration: '3600'  // 1 hour to avoid restarts during long TTS streams
                });
                const streamUrl = `${audioServicesUrl}/v1/background/stream?${params}`;
                console.log('[BGStream] URL:', streamUrl);
                
                // Create an audio element to play the background
                const audioEl = new Audio();
                audioEl.crossOrigin = 'anonymous';
                audioEl.src = streamUrl;
                audioEl.loop = true;  // Loop the finite file
                
                // Handle errors
                audioEl.onerror = (e) => {
                    console.error('[BGStream] Audio element error:', e);
                };
                
                // Apply fade-in if any track has it
                const maxFadeIn = Math.max(...bgInfo.tracks.map(t => t.fade_in || 0), 0);
                if (maxFadeIn > 0) {
                    audioEl.volume = 0;
                    await audioEl.play();
                    // Fade in
                    const fadeSteps = 20;
                    const fadeInterval = (maxFadeIn * 1000) / fadeSteps;
                    let step = 0;
                    const fadeTimer = setInterval(() => {
                        step++;
                        audioEl.volume = Math.min(1, step / fadeSteps);
                        if (step >= fadeSteps) clearInterval(fadeTimer);
                    }, fadeInterval);
                } else {
                    await audioEl.play();
                }
                
                window.bgAudioElement = audioEl;
                console.log('[BGStream] Background audio started');
                
            } catch (err) {
                console.error('[BGStream] Failed to start background:', err);
            }
        }
        
        async function stopBackgroundStream(sessionId, fadeOut = 2.0) {
            try {
                console.log('[BGStream] Stopping background audio stream...');
                
                // Fade out the audio element
                if (window.bgAudioElement) {
                    const audioEl = window.bgAudioElement;
                    const fadeSteps = 20;
                    const fadeInterval = (fadeOut * 1000) / fadeSteps;
                    let step = fadeSteps;
                    const startVolume = audioEl.volume;
                    
                    const fadeTimer = setInterval(() => {
                        step--;
                        audioEl.volume = Math.max(0, (step / fadeSteps) * startVolume);
                        if (step <= 0) {
                            clearInterval(fadeTimer);
                            audioEl.pause();
                            audioEl.src = '';
                            window.bgAudioElement = null;
                        }
                    }, fadeInterval);
                }
                
                // Tell server to stop the stream
                const audioServicesUrl = 'http://127.0.0.1:8892';
                await fetch(`${audioServicesUrl}/v1/background/stop-stream`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                    body: `session_id=${encodeURIComponent(sessionId)}`
                });
                
                console.log('[BGStream] Background audio stopped');
                
            } catch (err) {
                console.error('[BGStream] Failed to stop background stream:', err);
            }
        }

        function getBgTracks() {
            const tracks = [];
            document.querySelectorAll('.bg-track').forEach(track => {
                const fileSelect = track.querySelector('.bg-file-select');
                const volumeInput = track.querySelector('.bg-volume');
                const delayInput = track.querySelector('.bg-delay');
                const fadeInInput = track.querySelector('.bg-fade-in');
                const fadeOutInput = track.querySelector('.bg-fade-out');
                if (fileSelect && volumeInput) {
                    const file = fileSelect.value;
                    const volume = volumeInput.value;
                    const delay = delayInput ? delayInput.value : 0;
                    const fadeIn = fadeInInput ? fadeInInput.value : 0;
                    const fadeOut = fadeOutInput ? fadeOutInput.value : 0;
                    // Include all tracks with a file selected
                    if (file && file.trim()) {
                        tracks.push({ 
                            file: file.trim(), 
                            volume: parseFloat(volume) || 0,
                            delay: parseFloat(delay) || 0,
                            fade_in: parseFloat(fadeIn) || 0,
                            fade_out: parseFloat(fadeOut) || 0
                        });
                    }
                }
            });
            return tracks;
        }

        // Process audio file through RVC
        async function processRvcFile() {
            const fileInput = document.getElementById('rvc-audio-input');
            const file = fileInput.files[0];
            
            if (!file) {
                showToast('Please select an audio file', 'warn');
                return;
            }
            
            const model = document.getElementById('model-select').value;
            if (!model) {
                showToast('Please select an RVC model', 'warn');
                document.getElementById('model-select').focus();
                return;
            }
            
            const processBtn = document.getElementById('rvc-process-btn');
            const statusEl = document.getElementById('rvc-status');
            const progressBar = document.getElementById('rvc-progress-bar');
            const progressFill = document.getElementById('rvc-progress-fill');
            const audioPlayer = document.getElementById('rvc-audio-player');
            
            processBtn.disabled = true;
            processBtn.classList.add('btn-loading');
            statusEl.textContent = 'Processing audio through RVC...';
            statusEl.className = 'status';
            progressBar.style.display = 'block';
            progressFill.style.width = '10%';
            progressFill.textContent = '10%';
            audioPlayer.style.display = 'none';
            
            try {
                // Collect RVC parameters using unified collection function
                const rvcParamsRaw = collectRVCParams();
                // Parse values for RVC endpoint (endpoint expects parsed numbers)
                const rvcParams = {
                    pitch_algo: rvcParamsRaw.pitch_algo,
                    pitch_lvl: parseInt(rvcParamsRaw.pitch_lvl) || 0,
                    index_influence: parseFloat(rvcParamsRaw.index_influence) || 0.75,
                    respiration_median_filtering: parseInt(rvcParamsRaw.respiration_median_filtering) || 3,
                    envelope_ratio: parseFloat(rvcParamsRaw.envelope_ratio) || 0.25,
                    consonant_breath_protection: parseFloat(rvcParamsRaw.consonant_breath_protection) || 0.33
                };
                
                progressFill.style.width = '30%';
                progressFill.textContent = '30%';
                
                const formData = new FormData();
                formData.append('audio_file', file);
                formData.append('model_name', model);
                formData.append('rvc_params', JSON.stringify(rvcParams));
                
                const response = await fetch('/api/rvc/audio', {
                    method: 'POST',
                    body: formData
                });
                
                progressFill.style.width = '80%';
                progressFill.textContent = '80%';
                
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'RVC processing failed');
                }
                
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                
                progressFill.style.width = '100%';
                progressFill.textContent = '100%';
                
                audioPlayer.src = audioUrl;
                audioPlayer.style.display = 'block';
                
                statusEl.textContent = 'RVC processing complete!';
                statusEl.className = 'status success';
                showToast('RVC processing complete', 'success');
                
                // Auto-play
                audioPlayer.play().catch(() => {});
                
            } catch (error) {
                statusEl.textContent = 'Error: ' + error.message;
                statusEl.className = 'status error';
                showToast('RVC processing failed: ' + error.message, 'error');
            } finally {
                processBtn.disabled = false;
                processBtn.classList.remove('btn-loading');
                setTimeout(() => {
                    progressBar.style.display = 'none';
                    progressFill.style.width = '0%';
                }, 2000);
            }
        }

        // Post-process an audio file
        async function postProcessAudio() {
            const fileInput = document.getElementById('postprocess-audio-file');
            const file = fileInput.files[0];
            
            if (!file) {
                showToast('Please select an audio file', 'warn');
                return;
            }
            
            const postprocessBtn = document.getElementById('postprocess-btn');
            const statusEl = document.getElementById('postprocess-audio-status');
            const progressBar = document.getElementById('postprocess-progress-bar');
            const progressFill = document.getElementById('postprocess-progress-fill');
            const audioPlayer = document.getElementById('postprocessed-audio-player');
            
            postprocessBtn.disabled = true;
            postprocessBtn.classList.add('btn-loading');
            statusEl.textContent = 'Post-processing audio...';
            statusEl.className = 'status';
            progressBar.style.display = 'block';
            progressFill.style.width = '10%';
            progressFill.textContent = '10%';
            audioPlayer.style.display = 'none';
            
            try {
                // Collect all post-processing parameters using unified collection function
                const postParams = collectPostProcessParams();
                
                // Check file size and warn for large files
                const fileSizeMB = file.size / (1024 * 1024);
                if (fileSizeMB > 50) {
                    statusEl.textContent = `Processing large file (${fileSizeMB.toFixed(0)}MB) - this may take several minutes...`;
                    showToast(`Large file (${fileSizeMB.toFixed(0)}MB) - please be patient`, 'info');
                }
                
                progressFill.style.width = '30%';
                progressFill.textContent = '30%';
                
                const formData = new FormData();
                formData.append('audio_file', file);
                formData.append('post_params', JSON.stringify(postParams));
                
                // Dynamic timeout based on file size (minimum 2 min, scales with size)
                // ~1 minute per 20MB + 2 min base, maximum 60 minutes
                const timeoutMinutes = Math.max(2, Math.min(60, 2 + Math.ceil(fileSizeMB / 20)));
                const controller = new AbortController();
                const timeoutId = setTimeout(() => controller.abort(), timeoutMinutes * 60 * 1000);
                
                if (fileSizeMB > 50) {
                    console.log(`[Post-Process] Timeout: ${timeoutMinutes} minutes for ${fileSizeMB.toFixed(0)}MB file`);
                    statusEl.textContent = `Processing ${fileSizeMB.toFixed(0)}MB file (timeout: ${timeoutMinutes} min)...`;
                }
                
                const response = await fetch('/api/post-process/audio', {
                    method: 'POST',
                    body: formData,
                    signal: controller.signal
                });
                
                clearTimeout(timeoutId);
                
                progressFill.style.width = '80%';
                progressFill.textContent = '80%';
                
                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.detail || 'Post-processing failed');
                }
                
                const blob = await response.blob();
                const url = URL.createObjectURL(blob);
                
                progressFill.style.width = '100%';
                progressFill.textContent = '100%';
                
                audioPlayer.src = url;
                audioPlayer.style.display = 'block';
                audioPlayer.play().catch(() => {});
                
                statusEl.textContent = 'Post-processing complete!';
                statusEl.className = 'status success';
                showToast('Audio post-processed successfully!', 'success');
            } catch (error) {
                statusEl.textContent = `Error: ${error.message}`;
                statusEl.className = 'status error';
                showToast(error.message, 'error');
            } finally {
                postprocessBtn.disabled = false;
                postprocessBtn.classList.remove('btn-loading');
                setTimeout(() => {
                    progressBar.style.display = 'none';
                    progressFill.style.width = '0%';
                }, 2000);
            }
        }

        // UVR5 Audio Preprocessing
        let uvr5OutputBlob = null;
        
        async function processUVR5() {
            const fileInput = document.getElementById('uvr5-audio-input');
            const file = fileInput.files[0];
            
            if (!file) {
                showToast('Please select an audio file', 'warn');
                return;
            }
            
            const modelKey = document.getElementById('uvr5-model').value;
            const aggression = parseInt(document.getElementById('uvr5-aggression').value) || 10;
            const skipCache = document.getElementById('uvr5-skip-cache').checked;
            
            const processBtn = document.getElementById('uvr5-process-btn');
            const statusEl = document.getElementById('uvr5-status');
            const progressBar = document.getElementById('uvr5-progress-bar');
            const progressFill = document.getElementById('uvr5-progress-fill');
            
            // Get model display name
            const modelSelect = document.getElementById('uvr5-model');
            const modelName = modelSelect.options[modelSelect.selectedIndex].text;
            
            processBtn.disabled = true;
            processBtn.classList.add('btn-loading');
            statusEl.textContent = `Processing with ${modelName}... This may take a minute.`;
            statusEl.className = 'status';
            progressBar.style.display = 'block';
            progressFill.style.width = '10%';
            progressFill.textContent = '10%';
            
            // Hide previous results
            document.getElementById('uvr5-vocals-result').style.display = 'none';
            document.getElementById('uvr5-no-results').style.display = 'none';
            
            try {
                progressFill.style.width = '30%';
                progressFill.textContent = '30%';
                
                const formData = new FormData();
                formData.append('audio', file);
                formData.append('aggression', aggression.toString());
                formData.append('model_key', modelKey);
                formData.append('skip_if_cached', (!skipCache).toString());
                
                const response = await fetch('/api/preprocess/uvr5/clean-vocals', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.detail || 'Processing failed');
                }
                
                uvr5OutputBlob = await response.blob();
                const outputUrl = URL.createObjectURL(uvr5OutputBlob);
                const outputPlayer = document.getElementById('uvr5-vocals-player');
                outputPlayer.src = outputUrl;
                
                // Update label based on model type
                const resultLabel = document.querySelector('#uvr5-vocals-result label');
                if (modelKey === 'hp5_vocals') {
                    resultLabel.textContent = 'Vocals (Extracted):';
                } else {
                    resultLabel.textContent = 'Cleaned Audio:';
                }
                
                document.getElementById('uvr5-vocals-result').style.display = 'block';
                
                progressFill.style.width = '100%';
                progressFill.textContent = '100%';
                
                statusEl.textContent = 'Processing complete!';
                statusEl.className = 'status success';
                showToast('Audio processed successfully!', 'success');
                
            } catch (error) {
                statusEl.textContent = `Error: ${error.message}`;
                statusEl.className = 'status error';
                showToast(error.message, 'error');
                document.getElementById('uvr5-no-results').style.display = 'block';
            } finally {
                processBtn.disabled = false;
                processBtn.classList.remove('btn-loading');
                setTimeout(() => {
                    progressBar.style.display = 'none';
                    progressFill.style.width = '0%';
                }, 2000);
            }
        }
        
        function downloadUVR5Audio(type) {
            const fileInput = document.getElementById('uvr5-audio-input');
            const originalName = fileInput.files[0]?.name || 'audio';
            const baseName = originalName.replace(/\.[^/.]+$/, '');
            const modelKey = document.getElementById('uvr5-model').value;
            
            const suffix = modelKey === 'hp5_vocals' ? 'vocals' : 'cleaned';
            const filename = `${baseName}_${suffix}.wav`;
            
            if (!uvr5OutputBlob) {
                showToast('No audio to download', 'warn');
                return;
            }
            
            const url = URL.createObjectURL(uvr5OutputBlob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }
        
        async function unloadUVR5() {
            try {
                const response = await fetch('/api/preprocess/uvr5/unload', {
                    method: 'POST'
                });
                
                if (response.ok) {
                    showToast('UVR5 models unloaded - GPU memory freed', 'success');
                } else {
                    const error = await response.json();
                    throw new Error(error.error || 'Failed to unload');
                }
            } catch (error) {
                showToast(`Failed to unload UVR5: ${error.message}`, 'error');
            }
        }

        // Blend background audio with main audio file
        async function blendBackgroundAudio() {
            const fileInput = document.getElementById('main-audio-file');
            const file = fileInput.files[0];
            
            if (!file) {
                showToast('Please select a main audio file', 'warn');
                return;
            }
            
            const bgTracks = getBgTracks();
            if (bgTracks.length === 0) {
                showToast('Please add at least one background track', 'warn');
                return;
            }
            
            const mainVolume = 1.0;  // Fixed to 100% - user can adjust in post-processing if needed
            
            const blendBtn = document.getElementById('blend-btn');
            const statusEl = document.getElementById('main-audio-status');
            
            blendBtn.disabled = true;
            blendBtn.classList.add('btn-loading');
            statusEl.textContent = 'Blending audio...';
            statusEl.className = 'status';
            
            try {
                const formData = new FormData();
                formData.append('main_audio', file);
                formData.append('main_volume', mainVolume.toString());
                
                // Send background tracks as JSON to preserve pairing
                // This ensures files, volumes, and delays stay matched perfectly
                const bgTracksJson = JSON.stringify(bgTracks.map(t => ({
                    file: t.file,
                    volume: parseFloat(t.volume) || 0,
                    delay: parseFloat(t.delay) || 0
                })));
                formData.append('bg_tracks_json', bgTracksJson);
                
                const response = await fetch('/api/background-audio/blend', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.detail || 'Blending failed');
                }
                
                const blob = await response.blob();
                const url = URL.createObjectURL(blob);
                const audioPlayer = document.getElementById('blended-audio-player');
                audioPlayer.src = url;
                audioPlayer.style.display = 'block';
                audioPlayer.play();
                
                statusEl.textContent = 'Blending complete!';
                statusEl.className = 'status';
                showToast('Audio blended successfully!', 'success');
            } catch (error) {
                statusEl.textContent = `Error: ${error.message}`;
                statusEl.className = 'status error';
                showToast(error.message, 'error');
            } finally {
                blendBtn.disabled = false;
                blendBtn.classList.remove('btn-loading');
            }
        }

        // Script loading
        async function loadScriptFromSelect() {
            const select = document.getElementById('script-select');
            const scriptName = select.value;
            if (!scriptName) return;
            
            try {
                const response = await fetch(`/api/scripts/${encodeURIComponent(scriptName)}`);
                if (response.ok) {
                    const data = await response.json();
                    document.getElementById('text-input').value = data.content;
                    showToast(`Loaded script: ${data.name}`, 'success');
                    select.value = '';
                } else {
                    const error = await response.json();
                    showToast(error.detail || 'Failed to load script', 'error');
                }
            } catch (error) {
                showToast('Failed to load script', 'error');
            }
        }

        function addScript() {
            document.getElementById('script-file').click();
        }

        async function handleScriptUpload(event) {
            const file = event.target.files[0];
            if (!file) return;
            
            if (!file.name.toLowerCase().endsWith('.txt')) {
                showToast('Please select a .txt file', 'error');
                return;
            }
            
            try {
                const formData = new FormData();
                formData.append('file', file);
                
                const response = await fetch('/api/scripts/upload', {
                    method: 'POST',
                    body: formData
                });
                
                if (response.ok) {
                    const data = await response.json();
                    showToast(`Script added: ${data.filename}`, 'success');
                    await loadScripts();
                    const select = document.getElementById('script-select');
                    select.value = data.filename;
                    await loadScriptFromSelect();
                } else {
                    const error = await response.json();
                    showToast(error.detail || 'Failed to upload script', 'error');
                }
            } catch (error) {
                showToast('Failed to upload script', 'error');
            }
            
            event.target.value = '';
        }

        async function loadScripts() {
            try {
                const response = await fetch('/api/scripts');
                if (response.ok) {
                    const data = await response.json();
                    const select = document.getElementById('script-select');
                    while (select.options.length > 1) {
                        select.remove(1);
                    }
                    data.scripts.forEach(script => {
                        const option = document.createElement('option');
                        option.value = script;
                        option.textContent = script;
                        select.appendChild(option);
                    });
                }
            } catch (error) {
                console.error('Failed to load scripts:', error);
            }
        }

        // Help modal
        function showHelp() {
            document.getElementById('help-modal').classList.add('active');
        }

        function closeHelp(event) {
            if (!event || event.target.id === 'help-modal') {
                document.getElementById('help-modal').classList.remove('active');
            }
        }

        // Toast notifications
        function showToast(message, type = 'info') {
            const toast = document.getElementById('toast');
            const icons = { info: '‚ÑπÔ∏è', success: '‚úÖ', warn: '‚ö†Ô∏è', error: '‚ùå' };
            toast.textContent = `${icons[type] || '‚ÑπÔ∏è'} ${message}`;
            toast.className = `toast show ${type}`;
            setTimeout(() => {
                toast.classList.remove('show');
            }, 4000);
        }
        
        // Toggle Spatial Audio Advanced Panel
        function toggleSpatialAdvanced() {
            const panel = document.getElementById('spatial-advanced-panel');
            const arrow = document.getElementById('spatial-advanced-arrow');
            if (panel && arrow) {
                const isHidden = panel.style.display === 'none';
                panel.style.display = isHidden ? 'block' : 'none';
                arrow.style.transform = isHidden ? 'rotate(90deg)' : 'rotate(0deg)';
            }
        }

        // Worker Settings
        async function loadWorkerSettings() {
            // Prevent auto-save during load
            const wasLoading = isLoadingSettings;
            isLoadingSettings = true;
            try {
                const response = await fetch('/api/settings/workers');
                if (response.ok) {
                    const settings = await response.json();
                    if (settings.max_workers !== undefined) {
                        document.getElementById('max-workers').value = settings.max_workers;
                    }
                    if (settings.rvc_workers !== undefined) {
                        document.getElementById('rvc-workers').value = settings.rvc_workers;
                    }
                }
            } catch (err) {
                console.error('Failed to load worker settings:', err);
            } finally {
                isLoadingSettings = wasLoading; // Restore previous state
            }
        }

        async function saveWorkerSettings() {
            const settings = {
                max_workers: parseInt(document.getElementById('max-workers').value),
                rvc_workers: parseInt(document.getElementById('rvc-workers').value)
            };

            // Validate
            if (settings.max_workers < 1 || settings.rvc_workers < 1) {
                showToast('All worker counts must be at least 1', 'warn');
                return;
            }

            try {
                // Save to main server
                const response = await fetch('/api/settings/workers', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(settings)
                });

                if (response.ok) {
                    showToast('Worker settings saved successfully', 'success');
                } else {
                    const error = await response.json();
                    showToast(`Failed to save worker settings: ${error.detail || 'Unknown error'}`, 'error');
                }
            } catch (err) {
                console.error('Failed to save worker settings:', err);
                showToast('Failed to save worker settings', 'error');
            }
        }

        // ==========================================
        // TRANSCRIPTION FUNCTIONS
        // ==========================================
        
        // File input preview handler
        document.getElementById('transcribe-audio').addEventListener('change', function(e) {
            const file = e.target.files[0];
            if (file) {
                const preview = document.getElementById('transcribe-audio-preview');
                const player = document.getElementById('transcribe-audio-player');
                player.src = URL.createObjectURL(file);
                preview.style.display = 'block';
            }
        });

        // Update hints based on selected ASR model
        function updateModelHints() {
            const model = document.getElementById('transcribe-model').value;
            const modelHint = document.getElementById('model-hint');
            const languageHint = document.getElementById('language-hint');
            const autoOption = document.querySelector('#transcribe-language option[value="auto"]');
            
            const isGLM = model.startsWith('glm');
            
            if (isGLM) {
                modelHint.textContent = 'üß† GLM-ASR: Best for quiet/whispered speech, low-volume audio, and Cantonese dialect. Outperforms Whisper V3 on key benchmarks.';
                languageHint.textContent = 'GLM-ASR is optimized for English, Mandarin Chinese, and Cantonese (Á≤§ËØ≠).';
                // Disable auto-detect for GLM-ASR
                autoOption.disabled = true;
                autoOption.textContent = 'Auto-detect (Whisper only)';
                // If auto was selected, switch to English
                if (document.getElementById('transcribe-language').value === 'auto') {
                    document.getElementById('transcribe-language').value = 'en';
                }
            } else {
                modelHint.textContent = 'üéôÔ∏è Whisper: Best general-purpose ASR with excellent multilingual support and auto-detection.';
                languageHint.textContent = 'Whisper supports 90+ languages including auto-detection.';
                autoOption.disabled = false;
                autoOption.textContent = 'Auto-detect';
            }
        }

        // Save transcribe tab preferences to localStorage
        function saveTranscribePreferences() {
            const prefs = {
                inputSource: currentInputSource,
                device: document.getElementById('transcribe-device').value,
                model: document.getElementById('transcribe-model').value,
                language: document.getElementById('transcribe-language').value,
                endpoint: document.getElementById('transcribe-endpoint').value,
                cleanVocals: document.getElementById('clean-vocals').checked,
                postprocessAudio: document.getElementById('postprocess-audio').checked,
                skipExistingVocals: document.getElementById('skip-existing-vocals').checked
            };
            localStorage.setItem('voiceforge_transcribe_prefs', JSON.stringify(prefs));
        }
        
        // Load transcribe tab preferences from localStorage
        function loadTranscribePreferences() {
            try {
                const saved = localStorage.getItem('voiceforge_transcribe_prefs');
                if (saved) {
                    const prefs = JSON.parse(saved);
                    if (prefs.inputSource) setInputSource(prefs.inputSource);
                    if (prefs.device) document.getElementById('transcribe-device').value = prefs.device;
                    if (prefs.model) document.getElementById('transcribe-model').value = prefs.model;
                    if (prefs.language) document.getElementById('transcribe-language').value = prefs.language;
                    if (prefs.endpoint) document.getElementById('transcribe-endpoint').value = prefs.endpoint;
                    if (prefs.cleanVocals !== undefined) document.getElementById('clean-vocals').checked = prefs.cleanVocals;
                    if (prefs.postprocessAudio !== undefined) document.getElementById('postprocess-audio').checked = prefs.postprocessAudio;
                    if (prefs.skipExistingVocals !== undefined) document.getElementById('skip-existing-vocals').checked = prefs.skipExistingVocals;
                }
                // Update hints based on loaded model (handles both Whisper and GLM-ASR)
                updateModelHints();
            } catch (e) {
                console.warn('Failed to load transcribe preferences:', e);
            }
        }
        
        // Load preferences on page load
        document.addEventListener('DOMContentLoaded', loadTranscribePreferences);

        // ==========================================
        // MICROPHONE RECORDING
        // ==========================================
        
        let currentInputSource = 'file';
        let mediaRecorder = null;
        let audioChunks = [];
        let recordingStartTime = null;
        let recordingTimer = null;
        let audioContext = null;
        let analyser = null;
        let micStream = null;
        
        function setInputSource(source) {
            currentInputSource = source;
            
            const fileBtn = document.getElementById('input-source-file-btn');
            const micBtn = document.getElementById('input-source-mic-btn');
            const fileSection = document.getElementById('file-input-section');
            const micSection = document.getElementById('mic-input-section');
            
            if (source === 'file') {
                fileBtn.style.opacity = '1';
                micBtn.style.opacity = '0.6';
                fileSection.style.display = 'block';
                micSection.style.display = 'none';
            } else {
                fileBtn.style.opacity = '0.6';
                micBtn.style.opacity = '1';
                fileSection.style.display = 'none';
                micSection.style.display = 'block';
            }
        }
        
        // ==========================================
        // MICROPHONE MODE SELECTION
        // ==========================================
        
        let currentMicMode = 'record'; // 'record' or 'live'
        
        function setMicMode(mode) {
            currentMicMode = mode;
            
            const recordBtn = document.getElementById('mic-mode-record-btn');
            const liveBtn = document.getElementById('mic-mode-live-btn');
            const recordUI = document.getElementById('mic-record-mode');
            const liveUI = document.getElementById('mic-live-mode');
            
            if (mode === 'record') {
                recordBtn.className = 'btn btn-primary';
                liveBtn.className = 'btn btn-outline';
                recordUI.style.display = 'block';
                liveUI.style.display = 'none';
            } else {
                recordBtn.className = 'btn btn-outline';
                liveBtn.className = 'btn btn-primary';
                recordUI.style.display = 'none';
                liveUI.style.display = 'block';
            }
        }
        
        // ==========================================
        // LIVE TRANSCRIPTION (WebSocket)
        // ==========================================
        
        let liveWebSocket = null;
        let liveAudioContext = null;
        let liveAnalyser = null;
        let liveScriptProcessor = null;
        let liveMediaStream = null;
        let isLiveTranscribing = false;
        
        async function toggleLiveTranscription() {
            if (isLiveTranscribing) {
                stopLiveTranscription();
            } else {
                await startLiveTranscription();
            }
        }
        
        async function startLiveTranscription() {
            try {
                // Get model and language
                const model = document.getElementById('transcribe-model').value;
                const language = document.getElementById('transcribe-language').value;
                
                document.getElementById('live-status-text').textContent = 'Checking server...';
                
                // Check if ASR server is running first
                try {
                    const healthResp = await fetch('/v1/asr/health');
                    if (!healthResp.ok) {
                        showToast('ASR server not responding. Make sure ASR server is running (launcher option 4).', 'error');
                        document.getElementById('live-status-text').textContent = 'Server not available';
                        return;
                    }
                    const health = await healthResp.json();
                    if (health.status !== 'healthy') {
                        showToast('ASR server is not healthy. Check server logs.', 'error');
                        document.getElementById('live-status-text').textContent = 'Server unhealthy';
                        return;
                    }
                } catch (e) {
                    console.error('[LIVE] Health check failed:', e);
                    showToast('Cannot reach ASR server. Make sure ASR server is running (launcher option 4).', 'error');
                    document.getElementById('live-status-text').textContent = 'Server offline';
                    return;
                }
                
                document.getElementById('live-status-text').textContent = 'Requesting microphone...';
                
                // Request microphone access
                liveMediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000,
                        channelCount: 1
                    }
                });
                
                // Set up audio context
                liveAudioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const source = liveAudioContext.createMediaStreamSource(liveMediaStream);
                
                // Analyser for level visualization
                liveAnalyser = liveAudioContext.createAnalyser();
                liveAnalyser.fftSize = 256;
                source.connect(liveAnalyser);
                
                // Script processor for capturing audio data
                // Using 4096 buffer size for ~256ms chunks at 16kHz
                liveScriptProcessor = liveAudioContext.createScriptProcessor(4096, 1, 1);
                source.connect(liveScriptProcessor);
                liveScriptProcessor.connect(liveAudioContext.destination);
                
                // Connect to WebSocket on appropriate ASR server
                const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                
                // Select ASR server port based on model:
                // - GLM-ASR runs on port 8890
                // - Whisper runs on port 8889
                const isGLM = model.startsWith('glm');
                const asrPort = isGLM ? '8890' : '8889';
                const asrHost = window.location.hostname + ':' + asrPort;
                let wsUrl = `${wsProtocol}//${asrHost}/v1/audio/transcriptions/live?model=${encodeURIComponent(model)}&language=${encodeURIComponent(language)}`;
                console.log(`[LIVE] Connecting to ${isGLM ? 'GLM-ASR' : 'Whisper'} server at ${asrHost}`);
                
                console.log('[LIVE] Connecting to:', wsUrl);
                document.getElementById('live-status-text').textContent = 'Connecting...';
                
                try {
                    liveWebSocket = new WebSocket(wsUrl);
                } catch (e) {
                    console.error('[LIVE] WebSocket creation failed:', e);
                    showToast(`Failed to create WebSocket: ${e.message}`, 'error');
                    return;
                }
                
                liveWebSocket.onopen = () => {
                    console.log('[LIVE] WebSocket connected');
                    isLiveTranscribing = true;
                    updateLiveUI(true);
                    showToast('Live transcription started!', 'success');
                    
                    // Start sending audio
                    liveScriptProcessor.onaudioprocess = (e) => {
                        if (liveWebSocket && liveWebSocket.readyState === WebSocket.OPEN) {
                            const inputData = e.inputBuffer.getChannelData(0);
                            // Convert Float32Array to base64
                            // We need to copy the buffer since inputData's buffer might be reused
                            const float32Copy = new Float32Array(inputData.length);
                            float32Copy.set(inputData);
                            const uint8View = new Uint8Array(float32Copy.buffer);
                            
                            // Convert to base64 in chunks to avoid call stack issues
                            let binary = '';
                            const bytes = uint8View;
                            const len = bytes.byteLength;
                            for (let i = 0; i < len; i++) {
                                binary += String.fromCharCode(bytes[i]);
                            }
                            const base64Audio = btoa(binary);
                            
                            liveWebSocket.send(JSON.stringify({
                                type: 'audio',
                                data: base64Audio
                            }));
                        }
                    };
                    
                    // Start level visualization
                    updateLiveLevel();
                };
                
                liveWebSocket.onmessage = (event) => {
                    try {
                        const message = JSON.parse(event.data);
                        console.log('[LIVE] Received:', message.type);
                        handleLiveMessage(message);
                    } catch (e) {
                        console.error('[LIVE] Failed to parse message:', e, event.data);
                    }
                };
                
                liveWebSocket.onerror = (error) => {
                    console.error('[LIVE] WebSocket error:', error);
                    showToast('Live transcription connection failed. Check console (F12) for details.', 'error');
                    stopLiveTranscription();
                };
                
                liveWebSocket.onclose = (event) => {
                    console.log('[LIVE] WebSocket closed:', event.code, event.reason);
                    if (isLiveTranscribing) {
                        if (event.code !== 1000) { // 1000 = normal closure
                            showToast(`Connection closed: ${event.reason || 'Unknown reason'} (code: ${event.code})`, 'warn');
                        }
                        stopLiveTranscription();
                    }
                };
                
            } catch (error) {
                console.error('[LIVE] Start error:', error);
                showToast(`Failed to start: ${error.message}`, 'error');
                stopLiveTranscription();
            }
        }
        
        function stopLiveTranscription() {
            // Send end signal
            if (liveWebSocket && liveWebSocket.readyState === WebSocket.OPEN) {
                liveWebSocket.send(JSON.stringify({ type: 'end' }));
            }
            
            // Clean up audio
            if (liveScriptProcessor) {
                liveScriptProcessor.disconnect();
                liveScriptProcessor = null;
            }
            if (liveAnalyser) {
                liveAnalyser.disconnect();
                liveAnalyser = null;
            }
            if (liveAudioContext) {
                liveAudioContext.close();
                liveAudioContext = null;
            }
            if (liveMediaStream) {
                liveMediaStream.getTracks().forEach(track => track.stop());
                liveMediaStream = null;
            }
            
            // Close WebSocket
            if (liveWebSocket) {
                liveWebSocket.close();
                liveWebSocket = null;
            }
            
            isLiveTranscribing = false;
            updateLiveUI(false);
        }
        
        function handleLiveMessage(message) {
            const output = document.getElementById('transcription-output');
            const statusText = document.getElementById('live-status-text');
            
            switch (message.type) {
                case 'ready':
                    statusText.textContent = 'Listening...';
                    break;
                    
                case 'partial':
                case 'final':
                    // Show latest chunk
                    if (message.text) {
                        statusText.textContent = 'Transcribing...';
                    }
                    break;
                    
                case 'transcript':
                    // Update full transcript
                    if (message.text) {
                        output.value = message.text;
                        output.scrollTop = output.scrollHeight;
                        document.getElementById('copy-transcription-btn').disabled = false;
                        document.getElementById('use-for-tts-btn').disabled = false;
                    }
                    break;
                    
                case 'complete':
                    if (message.text) {
                        output.value = message.text;
                        output.scrollTop = output.scrollHeight;
                    }
                    statusText.textContent = 'Complete';
                    showToast('Live transcription complete!', 'success');
                    break;
                    
                case 'error':
                    showToast(`Error: ${message.message}`, 'error');
                    stopLiveTranscription();
                    break;
                    
                case 'config_updated':
                    console.log('[LIVE] Config updated');
                    break;
            }
        }
        
        function updateLiveUI(isActive) {
            const btn = document.getElementById('live-start-btn');
            const btnIcon = document.getElementById('live-btn-icon');
            const btnText = document.getElementById('live-btn-text');
            const statusDot = document.getElementById('live-status-dot');
            const statusText = document.getElementById('live-status-text');
            
            if (isActive) {
                btn.className = 'btn btn-danger';
                btn.style.background = '#dc3545';
                btnIcon.textContent = '‚èπÔ∏è';
                btnText.textContent = 'Stop';
                statusDot.style.display = 'inline';
                statusText.textContent = 'Listening...';
            } else {
                btn.className = 'btn btn-primary';
                btn.style.background = '';
                btnIcon.textContent = '‚ö°';
                btnText.textContent = 'Start Live';
                statusDot.style.display = 'none';
                statusText.textContent = 'Ready';
                
                // Reset level bar
                const levelBar = document.getElementById('live-level-bar');
                if (levelBar) levelBar.style.width = '0%';
            }
        }
        
        function updateLiveLevel() {
            if (!liveAnalyser || !isLiveTranscribing) return;
            
            const dataArray = new Uint8Array(liveAnalyser.frequencyBinCount);
            liveAnalyser.getByteFrequencyData(dataArray);
            
            // Calculate average level
            const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
            const level = Math.min(100, (average / 128) * 100);
            
            const levelBar = document.getElementById('live-level-bar');
            if (levelBar) {
                levelBar.style.width = level + '%';
                // Color based on level
                if (level > 60) {
                    levelBar.style.background = '#28a745';
                } else if (level > 30) {
                    levelBar.style.background = '#ffc107';
                } else {
                    levelBar.style.background = '#6c757d';
                }
            }
            
            requestAnimationFrame(updateLiveLevel);
        }
        
        // ==========================================
        // MICROPHONE RECORDING (Original)
        // ==========================================
        
        async function toggleMicRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopMicRecording();
            } else {
                await startMicRecording();
            }
        }
        
        async function startMicRecording() {
            try {
                // Request microphone access
                micStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000
                    } 
                });
                
                // Set up audio context for recording raw PCM (WAV compatible)
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(micStream);
                source.connect(analyser);
                analyser.fftSize = 256;
                
                // Start level visualization
                updateMicLevel();
                
                // Capture raw PCM audio using ScriptProcessor
                audioChunks = [];
                const scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                source.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
                
                scriptProcessor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);
                    // Copy the buffer (it gets reused)
                    audioChunks.push(new Float32Array(inputData));
                };
                
                // Store processor for cleanup
                window.micScriptProcessor = scriptProcessor;
                
                // Function to convert Float32 chunks to WAV blob
                window.createWavBlob = () => {
                    // Concatenate all chunks
                    const totalLength = audioChunks.reduce((acc, chunk) => acc + chunk.length, 0);
                    const audioData = new Float32Array(totalLength);
                    let offset = 0;
                    for (const chunk of audioChunks) {
                        audioData.set(chunk, offset);
                        offset += chunk.length;
                    }
                    
                    // Convert to 16-bit PCM
                    const buffer = new ArrayBuffer(44 + audioData.length * 2);
                    const view = new DataView(buffer);
                    
                    // WAV header
                    const writeString = (offset, string) => {
                        for (let i = 0; i < string.length; i++) {
                            view.setUint8(offset + i, string.charCodeAt(i));
                        }
                    };
                    
                    const sampleRate = 16000;
                    writeString(0, 'RIFF');
                    view.setUint32(4, 36 + audioData.length * 2, true);
                    writeString(8, 'WAVE');
                    writeString(12, 'fmt ');
                    view.setUint32(16, 16, true); // fmt chunk size
                    view.setUint16(20, 1, true); // PCM format
                    view.setUint16(22, 1, true); // mono
                    view.setUint32(24, sampleRate, true);
                    view.setUint32(28, sampleRate * 2, true); // byte rate
                    view.setUint16(32, 2, true); // block align
                    view.setUint16(34, 16, true); // bits per sample
                    writeString(36, 'data');
                    view.setUint32(40, audioData.length * 2, true);
                    
                    // Write audio data
                    let dataOffset = 44;
                    for (let i = 0; i < audioData.length; i++) {
                        const sample = Math.max(-1, Math.min(1, audioData[i]));
                        view.setInt16(dataOffset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                        dataOffset += 2;
                    }
                    
                    return new Blob([buffer], { type: 'audio/wav' });
                };
                
                // Simulate mediaRecorder interface for compatibility
                mediaRecorder = {
                    state: 'recording',
                    stop: () => {
                        mediaRecorder.state = 'inactive';
                        
                        // Disconnect processor
                        if (window.micScriptProcessor) {
                            window.micScriptProcessor.disconnect();
                            window.micScriptProcessor = null;
                        }
                        
                        // Create WAV blob
                        const audioBlob = window.createWavBlob();
                        
                        // Show preview
                        const preview = document.getElementById('mic-audio-preview');
                        const player = document.getElementById('mic-audio-player');
                        player.src = URL.createObjectURL(audioBlob);
                        preview.style.display = 'block';
                        
                        // Store blob for transcription
                        window.recordedAudioBlob = audioBlob;
                        
                        // Clean up
                        if (micStream) {
                            micStream.getTracks().forEach(track => track.stop());
                        }
                        if (audioContext) {
                            audioContext.close();
                            audioContext = null;
                        }
                    }
                };
                recordingStartTime = Date.now();
                
                // Update UI
                document.getElementById('mic-record-btn').classList.remove('btn-primary');
                document.getElementById('mic-record-btn').classList.add('btn-danger');
                document.getElementById('mic-record-btn').style.background = '#dc3545';
                document.getElementById('mic-record-icon').textContent = '‚èπÔ∏è';
                document.getElementById('mic-record-text').textContent = 'Stop Recording';
                
                // Start timer
                recordingTimer = setInterval(updateRecordingTime, 100);
                
            } catch (err) {
                console.error('Microphone access error:', err);
                showToast('Could not access microphone. Please allow microphone permissions.', 'error');
            }
        }
        
        function stopMicRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            
            // Clear timer
            if (recordingTimer) {
                clearInterval(recordingTimer);
                recordingTimer = null;
            }
            
            // Reset UI
            document.getElementById('mic-record-btn').classList.remove('btn-danger');
            document.getElementById('mic-record-btn').classList.add('btn-primary');
            document.getElementById('mic-record-btn').style.background = '';
            document.getElementById('mic-record-icon').textContent = 'üî¥';
            document.getElementById('mic-record-text').textContent = 'Start Recording';
            document.getElementById('mic-level-bar').style.width = '0%';
        }
        
        function updateRecordingTime() {
            if (!recordingStartTime) return;
            
            const elapsed = Date.now() - recordingStartTime;
            const seconds = Math.floor(elapsed / 1000);
            const minutes = Math.floor(seconds / 60);
            const secs = seconds % 60;
            
            document.getElementById('mic-recording-time').textContent = 
                `${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
        }
        
        function updateMicLevel() {
            if (!analyser) return;
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(dataArray);
            
            // Calculate average level
            const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
            const level = Math.min(100, (average / 128) * 100);
            
            document.getElementById('mic-level-bar').style.width = level + '%';
            
            // Continue updating while recording
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                requestAnimationFrame(updateMicLevel);
            }
        }

        async function transcribeAudio() {
            let audioFile;
            
            // Get audio from either file input or microphone recording
            if (currentInputSource === 'file') {
                const fileInput = document.getElementById('transcribe-audio');
                audioFile = fileInput.files[0];
                
                if (!audioFile) {
                    showToast('Please select an audio file first', 'warn');
                    return;
                }
            } else {
                // Microphone input
                if (!window.recordedAudioBlob) {
                    showToast('Please record audio first using the microphone', 'warn');
                    return;
                }
                
                // Convert blob to file (now always WAV)
                audioFile = new File([window.recordedAudioBlob], 'recording.wav', { type: 'audio/wav' });
            }
            
            const btn = document.getElementById('transcribe-btn');
            const status = document.getElementById('transcribe-status');
            const statusText = document.getElementById('transcribe-status-text');
            const progressDiv = document.getElementById('transcribe-progress');
            const progressBar = document.getElementById('transcribe-progress-bar');
            const segmentInfo = document.getElementById('transcribe-segment-info');
            const output = document.getElementById('transcription-output');
            const savedInfo = document.getElementById('transcription-saved');
            
            // Get all selector values - three independent options
            const device = document.getElementById('transcribe-device').value;
            const model = document.getElementById('transcribe-model').value;
            const endpoint = document.getElementById('transcribe-endpoint').value;
            
            btn.disabled = true;
            status.style.display = 'block';
            progressDiv.style.display = 'none';
            savedInfo.style.display = 'none';
            output.value = '';
            statusText.textContent = 'Starting transcription...';
            
            const formData = new FormData();
            formData.append('audio', audioFile);
            
            // Whisper handles punctuation natively
            
            const cleanVocals = document.getElementById('clean-vocals').checked;
            formData.append('clean_vocals', cleanVocals);
            
            const postprocessAudio = document.getElementById('postprocess-audio').checked;
            formData.append('postprocess_audio', postprocessAudio);
            
            const skipExistingVocals = document.getElementById('skip-existing-vocals').checked;
            formData.append('skip_existing_vocals', skipExistingVocals);
            
            // Pass device, model, and language
            formData.append('device', device);
            formData.append('model', model);
            
            const language = document.getElementById('transcribe-language').value;
            formData.append('language', language);
            
            // Save preferences to localStorage
            saveTranscribePreferences();
            
            try {
                // Endpoint choice is independent of device/model
                if (endpoint === 'streaming') {
                    await transcribeWithStreaming(formData, statusText, progressDiv, progressBar, segmentInfo, output);
                } else {
                    await transcribeWithBatch(formData, statusText, progressDiv, progressBar, output);
                }
                
                // Enable buttons
                document.getElementById('copy-transcription-btn').disabled = false;
                document.getElementById('use-for-tts-btn').disabled = false;
                
                // Save to file
                const transcription = output.value;
                if (transcription.trim()) {
                    await saveTranscription(transcription);
                }
                
                showToast('Transcription complete!', 'success');
                
            } catch (err) {
                console.error('Transcription error:', err);
                showToast(`Transcription failed: ${err.message}`, 'error');
            } finally {
                btn.disabled = false;
                status.style.display = 'none';
            }
        }
        
        async function transcribeWithBatch(formData, statusText, progressDiv, progressBar, output) {
            statusText.textContent = 'Transcribing (batch mode)...';
            progressDiv.style.display = 'block';
            progressBar.style.width = '50%';
            
            const response = await fetch('/api/transcribe', {
                method: 'POST',
                body: formData
            });
            
            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.detail || 'Transcription failed');
            }
            
            const result = await response.json();
            // Handle both response formats: {text: ...} or {transcription: ...}
            output.value = result.text || result.transcription || '';
            progressBar.style.width = '100%';
            statusText.textContent = 'Complete!';
        }
        
        async function transcribeWithOnnx(formData, statusText, progressDiv, progressBar, output) {
            statusText.textContent = 'Transcribing on CPU (ONNX)...';
            progressDiv.style.display = 'block';
            progressBar.style.width = '30%';
            
            const response = await fetch('/api/transcribe/onnx', {
                method: 'POST',
                body: formData
            });
            
            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.detail || 'ONNX transcription failed');
            }
            
            const result = await response.json();
            output.value = result.text || '';
            progressBar.style.width = '100%';
            statusText.textContent = 'Complete (CPU)!';
        }
        
        async function transcribeWithStreaming(formData, statusText, progressDiv, progressBar, segmentInfo, output) {
            const response = await fetch('/api/transcribe/stream', {
                method: 'POST',
                body: formData
            });
            
            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.detail || 'Transcription failed');
            }
            
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';
            let finalText = '';
            
            console.log('Starting to read SSE stream...');
            
            while (true) {
                const { done, value } = await reader.read();
                if (done) {
                    console.log('Stream ended');
                    break;
                }
                
                const chunk = decoder.decode(value, { stream: true });
                console.log('Received chunk:', chunk.length, 'bytes');
                buffer += chunk;
                
                // Parse SSE events (separated by double newlines)
                let eventEnd;
                while ((eventEnd = buffer.indexOf('\n\n')) !== -1) {
                    const eventBlock = buffer.slice(0, eventEnd);
                    buffer = buffer.slice(eventEnd + 2);
                    
                    // Parse lines in this event block
                    for (const line of eventBlock.split('\n')) {
                        if (line.startsWith('data: ')) {
                            try {
                                const event = JSON.parse(line.slice(6));
                                console.log('SSE Event:', event);
                                
                                switch (event.type) {
                                    case 'status':
                                        statusText.textContent = event.message || 'Processing...';
                                        if (event.progress !== undefined) {
                                            progressDiv.style.display = 'block';
                                            progressBar.style.width = event.progress + '%';
                                        }
                                        if (event.current_segment && event.total_segments) {
                                            segmentInfo.textContent = `Segment ${event.current_segment} of ${event.total_segments}`;
                                        }
                                        break;
                                    
                                    case 'text':
                                        // Real-time text update
                                        if (event.text) {
                                            output.value = event.text;
                                            output.scrollTop = output.scrollHeight;
                                        }
                                        if (event.progress !== undefined) {
                                            progressBar.style.width = event.progress + '%';
                                        }
                                        // Show segment info (Whisper streaming)
                                        if (event.segments !== undefined) {
                                            const durationInfo = event.duration_processed ? ` (${event.duration_processed.toFixed(1)}s processed)` : '';
                                            segmentInfo.textContent = `${event.segments} segments${durationInfo}`;
                                        }
                                        break;
                                    
                                    case 'segment':
                                        // Update output with accumulated text
                                        if (event.accumulated) {
                                            output.value = event.accumulated;
                                            output.scrollTop = output.scrollHeight;
                                        }
                                        if (event.segment && event.total) {
                                            segmentInfo.textContent = `Completed segment ${event.segment} of ${event.total}`;
                                        }
                                        break;
                                    
                                    case 'complete':
                                        finalText = event.text || output.value;
                                        output.value = finalText;
                                        progressBar.style.width = '100%';
                                        statusText.textContent = 'Complete!';
                                        break;
                                    
                                    case 'error':
                                        throw new Error(event.message || 'Transcription failed');
                                }
                            } catch (parseErr) {
                                if (parseErr.message !== 'Transcription failed') {
                                    console.warn('Failed to parse SSE event:', line);
                                } else {
                                    throw parseErr;
                                }
                            }
                        }
                    }
                }
            }
            
            // Use final text from complete event, or what we have
            output.value = finalText || output.value;
        }
        
        async function saveTranscription(text) {
            try {
                const response = await fetch('/api/save-transcription', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text })
                });
                
                if (response.ok) {
                    const result = await response.json();
                    const savedInfo = document.getElementById('transcription-saved');
                    const filename = document.getElementById('transcription-filename');
                    filename.textContent = result.filename;
                    savedInfo.style.display = 'block';
                }
            } catch (err) {
                console.error('Failed to save transcription:', err);
            }
        }
        
        function copyTranscription() {
            const output = document.getElementById('transcription-output');
            if (output.value) {
                navigator.clipboard.writeText(output.value).then(() => {
                    showToast('Copied to clipboard!', 'success');
                }).catch(() => {
                    // Fallback
                    output.select();
                    document.execCommand('copy');
                    showToast('Copied to clipboard!', 'success');
                });
            }
        }
        
        function useTranscriptionAsTTS() {
            const output = document.getElementById('transcription-output');
            if (output.value) {
                // Switch to TTS tab
                switchTab(0);
                // Set the text input
                const textInput = document.getElementById('text-input');
                if (textInput) {
                    textInput.value = output.value;
                    showToast('Transcription loaded into TTS input', 'success');
                }
            }
        }

        // ============================================================================
        // ComfyUI Integration
        // ============================================================================
        
        let currentComfyUIWorkflow = null;
        
        async function launchComfyUI() {
            const pathInput = document.getElementById('comfyui-path');
            const statusEl = document.getElementById('comfyui-status');
            const btn = document.getElementById('launch-comfyui-btn');
            
            const comfyuiPath = pathInput.value.trim();
            
            if (!comfyuiPath) {
                statusEl.textContent = '‚ö†Ô∏è Please enter ComfyUI path first';
                statusEl.className = 'status warning';
                return;
            }
            
            btn.disabled = true;
            btn.innerHTML = '<span>‚è≥</span> Starting...';
            statusEl.textContent = 'Launching ComfyUI...';
            statusEl.className = 'status';
            
            // Save settings first
            saveSettings();
            
            try {
                const response = await fetch('/api/comfyui/launch', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ path: comfyuiPath })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    statusEl.innerHTML = 'üöÄ ComfyUI is starting... <small>(wait 10-30 seconds, then click Connect)</small>';
                    statusEl.className = 'status success';
                    
                    // Auto-try to connect after a delay
                    setTimeout(() => {
                        statusEl.textContent = 'Attempting to connect...';
                        testComfyUIConnection();
                    }, 15000);
                } else {
                    statusEl.textContent = '‚ùå ' + (data.error || 'Failed to launch ComfyUI');
                    statusEl.className = 'status error';
                }
            } catch (error) {
                statusEl.textContent = '‚ùå Error: ' + error.message;
                statusEl.className = 'status error';
            } finally {
                btn.disabled = false;
                btn.innerHTML = '<span>üöÄ</span> Launch';
            }
        }
        
        async function testComfyUIConnection() {
            const urlInput = document.getElementById('comfyui-url');
            const statusEl = document.getElementById('comfyui-status');
            const infoEl = document.getElementById('comfyui-info');
            const btn = document.getElementById('comfyui-connect-btn');
            
            const comfyuiUrl = urlInput.value.trim() || 'http://127.0.0.1:8188';
            
            btn.disabled = true;
            statusEl.textContent = 'Connecting to ' + comfyuiUrl + '...';
            statusEl.className = 'status';
            
            // Save the URL to settings first
            saveSettings();
            
            try {
                // Pass the URL as a query parameter so the backend uses it immediately
                const response = await fetch('/api/comfyui/status?url=' + encodeURIComponent(comfyuiUrl));
                const data = await response.json();
                
                if (data.connected) {
                    statusEl.textContent = '‚úì Connected to ComfyUI server';
                    statusEl.className = 'status success';
                    infoEl.style.display = 'block';
                    
                    // Update info
                    document.getElementById('comfyui-connection-status').textContent = 'üü¢ Online';
                    document.getElementById('comfyui-node-count').textContent = data.node_count || '-';
                    document.getElementById('comfyui-queue-status').textContent = 
                        `${data.queue?.pending || 0} pending, ${data.queue?.running || 0} running`;
                    
                    // VRAM info if available
                    if (data.system_stats?.devices) {
                        const gpu = data.system_stats.devices[0];
                        if (gpu && gpu.vram_total) {
                            const usedGB = (gpu.vram_total - gpu.vram_free) / (1024 * 1024 * 1024);
                            const totalGB = gpu.vram_total / (1024 * 1024 * 1024);
                            document.getElementById('comfyui-vram').textContent = 
                                `${usedGB.toFixed(1)} / ${totalGB.toFixed(1)} GB`;
                        }
                    }
                    
                    // Auto-refresh workflows
                    refreshComfyUIWorkflows();
                    
                    showToast('Connected to ComfyUI', 'success');
                } else {
                    statusEl.textContent = `‚úó ${data.error || 'Connection failed'}`;
                    statusEl.className = 'status error';
                    infoEl.style.display = 'none';
                    showToast('ComfyUI connection failed', 'error');
                }
            } catch (err) {
                statusEl.textContent = `‚úó Error: ${err.message}`;
                statusEl.className = 'status error';
                infoEl.style.display = 'none';
                showToast('ComfyUI connection error', 'error');
            } finally {
                btn.disabled = false;
            }
        }
        
        async function refreshComfyUIWorkflows() {
            const listEl = document.getElementById('comfyui-workflows-list');
            listEl.innerHTML = '<div style="color: var(--text-muted); padding: 20px; text-align: center;">Loading workflows...</div>';
            
            try {
                // Get the ComfyUI path from the input field
                const pathInput = document.getElementById('comfyui-path');
                const comfyuiPath = pathInput ? pathInput.value.trim() : '';
                
                // Build URL with optional path parameter
                let url = '/api/comfyui/workflows';
                if (comfyuiPath) {
                    url += '?path=' + encodeURIComponent(comfyuiPath);
                }
                
                const response = await fetch(url);
                const data = await response.json();
                
                if (data.workflows && data.workflows.length > 0) {
                    listEl.innerHTML = '';
                    
                    // Group workflows by source
                    const localWorkflows = data.workflows.filter(wf => wf.source === 'local');
                    const comfyuiWorkflows = data.workflows.filter(wf => wf.source === 'comfyui' || wf.source === 'comfyui_fs' || wf.source === 'comfyui_userdata');
                    const userTemplateWorkflows = data.workflows.filter(wf => wf.source === 'user_template');
                    const templateWorkflows = data.workflows.filter(wf => wf.source === 'template');
                    
                    // Helper to create workflow item
                    const createWorkflowItem = (wf) => {
                        const item = document.createElement('div');
                        item.style.cssText = 'display: flex; align-items: center; justify-content: space-between; padding: 10px; background: var(--input-bg); border: 1px solid var(--border); border-radius: var(--radius-md); cursor: pointer; transition: all 0.2s;';
                        item.onmouseenter = () => item.style.borderColor = 'var(--accent)';
                        item.onmouseleave = () => item.style.borderColor = 'var(--border)';
                        
                        const typeColors = {
                            'SDXL': '#ff6b6b',
                            'SD3': '#4ecdc4',
                            'Flux': '#a855f7',
                            'SD1.5/SD2': '#3b82f6',
                            'Upscale': '#f59e0b',
                            'ControlNet': '#10b981',
                            'template': '#06b6d4'
                        };
                        const typeColor = typeColors[wf.workflow_type] || 'var(--text-muted)';
                        
                        const info = document.createElement('div');
                        info.innerHTML = `
                            <div style="display: flex; align-items: center; gap: 6px; flex-wrap: wrap;">
                                <span style="font-weight: 600; color: var(--text); font-size: 12px;">${wf.name}</span>
                                ${wf.workflow_type && wf.workflow_type !== 'unknown' ? 
                                    `<span style="font-size: 9px; padding: 2px 5px; background: ${typeColor}22; color: ${typeColor}; border-radius: 4px; font-weight: 600;">${wf.workflow_type}</span>` 
                                    : ''}
                                ${wf.is_api_format === false ? 
                                    `<span style="font-size: 9px; padding: 2px 5px; background: #f59e0b22; color: #f59e0b; border-radius: 4px;" title="GUI format - may need conversion">GUI</span>` 
                                    : ''}
                            </div>
                            <div style="font-size: 11px; color: var(--text-muted); margin-top: 3px;">
                                ${wf.node_count ? `${wf.node_count} nodes` : ''}${wf.has_prompt ? ' ‚Ä¢ ‚úèÔ∏è Prompt' : ''}${wf.has_sampler ? ' ‚Ä¢ üé≤ Sampler' : ''}${wf.node_name ? `From: ${wf.node_name}` : ''}
                            </div>
                        `;
                        
                        const loadBtn = document.createElement('button');
                        loadBtn.className = 'btn btn-secondary';
                        loadBtn.innerHTML = '<span>üìÇ</span> Load';
                        loadBtn.onclick = (e) => {
                            e.stopPropagation();
                            loadComfyUIWorkflow(wf.name, wf.source, wf.path);
                        };
                        
                        item.appendChild(info);
                        item.appendChild(loadBtn);
                        item.onclick = () => loadComfyUIWorkflow(wf.name, wf.source, wf.path);
                        return item;
                    };
                    
                    // Add local workflows section
                    if (localWorkflows.length > 0) {
                        const header = document.createElement('div');
                        header.style.cssText = 'font-size: 11px; color: var(--text-muted); margin-bottom: 8px; text-transform: uppercase; letter-spacing: 1px;';
                        header.textContent = `üìÅ Local Workflows (${localWorkflows.length})`;
                        listEl.appendChild(header);
                        
                        for (const wf of localWorkflows) {
                            listEl.appendChild(createWorkflowItem(wf));
                        }
                    }
                    
                    // Add ComfyUI workflows section
                    if (comfyuiWorkflows.length > 0) {
                        const header = document.createElement('div');
                        header.style.cssText = 'font-size: 10px; color: var(--accent); margin: 12px 0 6px 0; text-transform: uppercase; letter-spacing: 1px;';
                        header.textContent = `üñ•Ô∏è ComfyUI Saved Workflows (${comfyuiWorkflows.length})`;
                        listEl.appendChild(header);
                        
                        for (const wf of comfyuiWorkflows) {
                            listEl.appendChild(createWorkflowItem(wf));
                        }
                    }
                    
                    // Add user templates section
                    if (userTemplateWorkflows.length > 0) {
                        const header = document.createElement('div');
                        header.style.cssText = 'font-size: 10px; color: #a855f7; margin: 12px 0 6px 0; text-transform: uppercase; letter-spacing: 1px;';
                        header.textContent = `‚≠ê User Saved Templates (${userTemplateWorkflows.length})`;
                        listEl.appendChild(header);
                        
                        for (const wf of userTemplateWorkflows) {
                            listEl.appendChild(createWorkflowItem(wf));
                        }
                    }
                    
                    // Add custom node template workflows section (collapsible)
                    if (templateWorkflows.length > 0) {
                        const container = document.createElement('div');
                        container.style.cssText = 'margin-top: 12px;';
                        
                        const header = document.createElement('div');
                        header.style.cssText = 'font-size: 10px; color: #06b6d4; margin-bottom: 6px; text-transform: uppercase; letter-spacing: 1px; cursor: pointer; display: flex; align-items: center; gap: 5px; user-select: none;';
                        header.innerHTML = `<span class="template-toggle" style="transition: transform 0.2s;">‚ñ∂</span> üì¶ Custom Node Templates (${templateWorkflows.length})`;
                        
                        const content = document.createElement('div');
                        content.style.cssText = 'display: none; flex-direction: column; gap: 6px;';
                        
                        header.onclick = () => {
                            const isOpen = content.style.display !== 'none';
                            content.style.display = isOpen ? 'none' : 'flex';
                            header.querySelector('.template-toggle').style.transform = isOpen ? '' : 'rotate(90deg)';
                        };
                        
                        for (const wf of templateWorkflows) {
                            content.appendChild(createWorkflowItem(wf));
                        }
                        
                        container.appendChild(header);
                        container.appendChild(content);
                        listEl.appendChild(container);
                    }
                    
                    // Show connection hint if not connected
                    if (!data.comfyui_connected && comfyuiWorkflows.length === 0) {
                        const hint = document.createElement('div');
                        hint.style.cssText = 'font-size: 11px; color: var(--text-dim); margin-top: 10px; text-align: center;';
                        hint.innerHTML = 'üí° Connect to ComfyUI above to see your saved workflows';
                        listEl.appendChild(hint);
                    }
                } else {
                    listEl.innerHTML = `
                        <div style="color: var(--text-muted); padding: 20px; text-align: center;">
                            No workflows found.<br>
                            <small>Upload a workflow JSON or connect to ComfyUI to browse saved workflows</small>
                        </div>
                    `;
                }
            } catch (err) {
                listEl.innerHTML = `<div style="color: var(--danger); padding: 20px; text-align: center;">Error loading workflows: ${err.message}</div>`;
            }
        }
        
        async function loadComfyUIWorkflow(name, source = 'local', filePath = null) {
            const execSection = document.getElementById('comfyui-execution-section');
            const nameEl = document.getElementById('comfyui-workflow-name');
            const inputsEl = document.getElementById('comfyui-workflow-inputs');
            
            try {
                // Build URL with source and optional path for filesystem workflows
                let url = `/api/comfyui/workflow/${encodeURIComponent(name)}?source=${source}`;
                if (filePath) {
                    url += `&path=${encodeURIComponent(filePath)}`;
                }
                const response = await fetch(url);
                if (!response.ok) throw new Error('Failed to load workflow');
                
                const data = await response.json();
                currentComfyUIWorkflow = data.workflow;
                
                nameEl.textContent = `üìÑ ${data.name}`;
                inputsEl.innerHTML = '';
                
                // Create input fields for detected parameters
                if (data.inputs && data.inputs.length > 0) {
                    // Group inputs by node for better organization
                    let currentNodeId = null;
                    let currentNodeSection = null;
                    
                    for (const input of data.inputs) {
                        // Create node section header if this is a new node
                        if (input.node_id !== currentNodeId) {
                            currentNodeId = input.node_id;
                            currentNodeSection = document.createElement('div');
                            currentNodeSection.style.cssText = 'margin-bottom: 12px; padding: 10px; background: var(--input-bg); border: 1px solid var(--border); border-radius: var(--radius-md);';
                            
                            const header = document.createElement('div');
                            header.style.cssText = 'font-size: 11px; color: var(--accent); margin-bottom: 10px; font-weight: 600;';
                            header.textContent = `${input.node_title || input.class_type} (${input.node_id})`;
                            currentNodeSection.appendChild(header);
                            
                            inputsEl.appendChild(currentNodeSection);
                        }
                        
                        const group = document.createElement('div');
                        group.className = 'form-group';
                        group.style.marginBottom = '10px';
                        
                        const inputId = `comfyui-input-${input.node_id}-${input.param}`;
                        const tooltip = `Node: ${input.class_type}${input.required ? ' (required)' : ''}`;
                        
                        if (input.type === 'string') {
                            const rows = input.multiline ? 4 : 2;
                            const isPrompt = input.param === 'text' || input.label.toLowerCase().includes('prompt');
                            group.innerHTML = `
                                <label class="label-with-help">
                                    ${input.label}${input.required ? ' *' : ''}
                                    <span class="help-icon" title="${tooltip}">?</span>
                                </label>
                                <textarea id="${inputId}" 
                                    data-node-id="${input.node_id}" 
                                    data-param="${input.param}"
                                    data-type="string"
                                    data-class-type="${input.class_type}"
                                    rows="${isPrompt ? 4 : rows}" 
                                    style="width: 100%;"
                                    placeholder="${isPrompt ? 'Enter your prompt here...' : ''}"
                                >${input.value || ''}</textarea>
                            `;
                        } else if (input.type === 'int') {
                            const min = input.min !== undefined ? input.min : '';
                            const max = input.max !== undefined ? input.max : '';
                            const step = input.step || 1;
                            group.innerHTML = `
                                <label class="label-with-help">
                                    ${input.label}${input.required ? ' *' : ''}
                                    <span class="help-icon" title="${tooltip}${min !== '' ? ` (${min} - ${max})` : ''}">?</span>
                                </label>
                                <input type="number" id="${inputId}"
                                    data-node-id="${input.node_id}" 
                                    data-param="${input.param}"
                                    data-type="int"
                                    data-class-type="${input.class_type}"
                                    value="${input.value !== undefined ? input.value : 0}"
                                    ${min !== '' ? `min="${min}"` : ''}
                                    ${max !== '' ? `max="${max}"` : ''}
                                    step="${step}">
                            `;
                        } else if (input.type === 'float') {
                            const min = input.min !== undefined ? input.min : '';
                            const max = input.max !== undefined ? input.max : '';
                            const step = input.step || 0.01;
                            group.innerHTML = `
                                <label class="label-with-help">
                                    ${input.label}${input.required ? ' *' : ''}
                                    <span class="help-icon" title="${tooltip}${min !== '' ? ` (${min} - ${max})` : ''}">?</span>
                                </label>
                                <input type="number" id="${inputId}"
                                    data-node-id="${input.node_id}" 
                                    data-param="${input.param}"
                                    data-type="float"
                                    data-class-type="${input.class_type}"
                                    value="${input.value !== undefined ? input.value : 0}"
                                    ${min !== '' ? `min="${min}"` : ''}
                                    ${max !== '' ? `max="${max}"` : ''}
                                    step="${step}">
                            `;
                        } else if (input.type === 'boolean') {
                            group.innerHTML = `
                                <label class="checkbox-label">
                                    <input type="checkbox" id="${inputId}"
                                        data-node-id="${input.node_id}" 
                                        data-param="${input.param}"
                                        data-type="boolean"
                                        data-class-type="${input.class_type}"
                                        ${input.value ? 'checked' : ''}>
                                    <span>${input.label}${input.required ? ' *' : ''}</span>
                                    <span class="help-icon" title="${tooltip}" style="margin-left: 4px;">?</span>
                                </label>
                            `;
                        } else if (input.type === 'enum') {
                            const options = (input.options || []).map(opt => 
                                `<option value="${opt}" ${opt === input.value ? 'selected' : ''}>${opt}</option>`
                            ).join('');
                            group.innerHTML = `
                                <label class="label-with-help">
                                    ${input.label}${input.required ? ' *' : ''}
                                    <span class="help-icon" title="${tooltip}">?</span>
                                </label>
                                <select id="${inputId}"
                                    data-node-id="${input.node_id}" 
                                    data-param="${input.param}"
                                    data-type="enum"
                                    data-class-type="${input.class_type}">
                                    ${options}
                                </select>
                            `;
                        }
                        
                        if (currentNodeSection) {
                            currentNodeSection.appendChild(group);
                        } else {
                            inputsEl.appendChild(group);
                        }
                    }
                    
                    // Add info about node definitions and format
                    const info = document.createElement('div');
                    info.style.cssText = 'font-size: 10px; color: var(--text-dim); margin-top: 12px; text-align: center;';
                    let infoText = `‚úì ${data.inputs.length} editable parameters detected`;
                    if (data.is_gui_format) {
                        infoText += ' (converted from GUI format)';
                    }
                    if (data.has_node_defs) {
                        infoText += ' via ComfyUI';
                    }
                    info.textContent = infoText;
                    inputsEl.appendChild(info);
                } else {
                    let noInputsMsg = '<div style="color: var(--text-muted); padding: 20px; text-align: center;">';
                    noInputsMsg += 'No editable inputs detected in this workflow.<br>';
                    noInputsMsg += '<small>';
                    if (data.is_gui_format && !data.has_node_defs) {
                        noInputsMsg += 'Tip: Make sure ComfyUI is running to detect input parameters from GUI format workflows.';
                    } else {
                        noInputsMsg += 'This workflow may only have connected nodes with no user-configurable parameters.';
                    }
                    noInputsMsg += '</small></div>';
                    inputsEl.innerHTML = noInputsMsg;
                }
                
                execSection.style.display = 'block';
                const formatInfo = data.is_gui_format ? ' [GUI‚ÜíAPI converted]' : '';
                showToast(`Loaded workflow: ${data.name} (${data.inputs?.length || 0} inputs)${formatInfo}`, 'success');
                
            } catch (err) {
                showToast(`Error loading workflow: ${err.message}`, 'error');
            }
        }
        
        async function uploadComfyUIWorkflow(input) {
            const file = input.files[0];
            if (!file) return;
            
            try {
                const formData = new FormData();
                formData.append('file', file);
                
                const response = await fetch('/api/comfyui/workflow/upload', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.detail || 'Upload failed');
                }
                
                showToast(`Uploaded workflow: ${file.name}`, 'success');
                refreshComfyUIWorkflows();
                
            } catch (err) {
                showToast(`Upload error: ${err.message}`, 'error');
            }
            
            // Reset input
            input.value = '';
        }
        
        async function executeComfyUIWorkflow() {
            if (!currentComfyUIWorkflow) {
                showToast('No workflow loaded', 'warn');
                return;
            }
            
            const btn = document.getElementById('execute-workflow-btn');
            const statusEl = document.getElementById('comfyui-execution-status');
            const resultEl = document.getElementById('comfyui-result');
            const imagesEl = document.getElementById('comfyui-result-images');
            
            btn.disabled = true;
            statusEl.style.display = 'block';
            statusEl.textContent = 'Submitting workflow...';
            statusEl.className = 'status';
            resultEl.style.display = 'none';
            imagesEl.innerHTML = '';
            
            // Update workflow with user inputs
            const workflow = JSON.parse(JSON.stringify(currentComfyUIWorkflow));
            const inputElements = document.querySelectorAll('[data-node-id][data-param]');
            for (const inputEl of inputElements) {
                const nodeId = inputEl.dataset.nodeId;
                const param = inputEl.dataset.param;
                const inputType = inputEl.dataset.type;
                
                // Ensure node exists in workflow
                if (!workflow[nodeId]) {
                    // Get the class type from the data attribute
                    const classType = inputEl.dataset.classType || 'Unknown';
                    workflow[nodeId] = {
                        class_type: classType,
                        inputs: {}
                    };
                }
                
                // Ensure inputs object exists
                if (!workflow[nodeId].inputs) {
                    workflow[nodeId].inputs = {};
                }
                
                let value;
                
                // Parse value based on input type
                switch (inputType) {
                    case 'int':
                        value = parseInt(inputEl.value) || 0;
                        break;
                    case 'float':
                        value = parseFloat(inputEl.value) || 0.0;
                        break;
                    case 'boolean':
                        value = inputEl.checked;
                        break;
                    case 'string':
                    case 'enum':
                    default:
                        value = inputEl.value;
                        break;
                }
                
                workflow[nodeId].inputs[param] = value;
            }
            
            try {
                const response = await fetch('/api/comfyui/execute', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ workflow })
                });
                
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.detail || 'Execution failed');
                }
                
                const data = await response.json();
                statusEl.textContent = `Queued (ID: ${data.prompt_id})... Waiting for result...`;
                
                // Poll for result
                const promptId = data.prompt_id;
                let attempts = 0;
                const maxAttempts = 120; // 2 minutes max
                
                const checkResult = async () => {
                    attempts++;
                    try {
                        const historyResponse = await fetch(`/api/comfyui/history/${promptId}`);
                        const history = await historyResponse.json();
                        
                        if (history[promptId]) {
                            const outputs = history[promptId].outputs;
                            statusEl.textContent = '‚úì Execution complete!';
                            statusEl.className = 'status success';
                            
                            // Clear previous images before adding new ones
                            imagesEl.innerHTML = '';
                            
                            // Find images in outputs
                            let foundImages = false;
                            const cacheBuster = Date.now();
                            for (const nodeId in outputs) {
                                const nodeOutput = outputs[nodeId];
                                if (nodeOutput.images) {
                                    foundImages = true;
                                    for (const img of nodeOutput.images) {
                                        const imgEl = document.createElement('img');
                                        // Add cache-busting parameter to prevent browser caching old images
                                        imgEl.src = `/api/comfyui/view?filename=${encodeURIComponent(img.filename)}&subfolder=${encodeURIComponent(img.subfolder || '')}&type=${img.type || 'output'}&t=${cacheBuster}`;
                                        imgEl.style.cssText = 'max-width: 100%; max-height: 400px; border-radius: var(--radius-md); border: 1px solid var(--border);';
                                        imagesEl.appendChild(imgEl);
                                    }
                                }
                            }
                            
                            if (foundImages) {
                                resultEl.style.display = 'block';
                            }
                            
                            btn.disabled = false;
                            showToast('Workflow execution complete!', 'success');
                            return;
                        }
                        
                        if (attempts < maxAttempts) {
                            statusEl.textContent = `Executing... (${attempts}s)`;
                            setTimeout(checkResult, 1000);
                        } else {
                            throw new Error('Timeout waiting for result');
                        }
                    } catch (err) {
                        if (attempts < maxAttempts && !err.message.includes('Timeout')) {
                            setTimeout(checkResult, 1000);
                        } else {
                            throw err;
                        }
                    }
                };
                
                setTimeout(checkResult, 1000);
                
            } catch (err) {
                statusEl.textContent = `‚úó Error: ${err.message}`;
                statusEl.className = 'status error';
                btn.disabled = false;
                showToast(`Execution error: ${err.message}`, 'error');
            }
        }

        // ============================================================================
        // TTS Training Integration
        // ============================================================================
        
        const TRAINING_SERVER_URL = 'http://127.0.0.1:8895';
        const CHATTERBOX_URL = 'http://127.0.0.1:8893';
        const SOPRANO_URL = 'http://127.0.0.1:8894';
        let trainingWebSocket = null;
        let currentTrainingJobId = null;
        let trainingPollInterval = null;
        
        // HTTP polling fallback for training progress
        function startTrainingPolling(jobId) {
            if (trainingPollInterval) {
                clearInterval(trainingPollInterval);
            }
            
            console.log('[Training] Starting HTTP polling for job:', jobId);
            
            // Do an immediate poll
            pollJobStatus(jobId);
            
            // Poll every 5 seconds (less aggressive to not interfere with training)
            trainingPollInterval = setInterval(() => pollJobStatus(jobId), 5000);
        }
        
        async function pollJobStatus(jobId) {
            if (!jobId) {
                stopTrainingPolling();
                return;
            }
            
            const logEl = document.getElementById('training-log');
            const progressText = document.getElementById('training-progress-text');
            
            try {
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/jobs/${jobId}`);
                
                if (!res.ok) {
                    return;
                }
                
                const data = await res.json();
                
                // Update progress text with status
                if (data.status === 'running') {
                    if (data.progress && Object.keys(data.progress).length > 0) {
                        // Show progress in log
                        const p = data.progress;
                        let progressMsg = '';
                        if (p.step && p.total_steps) {
                            progressMsg = `Step ${p.step}/${p.total_steps}`;
                        } else if (p.epoch) {
                            progressMsg = `Epoch ${p.epoch}`;
                        }
                        if (p.loss) {
                            progressMsg += ` | Loss: ${p.loss.toFixed(4)}`;
                        }
                        if (progressMsg) {
                            progressText.textContent = progressMsg;
                        }
                        
                        handleTrainingProgress({
                            type: 'progress',
                            ...data.progress
                        });
                    } else {
                        progressText.textContent = 'Training in progress (waiting for first update)...';
                    }
                }
                
                // Check for completion
                if (data.status === 'completed') {
                    logEl.innerHTML += `<div style="color: var(--success);">[${new Date().toLocaleTimeString()}] Training completed!</div>`;
                    handleTrainingProgress({
                        type: 'status',
                        status: 'completed',
                        output_model: data.output_model
                    });
                    stopTrainingPolling();
                } else if (data.status === 'failed') {
                    logEl.innerHTML += `<div style="color: var(--danger);">[${new Date().toLocaleTimeString()}] Training failed: ${data.error}</div>`;
                    handleTrainingProgress({
                        type: 'status',
                        status: 'failed',
                        error: data.error
                    });
                    stopTrainingPolling();
                }
            } catch (e) {
                console.error('[Training] Polling error:', e);
            }
        }
        
        function stopTrainingPolling() {
            if (trainingPollInterval) {
                clearInterval(trainingPollInterval);
                trainingPollInterval = null;
            }
        }
        
        // Update UI based on selected training backend
        function updateTrainingUI() {
            const backend = document.getElementById('training-backend').value;
            const sopranoConfig = document.getElementById('soprano-training-config');
            const chatterboxConfig = document.getElementById('chatterbox-training-config');
            const hint = document.getElementById('training-backend-hint');
            
            if (backend === 'soprano') {
                sopranoConfig.style.display = 'block';
                chatterboxConfig.style.display = 'none';
                hint.textContent = 'Soprano: 80M params, very fast training. Creates a custom voice model.';
            } else {
                sopranoConfig.style.display = 'none';
                chatterboxConfig.style.display = 'block';
                hint.textContent = 'Chatterbox: Full voice cloning with audio prompts. Supports both Standard (Llama) and Turbo (GPT-2) modes.';
            }
        }
        
        // Toggle LoRA settings visibility
        function toggleLoraSettings() {
            const useLoraCheckbox = document.getElementById('soprano-use-lora');
            const loraSettings = document.getElementById('soprano-lora-settings');
            if (useLoraCheckbox && loraSettings) {
                loraSettings.style.display = useLoraCheckbox.checked ? 'flex' : 'none';
            }
        }
        
        // Initialize LoRA toggle listener
        document.addEventListener('DOMContentLoaded', () => {
            const useLoraCheckbox = document.getElementById('soprano-use-lora');
            if (useLoraCheckbox) {
                useLoraCheckbox.addEventListener('change', toggleLoraSettings);
                toggleLoraSettings(); // Set initial state
            }
        });
        
        // Dataset mode toggle
        function setDatasetMode(mode) {
            const simpleBtn = document.getElementById('dataset-mode-simple');
            const advancedBtn = document.getElementById('dataset-mode-advanced');
            const simpleMode = document.getElementById('dataset-simple-mode');
            const advancedMode = document.getElementById('dataset-advanced-mode');
            
            if (mode === 'simple') {
                simpleBtn.classList.add('active');
                advancedBtn.classList.remove('active');
                simpleMode.style.display = 'block';
                advancedMode.style.display = 'none';
            } else {
                simpleBtn.classList.remove('active');
                advancedBtn.classList.add('active');
                simpleMode.style.display = 'none';
                advancedMode.style.display = 'block';
                loadDatasets();
            }
        }
        
        // Browse for dataset folder (simple mode)
        function browseDatasetFolder() {
            // In browser context, prompt user to enter path
            const path = prompt('Enter the full path to your dataset folder:');
            if (path) {
                document.getElementById('training-dataset-path').value = path;
                validateDataset();
            }
        }
        
        // Validate dataset folder
        async function validateDataset() {
            const path = document.getElementById('training-dataset-path').value;
            if (!path) {
                showToast('Please enter a dataset path', 'error');
                return;
            }
            
            const statusDiv = document.getElementById('dataset-validation-status');
            const messageDiv = document.getElementById('dataset-validation-message');
            
            try {
                const formData = new FormData();
                formData.append('path', path);
                
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/validate`, {
                    method: 'POST',
                    body: formData
                });
                
                const data = await res.json();
                
                statusDiv.style.display = 'block';
                
                if (data.valid) {
                    statusDiv.style.background = 'rgba(76, 175, 80, 0.1)';
                    statusDiv.style.border = '1px solid var(--success)';
                    messageDiv.innerHTML = `
                        <div style="color: var(--success); font-weight: bold;">Dataset Valid</div>
                        <div style="color: var(--text-muted); margin-top: 4px;">Samples: ${data.samples}</div>
                    `;
                } else {
                    statusDiv.style.background = 'rgba(244, 67, 54, 0.1)';
                    statusDiv.style.border = '1px solid var(--danger)';
                    messageDiv.innerHTML = `
                        <div style="color: var(--danger); font-weight: bold;">Validation Failed</div>
                        <ul style="color: var(--text-muted); margin-top: 4px; margin-left: 20px;">
                            ${data.errors.map(e => `<li>${e}</li>`).join('')}
                        </ul>
                    `;
                }
            } catch (err) {
                statusDiv.style.display = 'block';
                statusDiv.style.background = 'rgba(244, 67, 54, 0.1)';
                statusDiv.style.border = '1px solid var(--danger)';
                messageDiv.innerHTML = `
                    <div style="color: var(--danger);">Error connecting to training server</div>
                    <div style="color: var(--text-muted); margin-top: 4px;">Make sure the training server is running on port 8895</div>
                `;
            }
        }
        
        // Load available datasets
        async function loadDatasets() {
            try {
                console.log('[loadDatasets] Fetching from:', `${TRAINING_SERVER_URL}/v1/datasets`);
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets`);
                const data = await res.json();
                console.log('[loadDatasets] Response:', data);
                
                const backend = document.getElementById('training-backend').value;
                console.log('[loadDatasets] Backend:', backend);
                const select = document.getElementById('training-dataset-select');
                
                select.innerHTML = '<option value="">-- Select dataset --</option>';
                
                const datasets = data[backend] || [];
                console.log('[loadDatasets] Datasets for backend:', datasets);
                datasets.forEach(ds => {
                    const opt = document.createElement('option');
                    opt.value = ds.path;
                    opt.textContent = `${ds.name} (${ds.samples} samples)${ds.valid ? '' : ' - Invalid'}`;
                    select.appendChild(opt);
                });
            } catch (err) {
                console.error('Failed to load datasets:', err);
            }
        }
        
        // Select dataset
        async function selectDataset() {
            const select = document.getElementById('training-dataset-select');
            const uploadSection = document.getElementById('dataset-upload-section');
            const filesList = document.getElementById('training-files-list');
            
            if (select.value) {
                uploadSection.style.display = 'block';
                document.getElementById('training-dataset-path').value = select.value;
                await refreshDatasetFiles();
            } else {
                uploadSection.style.display = 'none';
                filesList.style.display = 'none';
            }
        }
        
        // Refresh files list for selected dataset
        async function refreshDatasetFiles() {
            const backend = document.getElementById('training-backend').value;
            const datasetPath = document.getElementById('training-dataset-select').value;
            const datasetName = datasetPath.split(/[\\/]/).pop();
            
            if (!datasetName) return;
            
            const filesList = document.getElementById('training-files-list');
            const filesContainer = document.getElementById('training-files-container');
            const filesCount = document.getElementById('training-files-count');
            
            try {
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/${backend}/${datasetName}/files`);
                if (res.ok) {
                    const data = await res.json();
                    
                    if (data.files && data.files.length > 0) {
                        filesList.style.display = 'block';
                        filesCount.textContent = `(${data.total} files, ${data.transcribed_count} transcribed)`;
                        filesContainer.innerHTML = data.files.map(f => `
                            <div style="padding: 8px; border-bottom: 1px solid var(--border); display: flex; justify-content: space-between; align-items: center;">
                                <span style="word-break: break-all; margin-right: 10px;">${f.name}</span>
                                <span style="color: ${f.transcribed ? 'var(--success)' : 'var(--text-muted)'}; font-size: 12px; white-space: nowrap;">${f.transcribed ? '‚úì Transcribed' : 'No transcript'}</span>
                            </div>
                        `).join('');
                    } else {
                        filesContainer.innerHTML = '<div style="color: var(--text-muted); padding: 8px;">No files yet. Upload audio files above.</div>';
                        filesCount.textContent = '(0 files)';
                        filesList.style.display = 'block';
                    }
                }
            } catch (err) {
                console.error('Failed to load dataset files:', err);
            }
        }
        
        // Create new dataset
        async function createNewDataset() {
            const name = document.getElementById('new-dataset-name').value.trim();
            if (!name) {
                showToast('Please enter a dataset name', 'error');
                return;
            }
            
            const backend = document.getElementById('training-backend').value;
            
            try {
                const formData = new FormData();
                formData.append('name', name);
                formData.append('backend', backend);
                
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/create`, {
                    method: 'POST',
                    body: formData
                });
                
                const data = await res.json();
                
                if (data.success) {
                    showToast(`Dataset '${data.name}' created`, 'success');
                    document.getElementById('new-dataset-name').value = '';
                    loadDatasets();
                } else {
                    showToast(data.detail || 'Failed to create dataset', 'error');
                }
            } catch (err) {
                showToast(`Error: ${err.message}`, 'error');
            }
        }
        
        // Delete selected dataset
        async function deleteSelectedDataset() {
            const backend = document.getElementById('training-backend').value;
            const datasetPath = document.getElementById('training-dataset-select').value;
            const datasetName = datasetPath.split(/[\\/]/).pop();
            
            if (!datasetName) {
                showToast('Please select a dataset first', 'error');
                return;
            }
            
            if (!confirm(`Are you sure you want to delete dataset "${datasetName}"? This cannot be undone.`)) {
                return;
            }
            
            try {
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/${backend}/${datasetName}`, {
                    method: 'DELETE'
                });
                
                const data = await res.json();
                
                if (data.success) {
                    showToast(data.message || 'Dataset deleted', 'success');
                    document.getElementById('training-dataset-select').value = '';
                    document.getElementById('dataset-upload-section').style.display = 'none';
                    document.getElementById('training-files-list').style.display = 'none';
                    loadDatasets();
                } else {
                    showToast(data.detail || 'Failed to delete dataset', 'error');
                }
            } catch (err) {
                showToast(`Error: ${err.message}`, 'error');
            }
        }
        
        // Handle file upload for training
        function handleTrainingDrop(event) {
            event.preventDefault();
            const files = event.dataTransfer.files;
            processTrainingFiles(files);
        }
        
        function handleTrainingUpload(event) {
            const files = event.target.files;
            processTrainingFiles(files);
        }
        
        async function processTrainingFiles(files) {
            const backend = document.getElementById('training-backend').value;
            const datasetPath = document.getElementById('training-dataset-select').value;
            const datasetName = datasetPath.split(/[\\/]/).pop();
            
            if (!datasetName) {
                showToast('Please select a dataset first', 'error');
                return;
            }
            
            const filesList = document.getElementById('training-files-list');
            const filesContainer = document.getElementById('training-files-container');
            
            filesList.style.display = 'block';
            
            for (const file of files) {
                const formData = new FormData();
                formData.append('file', file);
                
                try {
                    const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/${backend}/${datasetName}/upload`, {
                        method: 'POST',
                        body: formData
                    });
                    
                    const data = await res.json();
                    
                    if (data.success) {
                        const fileEntry = document.createElement('div');
                        fileEntry.style.cssText = 'padding: 8px; border-bottom: 1px solid var(--border); display: flex; justify-content: space-between; align-items: center;';
                        fileEntry.innerHTML = `
                            <span>${data.filename}</span>
                            <span style="color: var(--success);">Uploaded</span>
                        `;
                        filesContainer.appendChild(fileEntry);
                    }
                } catch (err) {
                    console.error(`Failed to upload ${file.name}:`, err);
                }
            }
            
            showToast(`Uploaded ${files.length} files`, 'success');
            await refreshDatasetFiles();
        }
        
        // Transcribe dataset using ASR
        async function transcribeDataset() {
            const backend = document.getElementById('training-backend').value;
            const datasetPath = document.getElementById('training-dataset-select').value;
            const datasetName = datasetPath.split(/[\\/]/).pop();
            
            if (!datasetName) {
                showToast('Please select a dataset first', 'error');
                return;
            }
            
            try {
                showToast('Starting transcription...', 'info');
                
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/${backend}/${datasetName}/transcribe`, {
                    method: 'POST'
                });
                
                const data = await res.json();
                showToast(`Transcription started: ${data.total_files} files`, 'success');
                
                // Poll for transcription completion
                pollForTranscriptionComplete();
            } catch (err) {
                showToast(`Error: ${err.message}`, 'error');
            }
        }
        
        // Poll for transcription completion and refresh file list
        async function pollForTranscriptionComplete() {
            let lastTranscribed = 0;
            let stableCount = 0;
            
            const poll = async () => {
                const backend = document.getElementById('training-backend').value;
                const datasetPath = document.getElementById('training-dataset-select').value;
                const datasetName = datasetPath.split(/[\\/]/).pop();
                
                if (!datasetName) return;
                
                try {
                    const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/${backend}/${datasetName}/files`);
                    if (res.ok) {
                        const data = await res.json();
                        
                        if (data.transcribed_count === lastTranscribed) {
                            stableCount++;
                        } else {
                            lastTranscribed = data.transcribed_count;
                            stableCount = 0;
                            await refreshDatasetFiles();
                        }
                        
                        // If count stable for 3 polls, assume done
                        if (stableCount < 3 && data.transcribed_count < data.total) {
                            setTimeout(poll, 2000);
                        } else {
                            showToast(`Transcription complete! ${data.transcribed_count}/${data.total} files transcribed`, 'success');
                            await refreshDatasetFiles();
                        }
                    }
                } catch (err) {
                    console.error('Poll error:', err);
                }
            };
            
            setTimeout(poll, 2000);
        }
        
        // Segment long audio files
        async function segmentDataset() {
            const backend = document.getElementById('training-backend').value;
            const datasetPath = document.getElementById('training-dataset-select').value;
            const datasetName = datasetPath.split(/[\\/]/).pop();
            
            if (!datasetName) {
                showToast('Please select a dataset first', 'error');
                return;
            }
            
            try {
                const formData = new FormData();
                formData.append('min_duration', '3.0');
                formData.append('max_duration', '10.0');
                
                showToast('Segmenting uploaded audio files...', 'info');
                
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/${backend}/${datasetName}/segment-all`, {
                    method: 'POST',
                    body: formData
                });
                
                const data = await res.json();
                
                if (res.ok) {
                    showToast(data.message || `Segmenting ${data.total_files} files...`, 'success');
                    // Auto-refresh file list after segmentation (poll every 3 seconds)
                    showToast('File list will refresh when segmentation completes...', 'info');
                    pollForSegmentationComplete();
                } else {
                    showToast(data.detail || 'Segmentation failed', 'error');
                }
            } catch (err) {
                showToast(`Error: ${err.message}`, 'error');
            }
        }
        
        // Poll for segmentation completion and refresh file list
        async function pollForSegmentationComplete() {
            let lastCount = 0;
            let stableCount = 0;
            
            const poll = async () => {
                const backend = document.getElementById('training-backend').value;
                const datasetPath = document.getElementById('training-dataset-select').value;
                const datasetName = datasetPath.split(/[\\/]/).pop();
                
                if (!datasetName) return;
                
                try {
                    const res = await fetch(`${TRAINING_SERVER_URL}/v1/datasets/${backend}/${datasetName}/files`);
                    if (res.ok) {
                        const data = await res.json();
                        
                        if (data.total === lastCount) {
                            stableCount++;
                        } else {
                            lastCount = data.total;
                            stableCount = 0;
                            await refreshDatasetFiles();
                        }
                        
                        // If count stable for 3 polls (9 seconds), assume done
                        if (stableCount < 3) {
                            setTimeout(poll, 3000);
                        } else {
                            showToast('Segmentation complete!', 'success');
                            await refreshDatasetFiles();
                        }
                    }
                } catch (err) {
                    console.error('Poll error:', err);
                }
            };
            
            setTimeout(poll, 3000);
        }
        
        // Browse for speaker reference audio
        function browseSpeakerRef() {
            const path = prompt('Enter the path to speaker reference audio (3-10 seconds):');
            if (path) {
                document.getElementById('chatterbox-speaker-ref').value = path;
            }
        }
        
        // Connect to training WebSocket
        function connectTrainingWebSocket() {
            return new Promise((resolve, reject) => {
                // Already connected
                if (trainingWebSocket && trainingWebSocket.readyState === WebSocket.OPEN) {
                    console.log('[Training] WebSocket already connected');
                    resolve();
                    return;
                }
                
                // Close existing connection if any
                if (trainingWebSocket) {
                    try { trainingWebSocket.close(); } catch(e) {}
                    trainingWebSocket = null;
                }
                
                console.log('[Training] Attempting WebSocket connection...');
                
                try {
                    trainingWebSocket = new WebSocket(`ws://127.0.0.1:8895/ws/training`);
                } catch (e) {
                    console.error('[Training] Failed to create WebSocket:', e);
                    reject(e);
                    return;
                }
                
                let resolved = false;
                
                trainingWebSocket.onopen = () => {
                    console.log('[Training] WebSocket connected successfully');
                    resolved = true;
                    resolve();
                };
                
                trainingWebSocket.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        handleTrainingProgress(data);
                    } catch (e) {
                        console.error('[Training] Failed to parse message:', e);
                    }
                };
                
                trainingWebSocket.onclose = (event) => {
                    console.log('[Training] WebSocket closed:', event.code, event.reason);
                    if (!resolved) {
                        reject(new Error(`WebSocket closed: ${event.code}`));
                    }
                    // Reconnect after delay if training is active
                    if (currentTrainingJobId) {
                        setTimeout(() => connectTrainingWebSocket().catch(() => {}), 2000);
                    }
                };
                
                trainingWebSocket.onerror = (err) => {
                    console.error('[Training] WebSocket error:', err);
                    if (!resolved) {
                        reject(new Error('WebSocket connection failed'));
                    }
                };
                
                // Timeout after 5 seconds
                setTimeout(() => {
                    if (!resolved) {
                        console.error('[Training] WebSocket connection timeout');
                        try { trainingWebSocket.close(); } catch(e) {}
                        reject(new Error('WebSocket connection timeout'));
                    }
                }, 5000);
            });
        }
        
        // Handle training progress updates
        function handleTrainingProgress(data) {
            try {
                const progressText = document.getElementById('training-progress-text');
                const epochEl = document.getElementById('training-epoch');
                const lossEl = document.getElementById('training-loss');
                const etaEl = document.getElementById('training-eta');
                const progressBar = document.getElementById('training-progress-bar');
                const logEl = document.getElementById('training-log');
                
                // Skip noise
                if (data.type === 'heartbeat' || data.type === 'pong' || data.type === 'connected') {
                    return;
                }
                
                // Handle any message with step/loss data directly - don't care about type
                if (data.step !== undefined || data.loss !== undefined || data.epoch !== undefined) {
                    const step = data.step || 0;
                    const totalSteps = data.total_steps || 0;
                    const epoch = data.epoch || 0;
                    const loss = data.loss;
                    const gradNorm = data.grad_norm;
                    const eta = data.eta_seconds;
                    
                    const stepLabel = document.getElementById('training-step-label');
                    
                    // Detect phase: preprocessing has no loss, training has loss
                    const isPreprocessing = (loss === undefined && totalSteps > 0 && totalSteps < 1000);
                    
                    if (isPreprocessing) {
                        // Preprocessing phase - processing audio files
                        stepLabel.textContent = 'Preprocessing';
                        progressText.textContent = `Processing audio files: ${step}/${totalSteps}`;
                        epochEl.textContent = `${step}/${totalSteps}`;
                        const pct = (step / totalSteps) * 100;
                        progressBar.style.width = pct + '%';
                        lossEl.textContent = '-';
                        etaEl.textContent = '-';
                    } else if (totalSteps > 0) {
                        // Training phase
                        stepLabel.textContent = 'Step';
                        progressText.textContent = `Step ${step}/${totalSteps} (Epoch ${epoch})`;
                        epochEl.textContent = `${step}/${totalSteps}`;
                        const pct = (step / totalSteps) * 100;
                        progressBar.style.width = pct + '%';
                        
                        // Update loss (show loss + grad_norm if available)
                        if (loss !== undefined) {
                            let lossText = parseFloat(loss).toFixed(4);
                            if (gradNorm !== undefined) {
                                lossText += ` (grad: ${parseFloat(gradNorm).toFixed(2)})`;
                            }
                            lossEl.textContent = lossText;
                        }
                        
                        // Update ETA
                        if (eta) {
                            const mins = Math.floor(eta / 60);
                            const secs = Math.floor(eta % 60);
                            etaEl.textContent = mins + 'm ' + secs + 's';
                        }
                    } else if (epoch > 0) {
                        stepLabel.textContent = 'Epoch';
                        progressText.textContent = `Epoch ${epoch}`;
                        epochEl.textContent = epoch;
                    }
                    return;
                }
                
                // Handle status changes
                if (data.type === 'status') {
                    if (data.status === 'running') {
                        progressText.textContent = 'Training running...';
                    } else if (data.status === 'completed') {
                        progressBar.style.width = '100%';
                        progressText.textContent = 'Training completed!';
                        showToast('Training completed successfully!', 'success');
                        document.getElementById('start-training-btn').disabled = false;
                        document.getElementById('cancel-training-btn').disabled = true;
                        currentTrainingJobId = null;
                        stopTrainingPolling();
                        refreshTrainedModels();
                    } else if (data.status === 'failed') {
                        progressText.textContent = 'Training failed: ' + (data.error || 'Unknown error');
                        showToast('Training failed: ' + (data.error || 'Unknown error'), 'error');
                        document.getElementById('start-training-btn').disabled = false;
                        document.getElementById('cancel-training-btn').disabled = true;
                        currentTrainingJobId = null;
                        stopTrainingPolling();
                    } else if (data.status === 'cancelled') {
                        progressText.textContent = 'Training cancelled';
                        showToast('Training cancelled', 'info');
                        document.getElementById('start-training-btn').disabled = false;
                        document.getElementById('cancel-training-btn').disabled = true;
                        currentTrainingJobId = null;
                        stopTrainingPolling();
                    }
                }
            } catch (err) {
                console.error('[Training] Progress update error:', err);
            }
        }
        
        // Start training
        async function startTraining() {
            const backend = document.getElementById('training-backend').value;
            const datasetPath = document.getElementById('training-dataset-path').value;
            
            if (!datasetPath) {
                showToast('Please select or enter a dataset path', 'error');
                return;
            }
            
            // Connect WebSocket for progress
            const progressText = document.getElementById('training-progress-text');
            try {
                progressText.textContent = 'Connecting to training server...';
                await connectTrainingWebSocket();
                progressText.textContent = 'Starting training...';
            } catch (err) {
                console.error('[Training] Failed to connect WebSocket:', err);
                progressText.textContent = 'Starting training...';
            }
            
            // Clear previous log
            document.getElementById('training-log').innerHTML = '';
            
            let requestBody;
            
            if (backend === 'soprano') {
                // Parse learning rate - supports scientific notation (e.g. "5e-5", "1e-4")
                const lrInput = document.getElementById('soprano-lr').value;
                const learningRate = parseFloat(lrInput) || 5e-5;
                
                requestBody = {
                    model_name: document.getElementById('soprano-model-name').value || 'my_soprano_voice',
                    dataset_path: datasetPath,
                    epochs: parseInt(document.getElementById('soprano-epochs').value) || 20,
                    learning_rate: learningRate,
                    batch_size: parseInt(document.getElementById('soprano-batch-size').value) || 4,
                    save_every: parseInt(document.getElementById('soprano-save-every').value) || 10,
                    warmup_steps: parseInt(document.getElementById('soprano-warmup').value) || 100,
                    gradient_accumulation: parseInt(document.getElementById('soprano-grad-accum').value) || 1,
                    // LoRA settings
                    use_lora: document.getElementById('soprano-use-lora').checked,
                    lora_rank: parseInt(document.getElementById('soprano-lora-rank').value) || 32,
                    lora_alpha: parseInt(document.getElementById('soprano-lora-alpha').value) || 64,
                    lora_dropout: parseFloat(document.getElementById('soprano-lora-dropout').value) || 0.05
                };
            } else {
                requestBody = {
                    model_name: document.getElementById('chatterbox-model-name').value || 'my_chatterbox_voice',
                    dataset_path: datasetPath,
                    is_turbo: document.getElementById('chatterbox-turbo-mode').checked,
                    epochs: parseInt(document.getElementById('chatterbox-epochs').value) || 150,
                    learning_rate: parseFloat(document.getElementById('chatterbox-lr').value) || 5e-5,
                    batch_size: parseInt(document.getElementById('chatterbox-batch-size').value) || 4,
                    gradient_accumulation: parseInt(document.getElementById('chatterbox-grad-accum').value) || 8,
                    preprocess: document.getElementById('chatterbox-preprocess').checked,
                    speaker_reference: document.getElementById('chatterbox-speaker-ref').value || null
                };
            }
            
            try {
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/${backend}/train`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(requestBody)
                });
                
                const data = await res.json();
                
                if (data.job_id) {
                    currentTrainingJobId = data.job_id;
                    showToast(`Training started`, 'success');
                    document.getElementById('start-training-btn').disabled = true;
                    document.getElementById('cancel-training-btn').disabled = false;
                    document.getElementById('training-progress-section').style.display = 'block';
                    document.getElementById('training-progress-text').textContent = 'Training in progress...';
                    
                    // Add to training log
                    const logEl = document.getElementById('training-log');
                    logEl.innerHTML = `<div style="color: var(--primary);">[${new Date().toLocaleTimeString()}] Training started</div>`;
                    
                    // Start HTTP polling as backup
                    startTrainingPolling(data.job_id);
                } else {
                    showToast(data.detail || 'Failed to start training', 'error');
                }
            } catch (err) {
                showToast(`Error: ${err.message}`, 'error');
            }
        }
        
        // Cancel training
        async function cancelTraining() {
            if (!currentTrainingJobId) return;
            
            try {
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/jobs/${currentTrainingJobId}/cancel`, {
                    method: 'POST'
                });
                
                const data = await res.json();
                showToast(data.message || 'Cancellation requested', 'info');
            } catch (err) {
                showToast(`Error: ${err.message}`, 'error');
            }
        }
        
        // Refresh trained models list
        async function refreshTrainedModels() {
            try {
                const res = await fetch(`${TRAINING_SERVER_URL}/v1/models`);
                const data = await res.json();
                
                // Update Soprano models list
                const sopranoList = document.getElementById('soprano-models-list');
                if (data.soprano && data.soprano.length > 0) {
                    sopranoList.innerHTML = data.soprano.map(m => `
                        <div style="padding: 8px; border: 1px solid var(--border); border-radius: 4px; margin-bottom: 8px;">
                            <div style="font-weight: bold;">${m.name}</div>
                            <div style="color: var(--text-muted); font-size: 12px;">Created: ${new Date(m.created).toLocaleDateString()}</div>
                        </div>
                    `).join('');
                } else {
                    sopranoList.innerHTML = '<div style="color: var(--text-muted);">No custom Soprano models found.</div>';
                }
                
                // Update Chatterbox models list
                const chatterboxList = document.getElementById('chatterbox-models-list');
                if (data.chatterbox && data.chatterbox.length > 0) {
                    chatterboxList.innerHTML = data.chatterbox.map(m => `
                        <div style="padding: 8px; border: 1px solid var(--border); border-radius: 4px; margin-bottom: 8px;">
                            <div style="font-weight: bold;">${m.name}</div>
                            <div style="color: var(--text-muted); font-size: 12px;">
                                Files: ${m.files.join(', ') || 'None'}<br>
                                Created: ${new Date(m.created).toLocaleDateString()}
                            </div>
                        </div>
                    `).join('');
                } else {
                    chatterboxList.innerHTML = '<div style="color: var(--text-muted);">No custom Chatterbox models found.</div>';
                }
            } catch (err) {
                console.error('Failed to refresh models:', err);
            }
        }
        
        // Initialize training tab when loaded
        function initTrainingTab() {
            updateTrainingUI();
            refreshTrainedModels();
            loadDatasets(); // Load available datasets
        }
        
        // Call init when Training tab is shown
        const originalSwitchTab = window.switchTab || function() {};
        window.switchTab = function(index) {
            originalSwitchTab(index);
            if (index === 7) {
                initTrainingTab();
            }
        };
        
    </script>
</body>
</html>
